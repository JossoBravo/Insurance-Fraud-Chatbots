{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('Insurancefraud.xlsx', sheet_name='Fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_initial_date</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>limit/person</th>\n",
       "      <th>limit_accident</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>...</th>\n",
       "      <th>property_damage</th>\n",
       "      <th>bodily_injuries</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>fraud_reported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>2014-10-17</td>\n",
       "      <td>OH</td>\n",
       "      <td>250</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>YES</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "      <td>71610</td>\n",
       "      <td>6510</td>\n",
       "      <td>13020</td>\n",
       "      <td>52080</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>IN</td>\n",
       "      <td>250</td>\n",
       "      <td>500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NO</td>\n",
       "      <td>5070</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>3510</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>687698</td>\n",
       "      <td>2000-09-06</td>\n",
       "      <td>OH</td>\n",
       "      <td>100</td>\n",
       "      <td>300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NO</td>\n",
       "      <td>34650</td>\n",
       "      <td>7700</td>\n",
       "      <td>3850</td>\n",
       "      <td>23100</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>227811</td>\n",
       "      <td>1990-05-25</td>\n",
       "      <td>IL</td>\n",
       "      <td>250</td>\n",
       "      <td>500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "      <td>63400</td>\n",
       "      <td>6340</td>\n",
       "      <td>6340</td>\n",
       "      <td>50720</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>367455</td>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>IL</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1583.91</td>\n",
       "      <td>6000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>6500</td>\n",
       "      <td>1300</td>\n",
       "      <td>650</td>\n",
       "      <td>4550</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>941851</td>\n",
       "      <td>1991-07-16</td>\n",
       "      <td>OH</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1310.80</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>YES</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>87200</td>\n",
       "      <td>17440</td>\n",
       "      <td>8720</td>\n",
       "      <td>61040</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>285</td>\n",
       "      <td>41</td>\n",
       "      <td>186934</td>\n",
       "      <td>2014-01-05</td>\n",
       "      <td>IL</td>\n",
       "      <td>100</td>\n",
       "      <td>300</td>\n",
       "      <td>1000</td>\n",
       "      <td>1436.79</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>YES</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NO</td>\n",
       "      <td>108480</td>\n",
       "      <td>18080</td>\n",
       "      <td>18080</td>\n",
       "      <td>72320</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>130</td>\n",
       "      <td>34</td>\n",
       "      <td>918516</td>\n",
       "      <td>2003-02-17</td>\n",
       "      <td>OH</td>\n",
       "      <td>250</td>\n",
       "      <td>500</td>\n",
       "      <td>500</td>\n",
       "      <td>1383.49</td>\n",
       "      <td>3000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>YES</td>\n",
       "      <td>67500</td>\n",
       "      <td>7500</td>\n",
       "      <td>7500</td>\n",
       "      <td>52500</td>\n",
       "      <td>1996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>458</td>\n",
       "      <td>62</td>\n",
       "      <td>533940</td>\n",
       "      <td>2011-11-18</td>\n",
       "      <td>IL</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1356.92</td>\n",
       "      <td>5000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>YES</td>\n",
       "      <td>46980</td>\n",
       "      <td>5220</td>\n",
       "      <td>5220</td>\n",
       "      <td>36540</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>456</td>\n",
       "      <td>60</td>\n",
       "      <td>556080</td>\n",
       "      <td>1996-11-11</td>\n",
       "      <td>OH</td>\n",
       "      <td>250</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>766.19</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NO</td>\n",
       "      <td>5060</td>\n",
       "      <td>460</td>\n",
       "      <td>920</td>\n",
       "      <td>3680</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     months_as_customer  age  policy_number policy_initial_date policy_state  \\\n",
       "0                   328   48         521585          2014-10-17           OH   \n",
       "1                   228   42         342868          2006-06-27           IN   \n",
       "2                   134   29         687698          2000-09-06           OH   \n",
       "3                   256   41         227811          1990-05-25           IL   \n",
       "4                   228   44         367455          2014-06-06           IL   \n",
       "..                  ...  ...            ...                 ...          ...   \n",
       "995                   3   38         941851          1991-07-16           OH   \n",
       "996                 285   41         186934          2014-01-05           IL   \n",
       "997                 130   34         918516          2003-02-17           OH   \n",
       "998                 458   62         533940          2011-11-18           IL   \n",
       "999                 456   60         556080          1996-11-11           OH   \n",
       "\n",
       "     limit/person  limit_accident  policy_deductable  policy_annual_premium  \\\n",
       "0             250             500               1000                1406.91   \n",
       "1             250             500               2000                1197.22   \n",
       "2             100             300               2000                1413.14   \n",
       "3             250             500               2000                1415.74   \n",
       "4             500            1000               1000                1583.91   \n",
       "..            ...             ...                ...                    ...   \n",
       "995           500            1000               1000                1310.80   \n",
       "996           100             300               1000                1436.79   \n",
       "997           250             500                500                1383.49   \n",
       "998           500            1000               2000                1356.92   \n",
       "999           250             500               1000                 766.19   \n",
       "\n",
       "     umbrella_limit  ...  property_damage bodily_injuries witnesses  \\\n",
       "0                 0  ...              YES               1         2   \n",
       "1           5000000  ...               NO               0         0   \n",
       "2           5000000  ...               NO               2         3   \n",
       "3           6000000  ...               NO               1         2   \n",
       "4           6000000  ...               NO               0         1   \n",
       "..              ...  ...              ...             ...       ...   \n",
       "995               0  ...              YES               0         1   \n",
       "996               0  ...              YES               2         3   \n",
       "997         3000000  ...               NO               2         3   \n",
       "998         5000000  ...               NO               0         1   \n",
       "999               0  ...               NO               0         3   \n",
       "\n",
       "    police_report_available  total_claim_amount  injury_claim property_claim  \\\n",
       "0                       YES               71610          6510          13020   \n",
       "1                        NO                5070           780            780   \n",
       "2                        NO               34650          7700           3850   \n",
       "3                        NO               63400          6340           6340   \n",
       "4                        NO                6500          1300            650   \n",
       "..                      ...                 ...           ...            ...   \n",
       "995                      NO               87200         17440           8720   \n",
       "996                      NO              108480         18080          18080   \n",
       "997                     YES               67500          7500           7500   \n",
       "998                     YES               46980          5220           5220   \n",
       "999                      NO                5060           460            920   \n",
       "\n",
       "    vehicle_claim auto_year fraud_reported  \n",
       "0           52080      2004              1  \n",
       "1            3510      2007              1  \n",
       "2           23100      2007              0  \n",
       "3           50720      2014              1  \n",
       "4            4550      2009              0  \n",
       "..            ...       ...            ...  \n",
       "995         61040      2006              0  \n",
       "996         72320      2015              0  \n",
       "997         52500      1996              0  \n",
       "998         36540      1998              0  \n",
       "999          3680      2007              0  \n",
       "\n",
       "[1000 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este conjunto de datos parece contener información relacionada con reclamaciones de seguros, con columnas que incluyen detalles sobre los clientes (como months_as_customer, age, policy_number), detalles de la póliza de seguro (como policy_state, limit/person, policy_annual_premium), y detalles específicos de las reclamaciones (como total_claim_amount, injury_claim, vehicle_claim) entre otros. La columna fraud_reported indica si se reportó fraude en la reclamación, donde 1 representa fraude y 0 representa no fraude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>limit/person</th>\n",
       "      <th>limit_accident</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip_code</th>\n",
       "      <th>capital-gains</th>\n",
       "      <th>...</th>\n",
       "      <th>incident_hour_of_the_day</th>\n",
       "      <th>number_of_vehicles_involved</th>\n",
       "      <th>bodily_injuries</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>fraud_reported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>203.954000</td>\n",
       "      <td>38.948000</td>\n",
       "      <td>546238.648000</td>\n",
       "      <td>272.650000</td>\n",
       "      <td>580.200000</td>\n",
       "      <td>1136.000000</td>\n",
       "      <td>1256.406150</td>\n",
       "      <td>1.101000e+06</td>\n",
       "      <td>501214.488000</td>\n",
       "      <td>25126.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.644000</td>\n",
       "      <td>1.83900</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>1.487000</td>\n",
       "      <td>52761.94000</td>\n",
       "      <td>7433.420000</td>\n",
       "      <td>7399.570000</td>\n",
       "      <td>37928.950000</td>\n",
       "      <td>2005.103000</td>\n",
       "      <td>0.247000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>115.113174</td>\n",
       "      <td>9.140287</td>\n",
       "      <td>257063.005276</td>\n",
       "      <td>161.603196</td>\n",
       "      <td>287.420547</td>\n",
       "      <td>611.864673</td>\n",
       "      <td>244.167395</td>\n",
       "      <td>2.297407e+06</td>\n",
       "      <td>71701.610941</td>\n",
       "      <td>27872.187708</td>\n",
       "      <td>...</td>\n",
       "      <td>6.951373</td>\n",
       "      <td>1.01888</td>\n",
       "      <td>0.820127</td>\n",
       "      <td>1.111335</td>\n",
       "      <td>26401.53319</td>\n",
       "      <td>4880.951853</td>\n",
       "      <td>4824.726179</td>\n",
       "      <td>18886.252893</td>\n",
       "      <td>6.015861</td>\n",
       "      <td>0.431483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>100804.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>433.330000</td>\n",
       "      <td>-1.000000e+06</td>\n",
       "      <td>430104.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1995.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>115.750000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>335980.250000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1089.607500</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>448404.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>41812.50000</td>\n",
       "      <td>4295.000000</td>\n",
       "      <td>4445.000000</td>\n",
       "      <td>30292.500000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>199.500000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>533135.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1257.200000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>466445.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58055.00000</td>\n",
       "      <td>6775.000000</td>\n",
       "      <td>6750.000000</td>\n",
       "      <td>42100.000000</td>\n",
       "      <td>2005.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>276.250000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>759099.750000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1415.695000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>603251.000000</td>\n",
       "      <td>51025.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>70592.50000</td>\n",
       "      <td>11305.000000</td>\n",
       "      <td>10885.000000</td>\n",
       "      <td>50822.500000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>479.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>999435.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2047.590000</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>620962.000000</td>\n",
       "      <td>100500.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>114920.00000</td>\n",
       "      <td>21450.000000</td>\n",
       "      <td>23670.000000</td>\n",
       "      <td>79560.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       months_as_customer          age  policy_number  limit/person  \\\n",
       "count         1000.000000  1000.000000    1000.000000   1000.000000   \n",
       "mean           203.954000    38.948000  546238.648000    272.650000   \n",
       "std            115.113174     9.140287  257063.005276    161.603196   \n",
       "min              0.000000    19.000000  100804.000000    100.000000   \n",
       "25%            115.750000    32.000000  335980.250000    100.000000   \n",
       "50%            199.500000    38.000000  533135.000000    250.000000   \n",
       "75%            276.250000    44.000000  759099.750000    500.000000   \n",
       "max            479.000000    64.000000  999435.000000    500.000000   \n",
       "\n",
       "       limit_accident  policy_deductable  policy_annual_premium  \\\n",
       "count     1000.000000        1000.000000            1000.000000   \n",
       "mean       580.200000        1136.000000            1256.406150   \n",
       "std        287.420547         611.864673             244.167395   \n",
       "min        300.000000         500.000000             433.330000   \n",
       "25%        300.000000         500.000000            1089.607500   \n",
       "50%        500.000000        1000.000000            1257.200000   \n",
       "75%       1000.000000        2000.000000            1415.695000   \n",
       "max       1000.000000        2000.000000            2047.590000   \n",
       "\n",
       "       umbrella_limit  insured_zip_code  capital-gains  ...  \\\n",
       "count    1.000000e+03       1000.000000    1000.000000  ...   \n",
       "mean     1.101000e+06     501214.488000   25126.100000  ...   \n",
       "std      2.297407e+06      71701.610941   27872.187708  ...   \n",
       "min     -1.000000e+06     430104.000000       0.000000  ...   \n",
       "25%      0.000000e+00     448404.500000       0.000000  ...   \n",
       "50%      0.000000e+00     466445.500000       0.000000  ...   \n",
       "75%      0.000000e+00     603251.000000   51025.000000  ...   \n",
       "max      1.000000e+07     620962.000000  100500.000000  ...   \n",
       "\n",
       "       incident_hour_of_the_day  number_of_vehicles_involved  bodily_injuries  \\\n",
       "count               1000.000000                   1000.00000      1000.000000   \n",
       "mean                  11.644000                      1.83900         0.992000   \n",
       "std                    6.951373                      1.01888         0.820127   \n",
       "min                    0.000000                      1.00000         0.000000   \n",
       "25%                    6.000000                      1.00000         0.000000   \n",
       "50%                   12.000000                      1.00000         1.000000   \n",
       "75%                   17.000000                      3.00000         2.000000   \n",
       "max                   23.000000                      4.00000         2.000000   \n",
       "\n",
       "         witnesses  total_claim_amount  injury_claim  property_claim  \\\n",
       "count  1000.000000          1000.00000   1000.000000     1000.000000   \n",
       "mean      1.487000         52761.94000   7433.420000     7399.570000   \n",
       "std       1.111335         26401.53319   4880.951853     4824.726179   \n",
       "min       0.000000           100.00000      0.000000        0.000000   \n",
       "25%       1.000000         41812.50000   4295.000000     4445.000000   \n",
       "50%       1.000000         58055.00000   6775.000000     6750.000000   \n",
       "75%       2.000000         70592.50000  11305.000000    10885.000000   \n",
       "max       3.000000        114920.00000  21450.000000    23670.000000   \n",
       "\n",
       "       vehicle_claim    auto_year  fraud_reported  \n",
       "count    1000.000000  1000.000000     1000.000000  \n",
       "mean    37928.950000  2005.103000        0.247000  \n",
       "std     18886.252893     6.015861        0.431483  \n",
       "min        70.000000  1995.000000        0.000000  \n",
       "25%     30292.500000  2000.000000        0.000000  \n",
       "50%     42100.000000  2005.000000        0.000000  \n",
       "75%     50822.500000  2010.000000        0.000000  \n",
       "max     79560.000000  2015.000000        1.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_row = df['fraud_reported'].sum()\n",
    "sum_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_initial_date</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>limit/person</th>\n",
       "      <th>limit_accident</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>...</th>\n",
       "      <th>bodily_injuries</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>fraud_reported</th>\n",
       "      <th>Train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>2014-10-17</td>\n",
       "      <td>OH</td>\n",
       "      <td>250</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "      <td>71610</td>\n",
       "      <td>6510</td>\n",
       "      <td>13020</td>\n",
       "      <td>52080</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>IN</td>\n",
       "      <td>250</td>\n",
       "      <td>500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NO</td>\n",
       "      <td>5070</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>3510</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>687698</td>\n",
       "      <td>2000-09-06</td>\n",
       "      <td>OH</td>\n",
       "      <td>100</td>\n",
       "      <td>300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NO</td>\n",
       "      <td>34650</td>\n",
       "      <td>7700</td>\n",
       "      <td>3850</td>\n",
       "      <td>23100</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>227811</td>\n",
       "      <td>1990-05-25</td>\n",
       "      <td>IL</td>\n",
       "      <td>250</td>\n",
       "      <td>500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "      <td>63400</td>\n",
       "      <td>6340</td>\n",
       "      <td>6340</td>\n",
       "      <td>50720</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>367455</td>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>IL</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1583.91</td>\n",
       "      <td>6000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>6500</td>\n",
       "      <td>1300</td>\n",
       "      <td>650</td>\n",
       "      <td>4550</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   months_as_customer  age  policy_number policy_initial_date policy_state  \\\n",
       "0                 328   48         521585          2014-10-17           OH   \n",
       "1                 228   42         342868          2006-06-27           IN   \n",
       "2                 134   29         687698          2000-09-06           OH   \n",
       "3                 256   41         227811          1990-05-25           IL   \n",
       "4                 228   44         367455          2014-06-06           IL   \n",
       "\n",
       "   limit/person  limit_accident  policy_deductable  policy_annual_premium  \\\n",
       "0           250             500               1000                1406.91   \n",
       "1           250             500               2000                1197.22   \n",
       "2           100             300               2000                1413.14   \n",
       "3           250             500               2000                1415.74   \n",
       "4           500            1000               1000                1583.91   \n",
       "\n",
       "   umbrella_limit  ...  bodily_injuries witnesses police_report_available  \\\n",
       "0               0  ...                1         2                     YES   \n",
       "1         5000000  ...                0         0                      NO   \n",
       "2         5000000  ...                2         3                      NO   \n",
       "3         6000000  ...                1         2                      NO   \n",
       "4         6000000  ...                0         1                      NO   \n",
       "\n",
       "  total_claim_amount  injury_claim  property_claim vehicle_claim auto_year  \\\n",
       "0              71610          6510           13020         52080      2004   \n",
       "1               5070           780             780          3510      2007   \n",
       "2              34650          7700            3850         23100      2007   \n",
       "3              63400          6340            6340         50720      2014   \n",
       "4               6500          1300             650          4550      2009   \n",
       "\n",
       "  fraud_reported Train  \n",
       "0              1     0  \n",
       "1              1     1  \n",
       "2              0     1  \n",
       "3              1     1  \n",
       "4              0     0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "df['Train']=[1 if np.random.uniform()<0.5 else 0 for _ in range(len(df))]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este fragmento de código agrega una nueva columna llamada Train al DataFrame df. La columna se llena con valores 1 y 0, determinados de forma aleatoria. La intención detrás de esto suele ser dividir el conjunto de datos en dos subconjuntos: uno para entrenamiento y otro para pruebas/validación, una práctica común en el aprendizaje automático y análisis de datos para evaluar la generalización de los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna Train ahora puede ser utilizada como un indicador para dividir el conjunto de datos. Por ejemplo, puedes usar las filas donde Train es 1 para entrenar un modelo, y las filas donde Train es 0 para validar el modelo o para pruebas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna Train se ha añadido correctamente al DataFrame. Ahora cada fila tiene asignado un valor 0 o 1 en esta columna, determinado de forma aleatoria. Esto indica si cada fila se utilizará para entrenamiento (1) o no (0), permitiendo así una división simple del conjunto de datos para propósitos de entrenamiento y validación o pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(columns=['fraud_reported', 'Train'])\n",
    "y=df['fraud_reported']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = df.drop(columns=['fraud_reported', 'Train']): Esta línea crea un nuevo DataFrame x que es una copia de df pero sin las columnas fraud_reported y Train. La función drop elimina las columnas especificadas del DataFrame. Esto se hace porque fraud_reported es lo que usualmente queremos predecir (la variable objetivo o dependiente), y Train es una columna artificial que hemos añadido para dividir el conjunto de datos, por lo tanto, ninguna de las dos debe incluirse en las variables de entrada para el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = df['fraud_reported']: Esta línea extrae la columna fraud_reported de df y la asigna a y. Esta será nuestra variable objetivo, que contiene los valores que intentaremos predecir con nuestro modelo. En el contexto de este conjunto de datos, y contiene información sobre si se reportó fraude (1) o no (0) en cada caso.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En resumen:\n",
    "\n",
    "x contiene los predictores o variables independientes (todas las columnas excepto fraud_reported y Train), que son los datos que usaremos para predecir los valores de y.\n",
    "y contiene la variable objetivo o dependiente (fraud_reported), que es el resultado que esperamos predecir basándonos en los datos en x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x[df['Train'] == 1]\n",
    "#It selects the rows on x, where the conditiomn is true\n",
    "x_test = x[df['Train'] == 0]\n",
    "#It selects the rows on x, where the conditiomn is true\n",
    "y_train = y[df['Train'] == 1]\n",
    "#It selects the rows on y, where the conditiomn is true\n",
    "y_test = y[df['Train'] == 0]\n",
    "#It selects the rows on y, where the conditiomn is true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este bloque de código divide los datos en dos conjuntos: uno para entrenar el modelo (x_train y y_train) y otro para evaluar su rendimiento (x_test y y_test), basándose en la columna Train que fue añadida previamente al DataFrame df. Esta es una práctica común en el aprendizaje automático para evaluar cómo el modelo generaliza a nuevos datos que no ha visto durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_initial_date</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>limit/person</th>\n",
       "      <th>limit_accident</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>...</th>\n",
       "      <th>number_of_vehicles_involved</th>\n",
       "      <th>property_damage</th>\n",
       "      <th>bodily_injuries</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>IN</td>\n",
       "      <td>250</td>\n",
       "      <td>500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NO</td>\n",
       "      <td>5070</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>3510</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>687698</td>\n",
       "      <td>2000-09-06</td>\n",
       "      <td>OH</td>\n",
       "      <td>100</td>\n",
       "      <td>300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NO</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NO</td>\n",
       "      <td>34650</td>\n",
       "      <td>7700</td>\n",
       "      <td>3850</td>\n",
       "      <td>23100</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>227811</td>\n",
       "      <td>1990-05-25</td>\n",
       "      <td>IL</td>\n",
       "      <td>250</td>\n",
       "      <td>500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "      <td>63400</td>\n",
       "      <td>6340</td>\n",
       "      <td>6340</td>\n",
       "      <td>50720</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>842643</td>\n",
       "      <td>1997-11-20</td>\n",
       "      <td>OH</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>1215.36</td>\n",
       "      <td>3000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>YES</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NO</td>\n",
       "      <td>56520</td>\n",
       "      <td>4710</td>\n",
       "      <td>9420</td>\n",
       "      <td>42390</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>121</td>\n",
       "      <td>34</td>\n",
       "      <td>626808</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>OH</td>\n",
       "      <td>100</td>\n",
       "      <td>300</td>\n",
       "      <td>1000</td>\n",
       "      <td>936.61</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>7280</td>\n",
       "      <td>1120</td>\n",
       "      <td>1120</td>\n",
       "      <td>5040</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    months_as_customer  age  policy_number policy_initial_date policy_state  \\\n",
       "1                  228   42         342868          2006-06-27           IN   \n",
       "2                  134   29         687698          2000-09-06           OH   \n",
       "3                  256   41         227811          1990-05-25           IL   \n",
       "12                  60   23         842643          1997-11-20           OH   \n",
       "13                 121   34         626808          2012-10-26           OH   \n",
       "\n",
       "    limit/person  limit_accident  policy_deductable  policy_annual_premium  \\\n",
       "1            250             500               2000                1197.22   \n",
       "2            100             300               2000                1413.14   \n",
       "3            250             500               2000                1415.74   \n",
       "12           500            1000                500                1215.36   \n",
       "13           100             300               1000                 936.61   \n",
       "\n",
       "    umbrella_limit  ...  number_of_vehicles_involved property_damage  \\\n",
       "1          5000000  ...                            1              NO   \n",
       "2          5000000  ...                            3              NO   \n",
       "3          6000000  ...                            1              NO   \n",
       "12         3000000  ...                            1             YES   \n",
       "13               0  ...                            1              NO   \n",
       "\n",
       "   bodily_injuries witnesses  police_report_available  total_claim_amount  \\\n",
       "1                0         0                       NO                5070   \n",
       "2                2         3                       NO               34650   \n",
       "3                1         2                       NO               63400   \n",
       "12               1         0                       NO               56520   \n",
       "13               1         1                       NO                7280   \n",
       "\n",
       "   injury_claim property_claim vehicle_claim auto_year  \n",
       "1           780            780          3510      2007  \n",
       "2          7700           3850         23100      2007  \n",
       "3          6340           6340         50720      2014  \n",
       "12         4710           9420         42390      2000  \n",
       "13         1120           1120          5040      2010  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es útil para un modelo de aprendizaje automático que solo puede manejar datos numéricos, o cuando se desea realizar análisis estadístico que solo aplica a datos numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>limit/person</th>\n",
       "      <th>limit_accident</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip_code</th>\n",
       "      <th>capital-gains</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>incident_hour_of_the_day</th>\n",
       "      <th>number_of_vehicles_involved</th>\n",
       "      <th>bodily_injuries</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>250</td>\n",
       "      <td>500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>468176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5070</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>3510</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>687698</td>\n",
       "      <td>100</td>\n",
       "      <td>300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>430632</td>\n",
       "      <td>35100</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>34650</td>\n",
       "      <td>7700</td>\n",
       "      <td>3850</td>\n",
       "      <td>23100</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>227811</td>\n",
       "      <td>250</td>\n",
       "      <td>500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>608117</td>\n",
       "      <td>48900</td>\n",
       "      <td>-62400</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>63400</td>\n",
       "      <td>6340</td>\n",
       "      <td>6340</td>\n",
       "      <td>50720</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>842643</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>500</td>\n",
       "      <td>1215.36</td>\n",
       "      <td>3000000</td>\n",
       "      <td>432220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56520</td>\n",
       "      <td>4710</td>\n",
       "      <td>9420</td>\n",
       "      <td>42390</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>121</td>\n",
       "      <td>34</td>\n",
       "      <td>626808</td>\n",
       "      <td>100</td>\n",
       "      <td>300</td>\n",
       "      <td>1000</td>\n",
       "      <td>936.61</td>\n",
       "      <td>0</td>\n",
       "      <td>464652</td>\n",
       "      <td>52800</td>\n",
       "      <td>-32800</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7280</td>\n",
       "      <td>1120</td>\n",
       "      <td>1120</td>\n",
       "      <td>5040</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    months_as_customer  age  policy_number  limit/person  limit_accident  \\\n",
       "1                  228   42         342868           250             500   \n",
       "2                  134   29         687698           100             300   \n",
       "3                  256   41         227811           250             500   \n",
       "12                  60   23         842643           500            1000   \n",
       "13                 121   34         626808           100             300   \n",
       "\n",
       "    policy_deductable  policy_annual_premium  umbrella_limit  \\\n",
       "1                2000                1197.22         5000000   \n",
       "2                2000                1413.14         5000000   \n",
       "3                2000                1415.74         6000000   \n",
       "12                500                1215.36         3000000   \n",
       "13               1000                 936.61               0   \n",
       "\n",
       "    insured_zip_code  capital-gains  capital-loss  incident_hour_of_the_day  \\\n",
       "1             468176              0             0                         8   \n",
       "2             430632          35100             0                         7   \n",
       "3             608117          48900        -62400                         5   \n",
       "12            432220              0             0                         9   \n",
       "13            464652          52800        -32800                         5   \n",
       "\n",
       "    number_of_vehicles_involved  bodily_injuries  witnesses  \\\n",
       "1                             1                0          0   \n",
       "2                             3                2          3   \n",
       "3                             1                1          2   \n",
       "12                            1                1          0   \n",
       "13                            1                1          1   \n",
       "\n",
       "    total_claim_amount  injury_claim  property_claim  vehicle_claim  auto_year  \n",
       "1                 5070           780             780           3510       2007  \n",
       "2                34650          7700            3850          23100       2007  \n",
       "3                63400          6340            6340          50720       2014  \n",
       "12               56520          4710            9420          42390       2000  \n",
       "13                7280          1120            1120           5040       2010  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_df = x_train.select_dtypes(include=['number'])\n",
    "numeric_test_df = x_test.select_dtypes(include=['number'])\n",
    "numeric_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy_state</th>\n",
       "      <th>insured_sex</th>\n",
       "      <th>insured_education_level</th>\n",
       "      <th>insured_occupation</th>\n",
       "      <th>incident_type</th>\n",
       "      <th>incident_severity</th>\n",
       "      <th>authorities_contacted</th>\n",
       "      <th>incident_state</th>\n",
       "      <th>property_damage</th>\n",
       "      <th>police_report_available</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IN</td>\n",
       "      <td>MALE</td>\n",
       "      <td>MD</td>\n",
       "      <td>machine-op-inspct</td>\n",
       "      <td>Vehicle Theft</td>\n",
       "      <td>Minor Damage</td>\n",
       "      <td>Police</td>\n",
       "      <td>VA</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OH</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>PhD</td>\n",
       "      <td>sales</td>\n",
       "      <td>Multi-vehicle Collision</td>\n",
       "      <td>Minor Damage</td>\n",
       "      <td>Police</td>\n",
       "      <td>NY</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IL</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>PhD</td>\n",
       "      <td>armed-forces</td>\n",
       "      <td>Single Vehicle Collision</td>\n",
       "      <td>Major Damage</td>\n",
       "      <td>Police</td>\n",
       "      <td>OH</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>OH</td>\n",
       "      <td>MALE</td>\n",
       "      <td>MD</td>\n",
       "      <td>protective-serv</td>\n",
       "      <td>Single Vehicle Collision</td>\n",
       "      <td>Total Loss</td>\n",
       "      <td>Ambulance</td>\n",
       "      <td>SC</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>OH</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>MD</td>\n",
       "      <td>armed-forces</td>\n",
       "      <td>Parked Car</td>\n",
       "      <td>Minor Damage</td>\n",
       "      <td>None</td>\n",
       "      <td>SC</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>OH</td>\n",
       "      <td>MALE</td>\n",
       "      <td>MD</td>\n",
       "      <td>other-service</td>\n",
       "      <td>Single Vehicle Collision</td>\n",
       "      <td>Total Loss</td>\n",
       "      <td>Other</td>\n",
       "      <td>WV</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>IN</td>\n",
       "      <td>MALE</td>\n",
       "      <td>MD</td>\n",
       "      <td>exec-managerial</td>\n",
       "      <td>Multi-vehicle Collision</td>\n",
       "      <td>Major Damage</td>\n",
       "      <td>Fire</td>\n",
       "      <td>OH</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>OH</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Masters</td>\n",
       "      <td>craft-repair</td>\n",
       "      <td>Single Vehicle Collision</td>\n",
       "      <td>Minor Damage</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NC</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>IL</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Associate</td>\n",
       "      <td>handlers-cleaners</td>\n",
       "      <td>Single Vehicle Collision</td>\n",
       "      <td>Major Damage</td>\n",
       "      <td>Other</td>\n",
       "      <td>NY</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>OH</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Associate</td>\n",
       "      <td>sales</td>\n",
       "      <td>Parked Car</td>\n",
       "      <td>Minor Damage</td>\n",
       "      <td>Police</td>\n",
       "      <td>WV</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>494 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    policy_state insured_sex insured_education_level insured_occupation  \\\n",
       "1             IN        MALE                      MD  machine-op-inspct   \n",
       "2             OH      FEMALE                     PhD              sales   \n",
       "3             IL      FEMALE                     PhD       armed-forces   \n",
       "12            OH        MALE                      MD    protective-serv   \n",
       "13            OH      FEMALE                      MD       armed-forces   \n",
       "..           ...         ...                     ...                ...   \n",
       "991           OH        MALE                      MD      other-service   \n",
       "992           IN        MALE                      MD    exec-managerial   \n",
       "995           OH      FEMALE                 Masters       craft-repair   \n",
       "998           IL        MALE               Associate  handlers-cleaners   \n",
       "999           OH      FEMALE               Associate              sales   \n",
       "\n",
       "                incident_type incident_severity authorities_contacted  \\\n",
       "1               Vehicle Theft      Minor Damage                Police   \n",
       "2     Multi-vehicle Collision      Minor Damage                Police   \n",
       "3    Single Vehicle Collision      Major Damage                Police   \n",
       "12   Single Vehicle Collision        Total Loss             Ambulance   \n",
       "13                 Parked Car      Minor Damage                  None   \n",
       "..                        ...               ...                   ...   \n",
       "991  Single Vehicle Collision        Total Loss                 Other   \n",
       "992   Multi-vehicle Collision      Major Damage                  Fire   \n",
       "995  Single Vehicle Collision      Minor Damage                  Fire   \n",
       "998  Single Vehicle Collision      Major Damage                 Other   \n",
       "999                Parked Car      Minor Damage                Police   \n",
       "\n",
       "    incident_state property_damage police_report_available  \n",
       "1               VA              NO                      NO  \n",
       "2               NY              NO                      NO  \n",
       "3               OH              NO                      NO  \n",
       "12              SC             YES                      NO  \n",
       "13              SC              NO                      NO  \n",
       "..             ...             ...                     ...  \n",
       "991             WV              NO                      NO  \n",
       "992             OH             YES                     YES  \n",
       "995             NC             YES                      NO  \n",
       "998             NY              NO                     YES  \n",
       "999             WV              NO                      NO  \n",
       "\n",
       "[494 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_df = x_train.select_dtypes(include=['object'])\n",
    "categorical_test_df = x_test.select_dtypes(include=['object'])\n",
    "categorical_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma similar a lo hecho con las variables numéricas, aquí seleccionas solo las columnas categóricas de x_train y x_test, creando categorical_df y categorical_test_df, respectivamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(numeric_df)\n",
    "\n",
    "# Transform numeric features\n",
    "X_train_numeric_processed = scaler.transform(numeric_df)\n",
    "X_test_numeric_processed = scaler.transform(numeric_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos utilizando StandardScaler de sklearn.preprocessing para estandarizar las características numéricas de tu conjunto de datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con fit, calculas la media y la desviación estándar de cada característica numérica en el conjunto de datos de entrenamiento (numeric_df). Esta información se utiliza para transformar los datos (tanto de entrenamiento como de prueba) de manera que cada característica se estandarice. Es importante ajustar el escalador solo a los datos de entrenamiento para evitar el \"data leakage\" (fuga de información) del conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos sirve la transformación para regresiones logísticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder= OneHotEncoder()\n",
    "encoder.fit(categorical_df)\n",
    "\n",
    "X_train_categorical_processed = encoder.transform(categorical_df).toarray()\n",
    "X_test_categorical_processed = encoder.transform(categorical_test_df).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método fit calcula los parámetros necesarios para la estandarización (media y desviación estándar) para cada característica. Este ajuste se hace solo con los datos de entrenamiento para evitar el sesgo en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = np.concatenate((X_train_numeric_processed, X_train_categorical_processed), axis=1)\n",
    "X_test_processed = np.concatenate((X_test_numeric_processed, X_test_categorical_processed), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.09434431,  1.00363048, -0.05836942, ...,  1.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.22230055,  0.57166058, -0.64828307, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 0.4664728 ,  0.0316982 , -1.65435125, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.53637752, -0.94023409,  0.55363201, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.71936549,  0.24768315, -1.33920502, ...,  1.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.63230234, -0.50826418,  1.46083522, ...,  0.        ,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.094344</td>\n",
       "      <td>1.003630</td>\n",
       "      <td>-0.058369</td>\n",
       "      <td>-0.152141</td>\n",
       "      <td>-0.293080</td>\n",
       "      <td>-0.232773</td>\n",
       "      <td>0.674134</td>\n",
       "      <td>-0.467292</td>\n",
       "      <td>-0.492574</td>\n",
       "      <td>0.981601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.222301</td>\n",
       "      <td>0.571661</td>\n",
       "      <td>-0.648283</td>\n",
       "      <td>1.369268</td>\n",
       "      <td>1.418284</td>\n",
       "      <td>-0.232773</td>\n",
       "      <td>1.400945</td>\n",
       "      <td>2.227365</td>\n",
       "      <td>1.528676</td>\n",
       "      <td>1.437230</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.466473</td>\n",
       "      <td>0.031698</td>\n",
       "      <td>-1.654351</td>\n",
       "      <td>-0.152141</td>\n",
       "      <td>-0.293080</td>\n",
       "      <td>-0.232773</td>\n",
       "      <td>0.444962</td>\n",
       "      <td>-0.467292</td>\n",
       "      <td>-0.320275</td>\n",
       "      <td>-0.930605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.571259</td>\n",
       "      <td>-0.508264</td>\n",
       "      <td>-0.470222</td>\n",
       "      <td>-0.152141</td>\n",
       "      <td>-0.293080</td>\n",
       "      <td>-0.232773</td>\n",
       "      <td>0.372076</td>\n",
       "      <td>-0.467292</td>\n",
       "      <td>-0.833927</td>\n",
       "      <td>-0.930605</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.327087</td>\n",
       "      <td>-0.184287</td>\n",
       "      <td>-0.412624</td>\n",
       "      <td>-1.064986</td>\n",
       "      <td>-0.977625</td>\n",
       "      <td>-0.232773</td>\n",
       "      <td>-0.434069</td>\n",
       "      <td>-0.467292</td>\n",
       "      <td>1.423667</td>\n",
       "      <td>-0.930605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.806570</td>\n",
       "      <td>0.787646</td>\n",
       "      <td>0.208338</td>\n",
       "      <td>-1.064986</td>\n",
       "      <td>-0.977625</td>\n",
       "      <td>-1.048304</td>\n",
       "      <td>1.766281</td>\n",
       "      <td>-0.467292</td>\n",
       "      <td>-0.313411</td>\n",
       "      <td>-0.930605</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>-0.684625</td>\n",
       "      <td>-1.156219</td>\n",
       "      <td>0.527162</td>\n",
       "      <td>-0.152141</td>\n",
       "      <td>-0.293080</td>\n",
       "      <td>-0.232773</td>\n",
       "      <td>-0.031202</td>\n",
       "      <td>-0.467292</td>\n",
       "      <td>-0.808049</td>\n",
       "      <td>-0.930605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>-0.536378</td>\n",
       "      <td>-0.940234</td>\n",
       "      <td>0.553632</td>\n",
       "      <td>1.369268</td>\n",
       "      <td>1.418284</td>\n",
       "      <td>-0.232773</td>\n",
       "      <td>0.428291</td>\n",
       "      <td>-0.467292</td>\n",
       "      <td>-0.988428</td>\n",
       "      <td>-0.930605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.719365</td>\n",
       "      <td>0.247683</td>\n",
       "      <td>-1.339205</td>\n",
       "      <td>-1.064986</td>\n",
       "      <td>-0.977625</td>\n",
       "      <td>-0.232773</td>\n",
       "      <td>0.796829</td>\n",
       "      <td>-0.467292</td>\n",
       "      <td>1.493319</td>\n",
       "      <td>1.613024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>-0.632302</td>\n",
       "      <td>-0.508264</td>\n",
       "      <td>1.460835</td>\n",
       "      <td>-0.152141</td>\n",
       "      <td>-0.293080</td>\n",
       "      <td>-1.048304</td>\n",
       "      <td>0.577965</td>\n",
       "      <td>0.880036</td>\n",
       "      <td>-0.818814</td>\n",
       "      <td>0.328653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0    1.094344  1.003630 -0.058369 -0.152141 -0.293080 -0.232773  0.674134   \n",
       "1    0.222301  0.571661 -0.648283  1.369268  1.418284 -0.232773  1.400945   \n",
       "2    0.466473  0.031698 -1.654351 -0.152141 -0.293080 -0.232773  0.444962   \n",
       "3   -0.571259 -0.508264 -0.470222 -0.152141 -0.293080 -0.232773  0.372076   \n",
       "4   -0.327087 -0.184287 -0.412624 -1.064986 -0.977625 -0.232773 -0.434069   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "501  0.806570  0.787646  0.208338 -1.064986 -0.977625 -1.048304  1.766281   \n",
       "502 -0.684625 -1.156219  0.527162 -0.152141 -0.293080 -0.232773 -0.031202   \n",
       "503 -0.536378 -0.940234  0.553632  1.369268  1.418284 -0.232773  0.428291   \n",
       "504  0.719365  0.247683 -1.339205 -1.064986 -0.977625 -0.232773  0.796829   \n",
       "505 -0.632302 -0.508264  1.460835 -0.152141 -0.293080 -1.048304  0.577965   \n",
       "\n",
       "           7         8         9   ...   60   61   62   63   64   65   66  \\\n",
       "0   -0.467292 -0.492574  0.981601  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "1    2.227365  1.528676  1.437230  ...  1.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "2   -0.467292 -0.320275 -0.930605  ...  0.0  0.0  0.0  1.0  0.0  0.0  1.0   \n",
       "3   -0.467292 -0.833927 -0.930605  ...  1.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "4   -0.467292  1.423667 -0.930605  ...  0.0  0.0  0.0  0.0  1.0  0.0  1.0   \n",
       "..        ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "501 -0.467292 -0.313411 -0.930605  ...  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "502 -0.467292 -0.808049 -0.930605  ...  0.0  1.0  0.0  0.0  0.0  0.0  1.0   \n",
       "503 -0.467292 -0.988428 -0.930605  ...  0.0  0.0  0.0  1.0  0.0  0.0  1.0   \n",
       "504 -0.467292  1.493319  1.613024  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "505  0.880036 -0.818814  0.328653  ...  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "\n",
       "      67   68   69  \n",
       "0    1.0  0.0  1.0  \n",
       "1    0.0  1.0  0.0  \n",
       "2    0.0  1.0  0.0  \n",
       "3    0.0  1.0  0.0  \n",
       "4    0.0  0.0  1.0  \n",
       "..   ...  ...  ...  \n",
       "501  1.0  1.0  0.0  \n",
       "502  0.0  1.0  0.0  \n",
       "503  0.0  0.0  1.0  \n",
       "504  1.0  1.0  0.0  \n",
       "505  0.0  0.0  1.0  \n",
       "\n",
       "[506 rows x 70 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_test_processed = pd.DataFrame(X_test_processed)\n",
    "X_test_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     1\n",
       "2     0\n",
       "3     1\n",
       "12    0\n",
       "13    0\n",
       "Name: fraud_reported, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_samples = len(y_train)\n",
    "total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_sample = sum(y_train)\n",
    "fraud_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_fraud_sample = total_samples - fraud_sample\n",
    "non_fraud_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2408906882591093"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_fraud = fraud_sample/total_samples\n",
    "sample_fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0538666666666667"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8/(1-sample_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8302521008403362"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_probability = 0.2\n",
    "weight_fraud = desired_probability/sample_fraud\n",
    "weight_fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos combinando (concatenando) las características numéricas procesadas y las características categóricas procesadas para tus conjuntos de datos de entrenamiento y prueba. Luego, conviertes el resultado en un DataFrame de pandas. Este es un paso importante en la preparación de los datos para el modelado, ya que reúnes todas las características transformadas en un solo conjunto de datos. Veamos cada línea en detalle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "ols=linear_model.LinearRegression()\n",
    "ols.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.04844884e-02, -5.08938874e-02, -2.24828308e-03,  4.13384293e-01,\n",
       "       -4.06631814e-01,  2.04708734e-02,  7.01990619e-03,  3.39198209e-02,\n",
       "       -3.24489792e-04, -3.67238628e-03, -8.85373765e-03,  5.66054656e-03,\n",
       "        3.51116335e-02,  1.72325463e-02,  1.50887269e-02, -3.05572723e+12,\n",
       "        5.78096405e+11,  5.60659133e+11,  2.19229353e+12,  9.57849586e-03,\n",
       "        1.07141885e+12,  1.07141885e+12,  1.07141885e+12,  5.56481502e+11,\n",
       "        5.56481502e+11,  1.83605089e+11,  1.83605089e+11,  1.83605089e+11,\n",
       "        1.83605089e+11,  1.83605089e+11,  1.83605089e+11,  1.83605089e+11,\n",
       "        2.50298447e+10,  2.50298447e+10,  2.50298447e+10,  2.50298447e+10,\n",
       "        2.50298447e+10,  2.50298447e+10,  2.50298447e+10,  2.50298447e+10,\n",
       "        2.50298447e+10,  2.50298447e+10,  2.50298447e+10,  2.50298447e+10,\n",
       "        2.50298447e+10,  2.50298447e+10, -4.58714175e+11, -4.58714175e+11,\n",
       "       -4.58714175e+11, -4.58714175e+11,  6.09488169e+11,  6.09488169e+11,\n",
       "        6.09488169e+11,  6.09488169e+11,  1.60251926e+11,  1.60251926e+11,\n",
       "        1.60251926e+11,  1.60251926e+11,  1.60251926e+11, -1.51741909e+11,\n",
       "       -1.51741909e+11, -1.51741909e+11, -1.51741909e+11, -1.51741909e+11,\n",
       "       -1.51741909e+11, -1.51741909e+11,  6.19657641e+11,  6.19657641e+11,\n",
       "       -7.06159649e+11, -7.06159649e+11])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols.fit(X_train_processed, y_train).coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -0.,  1.,  0., -0., -0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,\n",
       "        0.,  0., -0.,  0.,  0.,  0.,  0.,  1., -0.,  0., -0.,  1.,  1.,\n",
       "       -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "       -0.,  1.,  0.,  0.,  0., -0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "        1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  1., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0., -0., -0.,  0.,  1., -0., -0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,\n",
       "        0.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0., -0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0., -0.,  0.,  0.,\n",
       "       -0.,  0.,  0., -0.,  0.,  0., -0.,  1.,  0.,  1.,  0.,  0.,  0.,\n",
       "        0.,  1.,  1., -0.,  0.,  1.,  1.,  1.,  0.,  0., -0.,  0.,  1.,\n",
       "        1.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,  0.,  1.,  1.,  0.,\n",
       "       -0.,  0.,  1.,  0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        1.,  0.,  0.,  0., -0.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  1.,\n",
       "        0.,  0., -0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        1., -0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
       "        1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0., -0.,  0.,  1.,  0.,\n",
       "        0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,  0.,  1.,\n",
       "        1.,  0.,  1.,  0.,  0., -0.,  0.,  0.,  0., -0., -0.,  0.,  1.,\n",
       "        0.,  0.,  1., -0.,  1.,  0.,  1., -0.,  0., -0.,  0., -0.,  0.,\n",
       "        0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
       "        0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "        0.,  0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        1.,  1.,  0., -0., -0.,  0.,  0., -0.,  0.,  1.,  1.,  0.,  0.,\n",
       "        0., -0.,  0.,  1.,  1.,  1.,  0., -0.,  0.,  0.,  1.,  0., -0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
       "       -0.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1., -0.,\n",
       "        1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
       "        1.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  0.,  0., -0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  1.,  0., -0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1., -0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,  0., -0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols_predictions = ols.predict(X_test_processed).round(0)\n",
    "ols_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21146245059288538"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse_ols=mean_squared_error(y_test, ols_predictions)\n",
    "mse_ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>-0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraud_reported</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>342</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0           -0.0   1.0\n",
       "fraud_reported            \n",
       "0                342    36\n",
       "1                 71    57"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols_ct=pd.crosstab(y_test, ols_predictions)\n",
    "ols_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09523809523809523"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of False Positives: The number of instances where the model incorrectly predicts fraud (positive class) when the true outcome is not fraud (negative class).\n",
    "\n",
    "#Number of Actual Negatives: The total number of instances where the true outcome is not fraud (negative class).\n",
    "\n",
    "#Type I Error Rate= \n",
    "# Number of False Positives/Number of Actual Negatives\n",
    "\n",
    "type1_ols=ols_ct.iloc[0,1]/(ols_ct.iloc[0,0]+ols_ct.iloc[0,1])\n",
    "type1_ols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5546875"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of False negatives: The number of instances where the model incorrectly predicts not fraud (negative class)\n",
    "\n",
    "#Number of actual Positives: Total number of instances where true outcome is fraud\n",
    "\n",
    "#Type II Error Rate= \n",
    "# Number of False Negatives/Number of Actual Positives\n",
    "\n",
    "type2_ols=ols_ct.iloc[1,0]/(ols_ct.iloc[1,1]+ols_ct.iloc[1,0])\n",
    "type2_ols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4453125"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy of fraud detecting\n",
    "#Correctly predicts fraud / Total fraud\n",
    "fraud_acc_ols = ols_ct.iloc[1,1] / (ols_ct.iloc[1,1]+ols_ct.iloc[1,0])\n",
    "fraud_acc_ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9047619047619048"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy of not fraud detecting\n",
    "#Correctly predicts not fraud / Total not fraud\n",
    "nfraud_acc_ols = ols_ct.iloc[0,0] / (ols_ct.iloc[0,1]+ols_ct.iloc[0,0])\n",
    "nfraud_acc_ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7885375494071146"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#R_pseudo\n",
    "r_ols=(ols_ct.iloc[0,0]+ols_ct.iloc[1,1])/(ols_ct.iloc[0,0]+ols_ct.iloc[0,1]+ols_ct.iloc[1,0]+ols_ct.iloc[1,1])\n",
    "r_ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "ridge=linear_model.Ridge()\n",
    "ridge.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.88706212e-02, -5.53796235e-02, -7.17203541e-03,  1.39858629e-01,\n",
       "       -1.34250784e-01,  2.22202052e-02,  7.88044335e-03,  3.21144866e-02,\n",
       "        8.58024396e-03, -2.86995985e-03, -1.38569305e-02, -2.58918415e-04,\n",
       "       -4.77235796e-02,  1.89619415e-02,  1.64390493e-02,  1.79466490e-02,\n",
       "       -1.37788241e-02, -3.51194730e-02,  3.76298178e-02,  1.42622535e-02,\n",
       "       -3.35082184e-03, -2.19141159e-02,  2.52649377e-02,  1.52088048e-03,\n",
       "       -1.52088048e-03, -9.49953153e-02,  1.01862898e-01, -2.84722588e-02,\n",
       "        3.52247676e-02,  3.33303965e-02, -5.11722682e-02,  4.22178053e-03,\n",
       "       -6.57546404e-02,  6.14910775e-02,  2.49889241e-03,  1.38018455e-01,\n",
       "        2.44796208e-02, -8.47139945e-02,  1.08118826e-01, -8.95656130e-02,\n",
       "        3.64567441e-03, -3.51511192e-02, -2.42402809e-02, -2.62080337e-03,\n",
       "       -3.27669114e-02, -3.43918368e-03, -2.94752789e-02,  8.09923388e-02,\n",
       "       -8.50064740e-02,  3.34894141e-02,  3.36818390e-01, -9.34731956e-02,\n",
       "       -9.67213670e-02, -1.46623827e-01,  6.31999395e-02,  1.85916352e-02,\n",
       "       -1.42316146e-01,  5.96600036e-02,  8.64568114e-04,  4.34484854e-02,\n",
       "       -4.49086411e-02, -2.16265787e-02,  1.36426442e-02,  2.95091022e-03,\n",
       "        3.05279012e-02, -2.40347211e-02, -2.16389412e-02,  2.16389412e-02,\n",
       "        2.65415146e-02, -2.65415146e-02])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.fit(X_train_processed, y_train).coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -0.,  1., -0., -0., -0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  1., -0.,  1., -0.,  1.,  1.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "       -0.,  1.,  0.,  1.,  0., -0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "        1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  0., -0.,  0.,\n",
       "        0.,  0., -0., -0.,  0.,  0., -0., -0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0., -0.,\n",
       "        0.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,\n",
       "        0.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0., -0.,  0.,  0.,\n",
       "       -0.,  0.,  0., -0.,  0.,  0., -0.,  1.,  0.,  1.,  0.,  0.,  0.,\n",
       "        0.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  0.,  0., -0.,  0.,  1.,\n",
       "        1.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,  0.,  1.,  1.,  0.,\n",
       "       -0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  1.,  0.,  0., -0.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0., -0., -0.,  1.,  0.,  0.,  1.,  0.,  1.,  1.,\n",
       "        0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        1., -0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
       "        1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0., -0.,  0.,  1.,  0.,\n",
       "        0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "        0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,  0.,  1.,\n",
       "        0.,  0.,  1., -0.,  1.,  0.,  1.,  0.,  0.,  0.,  0., -0.,  0.,\n",
       "        1.,  0.,  0.,  0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
       "        0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "        0., -0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        1.,  1.,  0.,  0., -0.,  0., -0., -0.,  0.,  1.,  1.,  0.,  0.,\n",
       "        0., -0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0., -0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
       "        0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,\n",
       "        1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
       "        1.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  0.,  0., -0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  1.,  0., -0.,  0.,  0.,  0.,  0.,\n",
       "        0., -0.,  0.,  0.,  0.,  0.,  0., -0.,  1., -0.,  0.,  1.,  0.,\n",
       "        0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -0.,  0.,  1.,  0.,\n",
       "        0.,  0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_predictions = ridge.predict(X_test_processed).round(0)\n",
    "ridge_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19960474308300397"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_ridge=mean_squared_error(y_test, ridge_predictions)\n",
    "mse_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>-0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraud_reported</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>342</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0           -0.0   1.0\n",
       "fraud_reported            \n",
       "0                342    36\n",
       "1                 65    63"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_ct=pd.crosstab(y_test, ridge_predictions)\n",
    "ridge_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09523809523809523"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of False Positives: The number of instances where the model incorrectly predicts fraud (positive class) when the true outcome is not fraud (negative class).\n",
    "\n",
    "#Number of Actual Negatives: The total number of instances where the true outcome is not fraud (negative class).\n",
    "\n",
    "#Type I Error Rate= \n",
    "# Number of False Positives/Number of Actual Negatives\n",
    "\n",
    "type1_ridge=ridge_ct.iloc[0,1]/(ridge_ct.iloc[0,0]+ridge_ct.iloc[0,1])\n",
    "type1_ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5078125"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of False negatives: The number of instances where the model incorrectly predicts not fraud (negative class)\n",
    "\n",
    "#Number of actual Positives: Total number of instances where true outcome is fraud\n",
    "\n",
    "#Type II Error Rate= \n",
    "# Number of False Negatives/Number of Actual Positives\n",
    "\n",
    "type2_ridge=ridge_ct.iloc[1,0]/(ridge_ct.iloc[1,1]+ridge_ct.iloc[1,0])\n",
    "type2_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4921875"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy of fraud detecting\n",
    "#Correctly predicts fraud / Total fraud\n",
    "fraud_acc_ridge = ridge_ct.iloc[1,1] / (ridge_ct.iloc[1,1]+ridge_ct.iloc[1,0])\n",
    "fraud_acc_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9047619047619048"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy of not fraud detecting\n",
    "#Correctly predicts not fraud / Total not fraud\n",
    "nfraud_acc_ridge = ridge_ct.iloc[0,0] / (ridge_ct.iloc[0,1]+ridge_ct.iloc[0,0])\n",
    "nfraud_acc_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8003952569169961"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#R_pseudo\n",
    "r_ridge=(ridge_ct.iloc[0,0]+ridge_ct.iloc[1,1])/(ridge_ct.iloc[0,0]+ridge_ct.iloc[0,1]+ridge_ct.iloc[1,0]+ridge_ct.iloc[1,1])\n",
    "r_ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "logit=linear_model.LogisticRegression()\n",
    "logit.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.47606596e-01, -3.46809907e-01, -5.99580770e-02,\n",
       "         3.73247533e-01, -3.30028846e-01,  1.74364907e-01,\n",
       "         3.81879811e-02,  2.34080582e-01,  5.91988603e-02,\n",
       "        -3.55173419e-02, -8.61852067e-02, -1.00628575e-02,\n",
       "        -1.97146281e-01,  1.50757506e-01,  1.22366258e-01,\n",
       "         9.31170227e-02, -9.50837526e-02, -2.47885849e-01,\n",
       "         2.18258758e-01,  9.79727526e-02, -5.90375835e-02,\n",
       "        -1.19088001e-01,  1.79079344e-01,  6.02519788e-04,\n",
       "         3.51239849e-04, -7.12171109e-01,  6.05169972e-01,\n",
       "        -1.27389001e-01,  2.53628855e-01,  2.69669696e-01,\n",
       "        -2.75945653e-01, -1.20090009e-02, -5.54710698e-01,\n",
       "         4.79217531e-01, -1.00556756e-02,  7.38935351e-01,\n",
       "         7.38799568e-02, -4.07268391e-01,  7.13166289e-01,\n",
       "        -6.58792187e-01,  2.23337900e-02, -1.70206052e-01,\n",
       "        -1.01835977e-01,  2.41781522e-02, -1.49587808e-01,\n",
       "         1.69947836e-03, -1.05676660e-01,  2.93499487e-01,\n",
       "        -2.16151548e-01,  2.92824804e-02,  1.75023574e+00,\n",
       "        -5.02324959e-01, -5.71878943e-01, -6.75078075e-01,\n",
       "         4.60205327e-01,  1.34171678e-01, -9.95779369e-01,\n",
       "         3.59661257e-01,  4.26948669e-02,  3.07408954e-01,\n",
       "        -4.34765016e-01, -1.41023358e-01,  1.54780133e-01,\n",
       "         3.41301413e-02,  1.73410519e-01, -9.29876128e-02,\n",
       "        -1.57588887e-01,  1.58542646e-01,  1.84944525e-01,\n",
       "        -1.83990765e-01]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train_processed, y_train).coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_predictions = logit.predict(X_test_processed)\n",
    "logit_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2134387351778656"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_logit=mean_squared_error(y_test, logit_predictions)\n",
    "mse_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraud_reported</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>341</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0             0   1\n",
       "fraud_reported         \n",
       "0               341  37\n",
       "1                71  57"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_ct=pd.crosstab(y_test, logit_predictions)\n",
    "logit_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model incorrectly predicts fraud\n",
    "logit_ct.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model correctly predicts fraud\n",
    "logit_ct.iloc[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model incorrectly predicts not fraud\n",
    "logit_ct.iloc[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model correctly predicts not fraud\n",
    "logit_ct.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09788359788359788"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of False Positives: Model incorrectly predicts fraud (positive class) when the true outcome is not fraud (negative class).\n",
    "\n",
    "#Number of Actual Negatives: The total true not fraud (negative class).\n",
    "\n",
    "#Type I Error Rate= \n",
    "# Number of False Positives/Number of Actual Negatives\n",
    "# Model incorrecly predicts fraud / Total not fraud\n",
    "\n",
    "type1_logit=logit_ct.iloc[0,1]/(logit_ct.iloc[0,0]+logit_ct.iloc[0,1])\n",
    "type1_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5546875"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of False negatives: The number of instances where the model incorrectly predicts not fraud (negative class)\n",
    "\n",
    "#Number of actual Positives: Total number of instances where true outcome is fraud\n",
    "\n",
    "#Type II Error Rate= \n",
    "# Number of False Negatives/Number of Actual Positives\n",
    "# Model incorrecly predicts Not fraud / Total fraud\n",
    "\n",
    "type2_logit=logit_ct.iloc[1,0]/(logit_ct.iloc[1,1]+logit_ct.iloc[1,0])\n",
    "type2_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4453125"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy of fraud detecting\n",
    "#Correctly predicts fraud / Total fraud\n",
    "fraud_acc_logit = logit_ct.iloc[1,1] / (logit_ct.iloc[1,1]+logit_ct.iloc[1,0])\n",
    "fraud_acc_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9021164021164021"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy of not fraud detecting\n",
    "#Correctly predicts not fraud / Total not fraud\n",
    "nfraud_acc_logit = logit_ct.iloc[0,0] / (logit_ct.iloc[0,1]+logit_ct.iloc[0,0])\n",
    "nfraud_acc_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7865612648221344"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#R_pseudo\n",
    "r_logit=(logit_ct.iloc[0,0]+logit_ct.iloc[1,1])/(logit_ct.iloc[0,0]+logit_ct.iloc[0,1]+logit_ct.iloc[1,0]+logit_ct.iloc[1,1])\n",
    "r_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lasso_logit=linear_model.LogisticRegression(penalty='l1', solver='liblinear' )\n",
    "lasso_logit.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.29239785, -0.19015861, -0.02710468,  0.02917521,  0.        ,\n",
       "         0.16720366,  0.01507036,  0.23688327,  0.05573645, -0.02124459,\n",
       "        -0.0720296 ,  0.        , -0.15190913,  0.12876624,  0.09338855,\n",
       "         0.        , -0.06805997, -0.18004986,  0.15358562,  0.07456155,\n",
       "        -0.15121458, -0.16889272,  0.        ,  0.        ,  0.        ,\n",
       "        -0.76900884,  0.36349893, -0.15815474,  0.04553902,  0.        ,\n",
       "        -0.33018504, -0.00515039, -0.38392516,  0.36851936,  0.        ,\n",
       "         0.74011154,  0.        , -0.23361906,  0.62315139, -0.49164996,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         2.23912603,  0.        ,  0.        ,  0.        ,  0.06929936,\n",
       "        -0.11876291, -1.0939438 ,  0.        , -0.208867  ,  0.07755109,\n",
       "        -0.46099384,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -0.08854042, -0.3293645 ,  0.        ,  0.        , -0.30950152]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_logit.fit(X_train_processed, y_train).coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_logit_predictions = lasso_logit.predict(X_test_processed)\n",
    "lasso_logit_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20948616600790515"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_lasso_logit=mean_squared_error(y_test, lasso_logit_predictions)\n",
    "mse_lasso_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraud_reported</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>341</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0             0   1\n",
       "fraud_reported         \n",
       "0               341  37\n",
       "1                69  59"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_logit_ct=pd.crosstab(y_test, lasso_logit_predictions)\n",
    "lasso_logit_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09788359788359788"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of False Positives: The number of instances where the model incorrectly predicts default (positive class) when the true outcome is not default (negative class).\n",
    "\n",
    "#Number of Actual Negatives: The total number of instances where the true outcome is not default (negative class).\n",
    "\n",
    "#Type I Error Rate= \n",
    "# Number of False Positives/Number of Actual Negatives\n",
    "\n",
    "type1_lasso_logit=lasso_logit_ct.iloc[0,1]/(lasso_logit_ct.iloc[0,0]+lasso_logit_ct.iloc[0,1])\n",
    "type1_lasso_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5390625"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of False negatives: The number of instances where the model incorrectly predicts not fraud (negative class)\n",
    "\n",
    "#Number of actual Positives: Total number of instances where true outcome is fraud\n",
    "\n",
    "#Type II Error Rate= \n",
    "# Number of False Negatives/Number of Actual Positives\n",
    "\n",
    "type2_lasso_logit=lasso_logit_ct.iloc[1,0]/(lasso_logit_ct.iloc[1,1]+lasso_logit_ct.iloc[1,0])\n",
    "type2_lasso_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4609375"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy of fraud detecting\n",
    "#Correctly predicts fraud / Total fraud\n",
    "fraud_acc_lasso_logit = lasso_logit_ct.iloc[1,1] / (lasso_logit_ct.iloc[1,1]+lasso_logit_ct.iloc[1,0])\n",
    "fraud_acc_lasso_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9021164021164021"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy of not fraud detecting\n",
    "#Correctly predicts not fraud / Total not fraud\n",
    "nfraud_acc_lasso_logit = lasso_logit_ct.iloc[0,0] / (lasso_logit_ct.iloc[0,1]+lasso_logit_ct.iloc[0,0])\n",
    "nfraud_acc_lasso_logit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7905138339920948"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#R_pseudo\n",
    "r_lasso_logit=(lasso_logit_ct.iloc[0,0]+lasso_logit_ct.iloc[1,1])/(lasso_logit_ct.iloc[0,0]+lasso_logit_ct.iloc[0,1]+lasso_logit_ct.iloc[1,0]+lasso_logit_ct.iloc[1,1])\n",
    "r_lasso_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=8)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_estimators = int(np.sqrt(X_train_processed.shape[1]))\n",
    "\n",
    "# Initialize Random Forest classifier with the calculated number of estimators\n",
    "rf = RandomForestClassifier(n_estimators=n_estimators )\n",
    "\n",
    "# Train the classifier\n",
    "rf.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_predictions=rf.predict(X_test_processed)\n",
    "rf_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22924901185770752"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_rf=mean_squared_error(y_test, rf_predictions)\n",
    "mse_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraud_reported</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>362</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0             0   1\n",
       "fraud_reported         \n",
       "0               362  16\n",
       "1               100  28"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_ct=pd.crosstab(y_test, rf_predictions)\n",
    "rf_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.042328042328042326"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type1_rf=rf_ct.iloc[0,1]/(rf_ct.iloc[0,0]+rf_ct.iloc[0,1])\n",
    "type1_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78125"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type2_rf=rf_ct.iloc[1,0]/(rf_ct.iloc[1,1]+rf_ct.iloc[1,0])\n",
    "type2_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21875"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy of fraud detecting\n",
    "#Correctly predicts fraud / Total fraud\n",
    "fraud_acc_rf = rf_ct.iloc[1,1] / (rf_ct.iloc[1,1]+rf_ct.iloc[1,0])\n",
    "fraud_acc_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9576719576719577"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy of not fraud detecting\n",
    "#Correctly predicts not fraud / Total not fraud\n",
    "nfraud_acc_rf = rf_ct.iloc[0,0] / (rf_ct.iloc[0,1]+rf_ct.iloc[0,0])\n",
    "nfraud_acc_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7707509881422925"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#R_pseudo\n",
    "r_rf=(rf_ct.iloc[0,0]+rf_ct.iloc[1,1])/(rf_ct.iloc[0,0]+rf_ct.iloc[0,1]+rf_ct.iloc[1,0]+rf_ct.iloc[1,1])\n",
    "r_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraud</th>\n",
       "      <th>OLS</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>Logit</th>\n",
       "      <th>Lasso_Logit</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Fraud  OLS  Ridge  Logit  Lasso_Logit  Random Forest\n",
       "0        1  1.0    1.0      1            1              1\n",
       "4        0 -0.0   -0.0      0            0              0\n",
       "5        1  1.0    1.0      1            1              0\n",
       "6        0  0.0   -0.0      0            0              0\n",
       "7        0 -0.0   -0.0      0            0              0\n",
       "..     ...  ...    ...    ...          ...            ...\n",
       "988      0  0.0    0.0      0            0              0\n",
       "993      0  0.0    0.0      0            0              0\n",
       "994      0  0.0    0.0      0            0              0\n",
       "996      0  1.0    1.0      1            1              1\n",
       "997      0  0.0    0.0      0            0              0\n",
       "\n",
       "[506 rows x 6 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data={'Fraud': y_test,\n",
    "    'OLS': ols_predictions,\n",
    "    'Ridge': ridge_predictions,\n",
    "    'Logit': logit_predictions,\n",
    "    'Lasso_Logit': lasso_logit_predictions,\n",
    "    'Random Forest': rf_predictions\n",
    "          }\n",
    "\n",
    "\n",
    "test_df = pd.DataFrame(test_data)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El MSE es una medida del promedio de los cuadrados de los errores, es decir, la diferencia promedio al cuadrado entre los valores observados y los valores predichos por el modelo. Cuanto menor sea el MSE, mejor será el modelo en términos de precisión.\n",
    "\n",
    "El Pseudo R-cuadrado es una medida que intenta proporcionar una interpretación similar al R-cuadrado para modelos que no son de mínimos cuadrados ordinarios, como la regresión logística. No se interpreta exactamente de la misma manera que el R-cuadrado en la regresión lineal, pero un valor más alto generalmente indica un mejor ajuste del modelo.\n",
    "\n",
    "Error de Tipo 1 (Falsos Positivos): Un alto error de Tipo 1 significa que el modelo está identificando incorrectamente transacciones legítimas como fraudulentas. Esto puede ser costoso y molesto para los clientes legítimos y puede dañar la relación con los clientes y la reputación de la compañía de seguros. Predice que hay fraude, cuando no hay fraude.\n",
    "\n",
    "El error de Tipo 2 se refiere a la tasa de falsos negativos, es decir, cuántas veces un modelo no logra detectar un evento (como el fraude) cuando en realidad sí ocurrió. Esto puede resultar en pérdidas financieras significativas para la compañía de seguros si los reclamos fraudulentos no se detectan. Predice que no hay fraude, cuando hay fraude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Pseudo R^2</th>\n",
       "      <th>Fraud prediction accuracy</th>\n",
       "      <th>Type 2 error</th>\n",
       "      <th>Not Fraud prediction accuracy</th>\n",
       "      <th>Type 1 error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>0.211462</td>\n",
       "      <td>0.788538</td>\n",
       "      <td>0.445312</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RIDGE</td>\n",
       "      <td>0.199605</td>\n",
       "      <td>0.800395</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOGIT</td>\n",
       "      <td>0.213439</td>\n",
       "      <td>0.786561</td>\n",
       "      <td>0.445312</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.902116</td>\n",
       "      <td>0.097884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LASSO LOGIT</td>\n",
       "      <td>0.209486</td>\n",
       "      <td>0.790514</td>\n",
       "      <td>0.460938</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.902116</td>\n",
       "      <td>0.097884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RANDOM FOREST</td>\n",
       "      <td>0.229249</td>\n",
       "      <td>0.770751</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.957672</td>\n",
       "      <td>0.042328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model       MSE  Pseudo R^2  Fraud prediction accuracy  \\\n",
       "0            OLS  0.211462    0.788538                   0.445312   \n",
       "1          RIDGE  0.199605    0.800395                   0.492188   \n",
       "2          LOGIT  0.213439    0.786561                   0.445312   \n",
       "3    LASSO LOGIT  0.209486    0.790514                   0.460938   \n",
       "4  RANDOM FOREST  0.229249    0.770751                   0.218750   \n",
       "\n",
       "   Type 2 error  Not Fraud prediction accuracy  Type 1 error  \n",
       "0      0.554688                       0.904762      0.095238  \n",
       "1      0.507812                       0.904762      0.095238  \n",
       "2      0.554688                       0.902116      0.097884  \n",
       "3      0.539062                       0.902116      0.097884  \n",
       "4      0.781250                       0.957672      0.042328  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_values=[mse_ols, mse_ridge, mse_logit, mse_lasso_logit, mse_rf]\n",
    "pseudo_r2=[r_ols, r_ridge, r_logit,r_lasso_logit, r_rf]\n",
    "type1=[type1_ols, type1_ridge, type1_logit, type1_lasso_logit, type1_rf]\n",
    "type2=[type2_ols, type2_ridge, type2_logit, type2_lasso_logit, type2_rf]\n",
    "fraud_acc=[fraud_acc_ols, fraud_acc_ridge, fraud_acc_logit, fraud_acc_lasso_logit, fraud_acc_rf]\n",
    "nfraud_acc=[nfraud_acc_ols, nfraud_acc_ridge, nfraud_acc_logit, nfraud_acc_lasso_logit, nfraud_acc_rf]\n",
    "\n",
    "model_names=['OLS', 'RIDGE', 'LOGIT', 'LASSO LOGIT', 'RANDOM FOREST']\n",
    "summary_df = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'MSE': mse_values,\n",
    "    'Pseudo R^2': pseudo_r2,\n",
    "    'Fraud prediction accuracy': fraud_acc, \n",
    "    'Type 2 error': type2, \n",
    "    'Not Fraud prediction accuracy': nfraud_acc,\n",
    "    'Type 1 error': type1\n",
    "    \n",
    "})\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Conclusions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si analizando los modelos:\n",
    "\n",
    "1.-\n",
    "RIDGE tiene el menor MSE y el mayor Pseudo R-cuadrado, lo que sugiere que es el mejor en términos de ajuste del modelo y precisión. Además, es el segundo modelo con menor error tipo 1. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.- OLS es el modelo que minimiza el error tipo 2, es decir, es el modelo que con mayor precisión predice fraude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.-RANDOM FOREST tiene la tasa de error de Tipo 1 más baja, lo que indica que cuando identifica un caso como \"No fraude\", es más probable que realmente no lo sea. Es el modelo que predice con mayor precisión el \"no fraude\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dada la naturaleza del problema, queremos un modelo que equilibre la detección precisa del fraude (bajo error de Tipo 2) con una cantidad manejable de falsos positivos (error de Tipo 1), pero nos interesa más que minimice el error tipo 2, ya que la prima por tener el seguro es menor a la cantidad que se paga en caso de siniestro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ese motivo, es importante hacer el análisis en términos de dinero y en los beneficios monetarios que cada modelo brinda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In $ terms\n",
    "\n",
    "**Whatever prediction I make, I won´t pay for the investigation costs: private detectives, interviews, administrative expenses, transportation costs, manpower.**\n",
    "\n",
    "**If I predict fraud, I won´t pay the total claim and I will lose a customer, as none of the parties would like to work with each other anymore.**\n",
    "\n",
    "If I correctly predict fraud, I will gain the \"Total claim amount\"\n",
    "(I didn´t pay when I shouldn´t have). \n",
    "\n",
    "If incorrectly predict fraud (type 1), I will face legal action and, eventually, pay the Total Claim amount (I didn´t pay when I should have).\n",
    "\n",
    "**If I predict not fraud, I will pay**\n",
    "\n",
    "If I correctly predict not fraud, I will \"not lose\" (gain) the policy annual premium\n",
    "(I paid when I should have)\n",
    "\n",
    "If I incorrectly predict not fraud (type 2), I will lose the \"Total claim amount\" (because I shouldn´t be paying it)\n",
    "(I paid when I shouldn´t have)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefit\n",
    "\n",
    "Whatever prediction, I won´t spend on additional investigation\n",
    "\n",
    "If the prediction is \"not fraud\" the outcome would be the same as if the model had never been implemented .\n",
    "\n",
    "If the prediction is \"fraud\", I won´t pay, but I will lose a customer. There will be incremental flows: the incremental gain is when I correctly predict fraud, but the incremental loss is when I incorrectly predict fraud .\n",
    "\n",
    "**gain:   total claim when fraud * probability of accurately predicting fraud  + total investigation costs**\n",
    "\n",
    "**loss:   total annual premium when fraud + (total claim amount + legal fees)* probability of incorrectly predicting fraud (type 1)**\n",
    "\n",
    "Economical Benefit = gain - loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7854800"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wacc = 0.0764\n",
    "#Total claim when fraud occurred\n",
    "total_claim = x_test.loc[y_test == 1, 'total_claim_amount'].sum()\n",
    "total_claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2102675.3926701574"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total premium when fraud ocurred\n",
    "total_policy =((x_test.loc[y_test ==1, 'policy_annual_premium'])/wacc).sum()\n",
    "total_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278300"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total investigation costs = 500 dollares per incident (median of the range [400,700])\n",
    "#Includes private detectives, interviews, administrative expenses, transportation costs, manpower, etc.**\n",
    "total_investigation_costs = y_test.count() * 550\n",
    "total_investigation_costs \n",
    "#(506) * 550"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Legal fees are assumed to be proportional to the size of the claim\n",
    "#In this case, we assume that legal fees are ina range of 33% and 40% of the total claim, we decided to use the median\n",
    "legal_fees = 0.365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fraud prediction accuracy</th>\n",
       "      <th>Type 2 error</th>\n",
       "      <th>Not Fraud prediction accuracy</th>\n",
       "      <th>Type 1 error</th>\n",
       "      <th>Gain</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Benefit in thousands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>0.445312</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>3776.140625</td>\n",
       "      <td>3123.799393</td>\n",
       "      <td>652.341232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RIDGE</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>4144.334375</td>\n",
       "      <td>3123.799393</td>\n",
       "      <td>1020.534982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOGIT</td>\n",
       "      <td>0.445312</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.902116</td>\n",
       "      <td>0.097884</td>\n",
       "      <td>3776.140625</td>\n",
       "      <td>3152.163948</td>\n",
       "      <td>623.976677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LASSO LOGIT</td>\n",
       "      <td>0.460938</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.902116</td>\n",
       "      <td>0.097884</td>\n",
       "      <td>3898.871875</td>\n",
       "      <td>3152.163948</td>\n",
       "      <td>746.707927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RANDOM FOREST</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.957672</td>\n",
       "      <td>0.042328</td>\n",
       "      <td>1996.537500</td>\n",
       "      <td>2556.508282</td>\n",
       "      <td>-559.970782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Fraud prediction accuracy  Type 2 error  \\\n",
       "0            OLS                   0.445312      0.554688   \n",
       "1          RIDGE                   0.492188      0.507812   \n",
       "2          LOGIT                   0.445312      0.554688   \n",
       "3    LASSO LOGIT                   0.460938      0.539062   \n",
       "4  RANDOM FOREST                   0.218750      0.781250   \n",
       "\n",
       "   Not Fraud prediction accuracy  Type 1 error         Gain         Loss  \\\n",
       "0                       0.904762      0.095238  3776.140625  3123.799393   \n",
       "1                       0.904762      0.095238  4144.334375  3123.799393   \n",
       "2                       0.902116      0.097884  3776.140625  3152.163948   \n",
       "3                       0.902116      0.097884  3898.871875  3152.163948   \n",
       "4                       0.957672      0.042328  1996.537500  2556.508282   \n",
       "\n",
       "   Benefit in thousands  \n",
       "0            652.341232  \n",
       "1           1020.534982  \n",
       "2            623.976677  \n",
       "3            746.707927  \n",
       "4           -559.970782  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gain = [  (total_claim*fraud_acc_ols + total_investigation_costs)/10**3, \n",
    "          (total_claim*fraud_acc_ridge + total_investigation_costs)/10**3,\n",
    "          (total_claim*fraud_acc_logit + total_investigation_costs)/10**3,\n",
    "          (total_claim*fraud_acc_lasso_logit + total_investigation_costs)/10**3, \n",
    "          (total_claim*fraud_acc_rf + total_investigation_costs)/10**3]\n",
    "\n",
    "loss = [ ((1+legal_fees)*total_claim*type1_ols + total_policy)/10**3, \n",
    "           ((1+legal_fees)*total_claim*type1_ridge + total_policy)/10**3,\n",
    "         ((1+legal_fees)*total_claim*type1_logit + total_policy)/10**3,\n",
    "           ((1+legal_fees)*total_claim*type1_lasso_logit + total_policy)/10**3, \n",
    "          ((1+legal_fees)*total_claim*type1_rf + total_policy)/10**3]\n",
    "\n",
    "\n",
    "benefit = [(total_claim*fraud_acc_ols + total_investigation_costs - (1+legal_fees)*total_claim*type1_ols - total_policy)/10**3, \n",
    "          (total_claim*fraud_acc_ridge + total_investigation_costs - (1+legal_fees)*total_claim*type1_ridge - total_policy)/10**3,\n",
    "          (total_claim*fraud_acc_logit + total_investigation_costs - (1+legal_fees)*total_claim*type1_logit - total_policy)/10**3,\n",
    "          (total_claim*fraud_acc_lasso_logit + total_investigation_costs - (1+legal_fees)*total_claim*type1_lasso_logit - total_policy)/10**3, \n",
    "          (total_claim*fraud_acc_rf + total_investigation_costs - (1+legal_fees)*total_claim*type1_rf - total_policy)/10**3]\n",
    "\n",
    "             \n",
    "\n",
    "model_names=['OLS', 'RIDGE', 'LOGIT', 'LASSO LOGIT', 'RANDOM FOREST']\n",
    "summary_df = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Fraud prediction accuracy': fraud_acc, \n",
    "    'Type 2 error': type2, \n",
    "    'Not Fraud prediction accuracy': nfraud_acc,\n",
    "    'Type 1 error': type1,\n",
    "    'Gain': gain, \n",
    "    'Loss': loss,\n",
    "    'Benefit in thousands': benefit\n",
    "    \n",
    "    \n",
    "})\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Casos de fraude en test\n",
    "y_test.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pesar de que RIDGE no es el modelo que minimiza  el error tipo 1 o 2, es el modelo con menor MSE y es el \"segundo\" que mejor minimiza ambos errores. Por su buen ajuste, en general, y por su alta acertividad en predecir el fraude, RIDGE es el modelo que maximiza los beneficios económicos de la empresa.  \n",
    "\n",
    "En ese sentido, que la aseguradora use ese modelo le ayudará a ahorrar 894 mil de dólares por cada 128 casos de fraude, pues identifica el 50% de los fraudes.\n",
    "\n",
    "Si extrapolamos estos resultados y aplicamos el modelo a más de 128 casos, las ganancias aumentarán significativamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61365.625\n",
      "1255.0343749999997\n"
     ]
    }
   ],
   "source": [
    "c1 = x_test.loc[y_test == 1, 'total_claim_amount'].mean()\n",
    "p1 = x_test.loc[y_test == 1, 'policy_annual_premium'].mean()\n",
    "print(c1)\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming summary_df is already created as per your code\n",
    "# If not, make sure to create it first\n",
    "\n",
    "# Set the style for seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Define the metrics to plot\n",
    "metrics = ['Gain', 'Loss', 'Benefit in thousands']\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for ax, metric in zip(axes, metrics):\n",
    "    sns.barplot(x='Model', y=metric, data=summary_df, ax=ax, palette='viridis')\n",
    "    ax.set_title(f'{metric} by Model')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_xlabel('Model')\n",
    "    # Annotate bars with values\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f'{p.get_height():.2f}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                    ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Select the metrics to include in the grouped bar chart\n",
    "grouped_metrics = ['Gain', 'Loss', 'Benefit in thousands']\n",
    "\n",
    "# Melt the dataframe for seaborn\n",
    "melted_df = summary_df.melt(id_vars='Model', value_vars=grouped_metrics, var_name='Metric', value_name='Value')\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create the grouped bar chart\n",
    "sns.barplot(x='Model', y='Value', hue='Metric', data=melted_df, palette='Set2')\n",
    "\n",
    "# Set titles and labels\n",
    "plt.title('Comparison of Gain, Loss, and Benefit Across Models')\n",
    "plt.ylabel('Value (in thousands)')\n",
    "plt.xlabel('Model')\n",
    "plt.legend(title='Metric')\n",
    "\n",
    "# Annotate bars with values\n",
    "for container in plt.gca().containers:\n",
    "    plt.bar_label(container, fmt='%.2f', label_type='edge')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
