{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_initial_date</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>limit/person</th>\n",
       "      <th>limit_accident</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>...</th>\n",
       "      <th>property_damage</th>\n",
       "      <th>bodily_injuries</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>fraud_reported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>2014-10-17</td>\n",
       "      <td>OH</td>\n",
       "      <td>250</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>YES</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "      <td>71610</td>\n",
       "      <td>6510</td>\n",
       "      <td>13020</td>\n",
       "      <td>52080</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>IN</td>\n",
       "      <td>250</td>\n",
       "      <td>500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NO</td>\n",
       "      <td>5070</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>3510</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>687698</td>\n",
       "      <td>2000-09-06</td>\n",
       "      <td>OH</td>\n",
       "      <td>100</td>\n",
       "      <td>300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NO</td>\n",
       "      <td>34650</td>\n",
       "      <td>7700</td>\n",
       "      <td>3850</td>\n",
       "      <td>23100</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>227811</td>\n",
       "      <td>1990-05-25</td>\n",
       "      <td>IL</td>\n",
       "      <td>250</td>\n",
       "      <td>500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "      <td>63400</td>\n",
       "      <td>6340</td>\n",
       "      <td>6340</td>\n",
       "      <td>50720</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>367455</td>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>IL</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1583.91</td>\n",
       "      <td>6000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>6500</td>\n",
       "      <td>1300</td>\n",
       "      <td>650</td>\n",
       "      <td>4550</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   months_as_customer  age  policy_number policy_initial_date policy_state  \\\n",
       "0                 328   48         521585          2014-10-17           OH   \n",
       "1                 228   42         342868          2006-06-27           IN   \n",
       "2                 134   29         687698          2000-09-06           OH   \n",
       "3                 256   41         227811          1990-05-25           IL   \n",
       "4                 228   44         367455          2014-06-06           IL   \n",
       "\n",
       "   limit/person  limit_accident  policy_deductable  policy_annual_premium  \\\n",
       "0           250             500               1000                1406.91   \n",
       "1           250             500               2000                1197.22   \n",
       "2           100             300               2000                1413.14   \n",
       "3           250             500               2000                1415.74   \n",
       "4           500            1000               1000                1583.91   \n",
       "\n",
       "   umbrella_limit  ...  property_damage bodily_injuries witnesses  \\\n",
       "0               0  ...              YES               1         2   \n",
       "1         5000000  ...               NO               0         0   \n",
       "2         5000000  ...               NO               2         3   \n",
       "3         6000000  ...               NO               1         2   \n",
       "4         6000000  ...               NO               0         1   \n",
       "\n",
       "  police_report_available  total_claim_amount  injury_claim property_claim  \\\n",
       "0                     YES               71610          6510          13020   \n",
       "1                      NO                5070           780            780   \n",
       "2                      NO               34650          7700           3850   \n",
       "3                      NO               63400          6340           6340   \n",
       "4                      NO                6500          1300            650   \n",
       "\n",
       "  vehicle_claim auto_year fraud_reported  \n",
       "0         52080      2004              1  \n",
       "1          3510      2007              1  \n",
       "2         23100      2007              0  \n",
       "3         50720      2014              1  \n",
       "4          4550      2009              0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel('Insurancefraud.xlsx', sheet_name='Fraud')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fraud prediction accuracy</th>\n",
       "      <th>Type 2 error</th>\n",
       "      <th>Not Fraud prediction accuracy</th>\n",
       "      <th>Type 1 error</th>\n",
       "      <th>Benefit in thousands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>1020.534982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RIDGE</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>1020.534982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOGIT</td>\n",
       "      <td>0.445312</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.902116</td>\n",
       "      <td>0.097884</td>\n",
       "      <td>623.976677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LASSO LOGIT</td>\n",
       "      <td>0.460938</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.902116</td>\n",
       "      <td>0.097884</td>\n",
       "      <td>746.707927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RANDOM FOREST</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>-333.599809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Fraud prediction accuracy  Type 2 error  \\\n",
       "0            OLS                   0.492188      0.507812   \n",
       "1          RIDGE                   0.492188      0.507812   \n",
       "2          LOGIT                   0.445312      0.554688   \n",
       "3    LASSO LOGIT                   0.460938      0.539062   \n",
       "4  RANDOM FOREST                   0.265625      0.734375   \n",
       "\n",
       "   Not Fraud prediction accuracy  Type 1 error  Benefit in thousands  \n",
       "0                       0.904762      0.095238           1020.534982  \n",
       "1                       0.904762      0.095238           1020.534982  \n",
       "2                       0.902116      0.097884            623.976677  \n",
       "3                       0.902116      0.097884            746.707927  \n",
       "4                       0.944444      0.055556           -333.599809  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wacc = 0.0764\n",
    "np.random.seed(12345)\n",
    "desired_probability = 0.2\n",
    "\n",
    "df['Train']=[1 if np.random.uniform()<0.5 else 0 for _ in range(len(df))]\n",
    "df.head()\n",
    "\n",
    "x=df.drop(columns=['fraud_reported', 'Train'])\n",
    "y=df['fraud_reported']\n",
    "\n",
    "x_train = x[df['Train'] == 1]\n",
    "#It selects the rows on x, where the conditiomn is true\n",
    "x_test = x[df['Train'] == 0]\n",
    "#It selects the rows on x, where the conditiomn is true\n",
    "y_train = y[df['Train'] == 1]\n",
    "#It selects the rows on y, where the conditiomn is true\n",
    "y_test = y[df['Train'] == 0]\n",
    "#It selects the rows on y, where the conditiomn is true\n",
    "\n",
    "numeric_df = x_train.select_dtypes(include=['number'])\n",
    "numeric_test_df = x_test.select_dtypes(include=['number'])\n",
    "\n",
    "categorical_df = x_train.select_dtypes(include=['object'])\n",
    "categorical_test_df = x_test.select_dtypes(include=['object'])\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(numeric_df)\n",
    "\n",
    "# Transform numeric features\n",
    "X_train_numeric_processed = scaler.transform(numeric_df)\n",
    "X_test_numeric_processed = scaler.transform(numeric_test_df)\n",
    "\n",
    "encoder= OneHotEncoder()\n",
    "encoder.fit(categorical_df)\n",
    "\n",
    "X_train_categorical_processed = encoder.transform(categorical_df).toarray()\n",
    "X_test_categorical_processed = encoder.transform(categorical_test_df).toarray()\n",
    "\n",
    "X_train_processed = np.concatenate((X_train_numeric_processed, X_train_categorical_processed), axis=1)\n",
    "X_test_processed = np.concatenate((X_test_numeric_processed, X_test_categorical_processed), axis=1)\n",
    "\n",
    "total_samples = len(y_train)\n",
    "fraud_sample = sum(y_train)\n",
    "non_fraud_sample = total_samples - fraud_sample\n",
    "sample_fraud = fraud_sample/total_samples\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "ols=linear_model.LinearRegression()\n",
    "ols.fit(X_train_processed, y_train)\n",
    "\n",
    "ols_predictions = ols.predict(X_test_processed).round(0)\n",
    "ols_predictions\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_ols=mean_squared_error(y_test, ols_predictions)\n",
    "mse_ols\n",
    "\n",
    "ols_ct=pd.crosstab(y_test, ols_predictions)\n",
    "ols_ct\n",
    "\n",
    "type1_ols=ols_ct.iloc[0,1]/(ols_ct.iloc[0,0]+ols_ct.iloc[0,1])\n",
    "type1_ols\n",
    "type2_ols=ols_ct.iloc[1,0]/(ols_ct.iloc[1,1]+ols_ct.iloc[1,0])\n",
    "type2_ols\n",
    "fraud_acc_ols = ols_ct.iloc[1,1] / (ols_ct.iloc[1,1]+ols_ct.iloc[1,0])\n",
    "fraud_acc_ols\n",
    "nfraud_acc_ols = ols_ct.iloc[0,0] / (ols_ct.iloc[0,1]+ols_ct.iloc[0,0])\n",
    "nfraud_acc_ols\n",
    "\n",
    "r_ols=(ols_ct.iloc[0,0]+ols_ct.iloc[1,1])/(ols_ct.iloc[0,0]+ols_ct.iloc[0,1]+ols_ct.iloc[1,0]+ols_ct.iloc[1,1])\n",
    "r_ols\n",
    "\n",
    "from sklearn import linear_model\n",
    "ridge=linear_model.Ridge()\n",
    "ridge.fit(X_train_processed, y_train)\n",
    "\n",
    "ridge.fit(X_train_processed, y_train).coef_\n",
    "\n",
    "ridge_predictions = ridge.predict(X_test_processed).round(0)\n",
    "ridge_predictions\n",
    "mse_ridge=mean_squared_error(y_test, ridge_predictions)\n",
    "mse_ridge\n",
    "ridge_ct=pd.crosstab(y_test, ridge_predictions)\n",
    "ridge_ct\n",
    "\n",
    "type1_ridge=ridge_ct.iloc[0,1]/(ridge_ct.iloc[0,0]+ridge_ct.iloc[0,1])\n",
    "type1_ridge\n",
    "\n",
    "type2_ridge=ridge_ct.iloc[1,0]/(ridge_ct.iloc[1,1]+ridge_ct.iloc[1,0])\n",
    "type2_ridge\n",
    "fraud_acc_ridge = ridge_ct.iloc[1,1] / (ridge_ct.iloc[1,1]+ridge_ct.iloc[1,0])\n",
    "fraud_acc_ridge\n",
    "nfraud_acc_ridge = ridge_ct.iloc[0,0] / (ridge_ct.iloc[0,1]+ridge_ct.iloc[0,0])\n",
    "nfraud_acc_ridge\n",
    "r_ridge=(ridge_ct.iloc[0,0]+ridge_ct.iloc[1,1])/(ridge_ct.iloc[0,0]+ridge_ct.iloc[0,1]+ridge_ct.iloc[1,0]+ridge_ct.iloc[1,1])\n",
    "r_ridge\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "logit=linear_model.LogisticRegression()\n",
    "logit.fit(X_train_processed, y_train)\n",
    "logit_predictions = logit.predict(X_test_processed)\n",
    "logit_predictions\n",
    "\n",
    "mse_logit=mean_squared_error(y_test, logit_predictions)\n",
    "mse_logit\n",
    "\n",
    "logit_ct=pd.crosstab(y_test, logit_predictions)\n",
    "logit_ct\n",
    "\n",
    "type1_logit=logit_ct.iloc[0,1]/(logit_ct.iloc[0,0]+logit_ct.iloc[0,1])\n",
    "type1_logit\n",
    "\n",
    "type2_logit=logit_ct.iloc[1,0]/(logit_ct.iloc[1,1]+logit_ct.iloc[1,0])\n",
    "type2_logit\n",
    "\n",
    "fraud_acc_logit = logit_ct.iloc[1,1] / (logit_ct.iloc[1,1]+logit_ct.iloc[1,0])\n",
    "fraud_acc_logit\n",
    "\n",
    "nfraud_acc_logit = logit_ct.iloc[0,0] / (logit_ct.iloc[0,1]+logit_ct.iloc[0,0])\n",
    "nfraud_acc_logit\n",
    "\n",
    "r_logit=(logit_ct.iloc[0,0]+logit_ct.iloc[1,1])/(logit_ct.iloc[0,0]+logit_ct.iloc[0,1]+logit_ct.iloc[1,0]+logit_ct.iloc[1,1])\n",
    "r_logit\n",
    "\n",
    "from sklearn import linear_model\n",
    "lasso_logit=linear_model.LogisticRegression(penalty='l1', solver='liblinear')\n",
    "lasso_logit.fit(X_train_processed, y_train)\n",
    "\n",
    "lasso_logit_predictions = lasso_logit.predict(X_test_processed)\n",
    "lasso_logit_predictions\n",
    "\n",
    "mse_lasso_logit=mean_squared_error(y_test, lasso_logit_predictions)\n",
    "mse_lasso_logit\n",
    "\n",
    "lasso_logit_ct=pd.crosstab(y_test, lasso_logit_predictions)\n",
    "lasso_logit_ct\n",
    "\n",
    "type1_lasso_logit=lasso_logit_ct.iloc[0,1]/(lasso_logit_ct.iloc[0,0]+lasso_logit_ct.iloc[0,1])\n",
    "type1_lasso_logit\n",
    "\n",
    "type2_lasso_logit=lasso_logit_ct.iloc[1,0]/(lasso_logit_ct.iloc[1,1]+lasso_logit_ct.iloc[1,0])\n",
    "type2_lasso_logit\n",
    "fraud_acc_lasso_logit = lasso_logit_ct.iloc[1,1] / (lasso_logit_ct.iloc[1,1]+lasso_logit_ct.iloc[1,0])\n",
    "fraud_acc_lasso_logit\n",
    "nfraud_acc_lasso_logit = lasso_logit_ct.iloc[0,0] / (lasso_logit_ct.iloc[0,1]+lasso_logit_ct.iloc[0,0])\n",
    "nfraud_acc_lasso_logit \n",
    "\n",
    "r_lasso_logit=(lasso_logit_ct.iloc[0,0]+lasso_logit_ct.iloc[1,1])/(lasso_logit_ct.iloc[0,0]+lasso_logit_ct.iloc[0,1]+lasso_logit_ct.iloc[1,0]+lasso_logit_ct.iloc[1,1])\n",
    "r_lasso_logit\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_estimators = int(np.sqrt(X_train_processed.shape[1]))\n",
    "\n",
    "# Initialize Random Forest classifier with the calculated number of estimators\n",
    "rf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "\n",
    "# Train the classifier\n",
    "rf.fit(X_train_processed, y_train)\n",
    "\n",
    "rf_predictions=rf.predict(X_test_processed)\n",
    "rf_predictions\n",
    "\n",
    "mse_rf=mean_squared_error(y_test, rf_predictions)\n",
    "mse_rf\n",
    "\n",
    "rf_ct=pd.crosstab(y_test, rf_predictions)\n",
    "rf_ct\n",
    "\n",
    "type1_rf=rf_ct.iloc[0,1]/(rf_ct.iloc[0,0]+rf_ct.iloc[0,1])\n",
    "type1_rf\n",
    "\n",
    "type2_rf=rf_ct.iloc[1,0]/(rf_ct.iloc[1,1]+rf_ct.iloc[1,0])\n",
    "type2_rf\n",
    "\n",
    "fraud_acc_rf = rf_ct.iloc[1,1] / (rf_ct.iloc[1,1]+rf_ct.iloc[1,0])\n",
    "fraud_acc_rf\n",
    "\n",
    "nfraud_acc_rf = rf_ct.iloc[0,0] / (rf_ct.iloc[0,1]+rf_ct.iloc[0,0])\n",
    "nfraud_acc_rf\n",
    "\n",
    "r_rf=(rf_ct.iloc[0,0]+rf_ct.iloc[1,1])/(rf_ct.iloc[0,0]+rf_ct.iloc[0,1]+rf_ct.iloc[1,0]+rf_ct.iloc[1,1])\n",
    "r_rf\n",
    "\n",
    "mse_values=[mse_ols, mse_ridge, mse_logit, mse_lasso_logit, mse_rf]\n",
    "pseudo_r2=[r_ols, r_ridge, r_logit,r_lasso_logit, r_rf]\n",
    "type1=[type1_ols, type1_ridge, type1_logit, type1_lasso_logit, type1_rf]\n",
    "type2=[type2_ols, type2_ridge, type2_logit, type2_lasso_logit, type2_rf]\n",
    "fraud_acc=[fraud_acc_ols, fraud_acc_ridge, fraud_acc_logit, fraud_acc_lasso_logit, fraud_acc_rf]\n",
    "nfraud_acc=[nfraud_acc_ols, nfraud_acc_ridge, nfraud_acc_logit, nfraud_acc_lasso_logit, nfraud_acc_rf]\n",
    "\n",
    "total_claim = x_test.loc[y_test == 1, 'total_claim_amount'].sum()\n",
    "\n",
    "total_policy =((x_test.loc[y_test ==1, 'policy_annual_premium'])/wacc).sum()\n",
    "\n",
    "total_investigation_costs = y_test.count() * 550\n",
    "\n",
    "legal_fees = 0.365\n",
    "\n",
    "benefit = [(total_claim*fraud_acc_ols + total_investigation_costs - (1+legal_fees)*total_claim*type1_ols - total_policy)/10**3, \n",
    "          (total_claim*fraud_acc_ridge + total_investigation_costs - (1+legal_fees)*total_claim*type1_ridge - total_policy)/10**3,\n",
    "          (total_claim*fraud_acc_logit + total_investigation_costs - (1+legal_fees)*total_claim*type1_logit - total_policy)/10**3,\n",
    "          (total_claim*fraud_acc_lasso_logit + total_investigation_costs - (1+legal_fees)*total_claim*type1_lasso_logit - total_policy)/10**3, \n",
    "          (total_claim*fraud_acc_rf + total_investigation_costs - (1+legal_fees)*total_claim*type1_rf - total_policy)/10**3]\n",
    "\n",
    "model_names=['OLS', 'RIDGE', 'LOGIT', 'LASSO LOGIT', 'RANDOM FOREST']\n",
    "summary_df1 = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Fraud prediction accuracy': fraud_acc, \n",
    "    'Type 2 error': type2, \n",
    "    'Not Fraud prediction accuracy': nfraud_acc,\n",
    "    'Type 1 error': type1,\n",
    "    'Benefit in thousands': benefit})\n",
    "\n",
    "summary_df1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "f1 = y_test.sum()\n",
    "\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61365.625\n",
      "1255.0343750000002\n"
     ]
    }
   ],
   "source": [
    "c1 = x_test.loc[y_test == 1, 'total_claim_amount'].mean()\n",
    "p1 = x_test.loc[y_test == 1, 'policy_annual_premium'].mean()\n",
    "print(c1)\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fraud prediction accuracy</th>\n",
       "      <th>Type 2 error</th>\n",
       "      <th>Not Fraud prediction accuracy</th>\n",
       "      <th>Type 1 error</th>\n",
       "      <th>Benefit in thousands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>0.425197</td>\n",
       "      <td>0.574803</td>\n",
       "      <td>0.892761</td>\n",
       "      <td>0.107239</td>\n",
       "      <td>427.686446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RIDGE</td>\n",
       "      <td>0.425197</td>\n",
       "      <td>0.574803</td>\n",
       "      <td>0.898123</td>\n",
       "      <td>0.101877</td>\n",
       "      <td>485.026180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOGIT</td>\n",
       "      <td>0.370079</td>\n",
       "      <td>0.629921</td>\n",
       "      <td>0.906166</td>\n",
       "      <td>0.093834</td>\n",
       "      <td>139.222317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LASSO LOGIT</td>\n",
       "      <td>0.385827</td>\n",
       "      <td>0.614173</td>\n",
       "      <td>0.900804</td>\n",
       "      <td>0.099196</td>\n",
       "      <td>205.257858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RANDOM FOREST</td>\n",
       "      <td>0.259843</td>\n",
       "      <td>0.740157</td>\n",
       "      <td>0.932976</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>-437.705941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Fraud prediction accuracy  Type 2 error  \\\n",
       "0            OLS                   0.425197      0.574803   \n",
       "1          RIDGE                   0.425197      0.574803   \n",
       "2          LOGIT                   0.370079      0.629921   \n",
       "3    LASSO LOGIT                   0.385827      0.614173   \n",
       "4  RANDOM FOREST                   0.259843      0.740157   \n",
       "\n",
       "   Not Fraud prediction accuracy  Type 1 error  Benefit in thousands  \n",
       "0                       0.892761      0.107239            427.686446  \n",
       "1                       0.898123      0.101877            485.026180  \n",
       "2                       0.906166      0.093834            139.222317  \n",
       "3                       0.900804      0.099196            205.257858  \n",
       "4                       0.932976      0.067024           -437.705941  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wacc = 0.0764\n",
    "np.random.seed(56455)\n",
    "desired_probability = 0.2\n",
    "\n",
    "df['Train']=[1 if np.random.uniform()<0.5 else 0 for _ in range(len(df))]\n",
    "df.head()\n",
    "\n",
    "x=df.drop(columns=['fraud_reported', 'Train'])\n",
    "y=df['fraud_reported']\n",
    "\n",
    "x_train = x[df['Train'] == 1]\n",
    "#It selects the rows on x, where the conditiomn is true\n",
    "x_test = x[df['Train'] == 0]\n",
    "#It selects the rows on x, where the conditiomn is true\n",
    "y_train = y[df['Train'] == 1]\n",
    "#It selects the rows on y, where the conditiomn is true\n",
    "y_test = y[df['Train'] == 0]\n",
    "#It selects the rows on y, where the conditiomn is true\n",
    "\n",
    "numeric_df = x_train.select_dtypes(include=['number'])\n",
    "numeric_test_df = x_test.select_dtypes(include=['number'])\n",
    "\n",
    "categorical_df = x_train.select_dtypes(include=['object'])\n",
    "categorical_test_df = x_test.select_dtypes(include=['object'])\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(numeric_df)\n",
    "\n",
    "# Transform numeric features\n",
    "X_train_numeric_processed = scaler.transform(numeric_df)\n",
    "X_test_numeric_processed = scaler.transform(numeric_test_df)\n",
    "\n",
    "encoder= OneHotEncoder()\n",
    "encoder.fit(categorical_df)\n",
    "\n",
    "X_train_categorical_processed = encoder.transform(categorical_df).toarray()\n",
    "X_test_categorical_processed = encoder.transform(categorical_test_df).toarray()\n",
    "\n",
    "X_train_processed = np.concatenate((X_train_numeric_processed, X_train_categorical_processed), axis=1)\n",
    "X_test_processed = np.concatenate((X_test_numeric_processed, X_test_categorical_processed), axis=1)\n",
    "\n",
    "total_samples = len(y_train)\n",
    "fraud_sample = sum(y_train)\n",
    "non_fraud_sample = total_samples - fraud_sample\n",
    "sample_fraud = fraud_sample/total_samples\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "ols=linear_model.LinearRegression()\n",
    "ols.fit(X_train_processed, y_train)\n",
    "\n",
    "ols_predictions = ols.predict(X_test_processed).round(0)\n",
    "ols_predictions\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_ols=mean_squared_error(y_test, ols_predictions)\n",
    "mse_ols\n",
    "\n",
    "ols_ct=pd.crosstab(y_test, ols_predictions)\n",
    "ols_ct\n",
    "\n",
    "type1_ols=ols_ct.iloc[0,1]/(ols_ct.iloc[0,0]+ols_ct.iloc[0,1])\n",
    "type1_ols\n",
    "type2_ols=ols_ct.iloc[1,0]/(ols_ct.iloc[1,1]+ols_ct.iloc[1,0])\n",
    "type2_ols\n",
    "fraud_acc_ols = ols_ct.iloc[1,1] / (ols_ct.iloc[1,1]+ols_ct.iloc[1,0])\n",
    "fraud_acc_ols\n",
    "nfraud_acc_ols = ols_ct.iloc[0,0] / (ols_ct.iloc[0,1]+ols_ct.iloc[0,0])\n",
    "nfraud_acc_ols\n",
    "\n",
    "r_ols=(ols_ct.iloc[0,0]+ols_ct.iloc[1,1])/(ols_ct.iloc[0,0]+ols_ct.iloc[0,1]+ols_ct.iloc[1,0]+ols_ct.iloc[1,1])\n",
    "r_ols\n",
    "\n",
    "from sklearn import linear_model\n",
    "ridge=linear_model.Ridge()\n",
    "ridge.fit(X_train_processed, y_train)\n",
    "\n",
    "ridge.fit(X_train_processed, y_train).coef_\n",
    "\n",
    "ridge_predictions = ridge.predict(X_test_processed).round(0)\n",
    "ridge_predictions\n",
    "mse_ridge=mean_squared_error(y_test, ridge_predictions)\n",
    "mse_ridge\n",
    "ridge_ct=pd.crosstab(y_test, ridge_predictions)\n",
    "ridge_ct\n",
    "\n",
    "type1_ridge=ridge_ct.iloc[0,1]/(ridge_ct.iloc[0,0]+ridge_ct.iloc[0,1])\n",
    "type1_ridge\n",
    "\n",
    "type2_ridge=ridge_ct.iloc[1,0]/(ridge_ct.iloc[1,1]+ridge_ct.iloc[1,0])\n",
    "type2_ridge\n",
    "fraud_acc_ridge = ridge_ct.iloc[1,1] / (ridge_ct.iloc[1,1]+ridge_ct.iloc[1,0])\n",
    "fraud_acc_ridge\n",
    "nfraud_acc_ridge = ridge_ct.iloc[0,0] / (ridge_ct.iloc[0,1]+ridge_ct.iloc[0,0])\n",
    "nfraud_acc_ridge\n",
    "r_ridge=(ridge_ct.iloc[0,0]+ridge_ct.iloc[1,1])/(ridge_ct.iloc[0,0]+ridge_ct.iloc[0,1]+ridge_ct.iloc[1,0]+ridge_ct.iloc[1,1])\n",
    "r_ridge\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "logit=linear_model.LogisticRegression()\n",
    "logit.fit(X_train_processed, y_train)\n",
    "logit_predictions = logit.predict(X_test_processed)\n",
    "logit_predictions\n",
    "\n",
    "mse_logit=mean_squared_error(y_test, logit_predictions)\n",
    "mse_logit\n",
    "\n",
    "logit_ct=pd.crosstab(y_test, logit_predictions)\n",
    "logit_ct\n",
    "\n",
    "type1_logit=logit_ct.iloc[0,1]/(logit_ct.iloc[0,0]+logit_ct.iloc[0,1])\n",
    "type1_logit\n",
    "\n",
    "type2_logit=logit_ct.iloc[1,0]/(logit_ct.iloc[1,1]+logit_ct.iloc[1,0])\n",
    "type2_logit\n",
    "\n",
    "fraud_acc_logit = logit_ct.iloc[1,1] / (logit_ct.iloc[1,1]+logit_ct.iloc[1,0])\n",
    "fraud_acc_logit\n",
    "\n",
    "nfraud_acc_logit = logit_ct.iloc[0,0] / (logit_ct.iloc[0,1]+logit_ct.iloc[0,0])\n",
    "nfraud_acc_logit\n",
    "\n",
    "r_logit=(logit_ct.iloc[0,0]+logit_ct.iloc[1,1])/(logit_ct.iloc[0,0]+logit_ct.iloc[0,1]+logit_ct.iloc[1,0]+logit_ct.iloc[1,1])\n",
    "r_logit\n",
    "\n",
    "from sklearn import linear_model\n",
    "lasso_logit=linear_model.LogisticRegression(penalty='l1', solver='liblinear')\n",
    "lasso_logit.fit(X_train_processed, y_train)\n",
    "\n",
    "lasso_logit_predictions = lasso_logit.predict(X_test_processed)\n",
    "lasso_logit_predictions\n",
    "\n",
    "mse_lasso_logit=mean_squared_error(y_test, lasso_logit_predictions)\n",
    "mse_lasso_logit\n",
    "\n",
    "lasso_logit_ct=pd.crosstab(y_test, lasso_logit_predictions)\n",
    "lasso_logit_ct\n",
    "\n",
    "type1_lasso_logit=lasso_logit_ct.iloc[0,1]/(lasso_logit_ct.iloc[0,0]+lasso_logit_ct.iloc[0,1])\n",
    "type1_lasso_logit\n",
    "\n",
    "type2_lasso_logit=lasso_logit_ct.iloc[1,0]/(lasso_logit_ct.iloc[1,1]+lasso_logit_ct.iloc[1,0])\n",
    "type2_lasso_logit\n",
    "fraud_acc_lasso_logit = lasso_logit_ct.iloc[1,1] / (lasso_logit_ct.iloc[1,1]+lasso_logit_ct.iloc[1,0])\n",
    "fraud_acc_lasso_logit\n",
    "nfraud_acc_lasso_logit = lasso_logit_ct.iloc[0,0] / (lasso_logit_ct.iloc[0,1]+lasso_logit_ct.iloc[0,0])\n",
    "nfraud_acc_lasso_logit \n",
    "\n",
    "r_lasso_logit=(lasso_logit_ct.iloc[0,0]+lasso_logit_ct.iloc[1,1])/(lasso_logit_ct.iloc[0,0]+lasso_logit_ct.iloc[0,1]+lasso_logit_ct.iloc[1,0]+lasso_logit_ct.iloc[1,1])\n",
    "r_lasso_logit\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_estimators = int(np.sqrt(X_train_processed.shape[1]))\n",
    "\n",
    "# Initialize Random Forest classifier with the calculated number of estimators\n",
    "rf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "\n",
    "# Train the classifier\n",
    "rf.fit(X_train_processed, y_train)\n",
    "\n",
    "rf_predictions=rf.predict(X_test_processed)\n",
    "rf_predictions\n",
    "\n",
    "mse_rf=mean_squared_error(y_test, rf_predictions)\n",
    "mse_rf\n",
    "\n",
    "rf_ct=pd.crosstab(y_test, rf_predictions)\n",
    "rf_ct\n",
    "\n",
    "type1_rf=rf_ct.iloc[0,1]/(rf_ct.iloc[0,0]+rf_ct.iloc[0,1])\n",
    "type1_rf\n",
    "\n",
    "type2_rf=rf_ct.iloc[1,0]/(rf_ct.iloc[1,1]+rf_ct.iloc[1,0])\n",
    "type2_rf\n",
    "\n",
    "fraud_acc_rf = rf_ct.iloc[1,1] / (rf_ct.iloc[1,1]+rf_ct.iloc[1,0])\n",
    "fraud_acc_rf\n",
    "\n",
    "nfraud_acc_rf = rf_ct.iloc[0,0] / (rf_ct.iloc[0,1]+rf_ct.iloc[0,0])\n",
    "nfraud_acc_rf\n",
    "\n",
    "r_rf=(rf_ct.iloc[0,0]+rf_ct.iloc[1,1])/(rf_ct.iloc[0,0]+rf_ct.iloc[0,1]+rf_ct.iloc[1,0]+rf_ct.iloc[1,1])\n",
    "r_rf\n",
    "\n",
    "mse_values=[mse_ols, mse_ridge, mse_logit, mse_lasso_logit, mse_rf]\n",
    "pseudo_r2=[r_ols, r_ridge, r_logit,r_lasso_logit, r_rf]\n",
    "type1=[type1_ols, type1_ridge, type1_logit, type1_lasso_logit, type1_rf]\n",
    "type2=[type2_ols, type2_ridge, type2_logit, type2_lasso_logit, type2_rf]\n",
    "fraud_acc=[fraud_acc_ols, fraud_acc_ridge, fraud_acc_logit, fraud_acc_lasso_logit, fraud_acc_rf]\n",
    "nfraud_acc=[nfraud_acc_ols, nfraud_acc_ridge, nfraud_acc_logit, nfraud_acc_lasso_logit, nfraud_acc_rf]\n",
    "\n",
    "total_claim = x_test.loc[y_test == 1, 'total_claim_amount'].sum()\n",
    "\n",
    "total_policy =((x_test.loc[y_test ==1, 'policy_annual_premium'])/wacc).sum()\n",
    "\n",
    "total_investigation_costs = y_test.count() * 550\n",
    "\n",
    "legal_fees = 0.365\n",
    "\n",
    "benefit = [(total_claim*fraud_acc_ols + total_investigation_costs - (1+legal_fees)*total_claim*type1_ols - total_policy)/10**3, \n",
    "          (total_claim*fraud_acc_ridge + total_investigation_costs - (1+legal_fees)*total_claim*type1_ridge - total_policy)/10**3,\n",
    "          (total_claim*fraud_acc_logit + total_investigation_costs - (1+legal_fees)*total_claim*type1_logit - total_policy)/10**3,\n",
    "          (total_claim*fraud_acc_lasso_logit + total_investigation_costs - (1+legal_fees)*total_claim*type1_lasso_logit - total_policy)/10**3, \n",
    "          (total_claim*fraud_acc_rf + total_investigation_costs - (1+legal_fees)*total_claim*type1_rf - total_policy)/10**3]\n",
    "\n",
    "model_names=['OLS', 'RIDGE', 'LOGIT', 'LASSO LOGIT', 'RANDOM FOREST']\n",
    "summary_df2 = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Fraud prediction accuracy': fraud_acc, \n",
    "    'Type 2 error': type2, \n",
    "    'Not Fraud prediction accuracy': nfraud_acc,\n",
    "    'Type 1 error': type1,\n",
    "    'Benefit in thousands': benefit})\n",
    "\n",
    "summary_df2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n"
     ]
    }
   ],
   "source": [
    "f2 = y_test.sum()\n",
    "\n",
    "print(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61687.637795275594\n",
      "1222.1902362204723\n"
     ]
    }
   ],
   "source": [
    "c2 = x_test.loc[y_test == 1, 'total_claim_amount'].mean()\n",
    "p2 = x_test.loc[y_test == 1, 'policy_annual_premium'].mean()\n",
    "print(c2)\n",
    "print(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fraud prediction accuracy</th>\n",
       "      <th>Type 2 error</th>\n",
       "      <th>Not Fraud prediction accuracy</th>\n",
       "      <th>Type 1 error</th>\n",
       "      <th>Benefit in thousands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.905612</td>\n",
       "      <td>0.094388</td>\n",
       "      <td>895.224404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RIDGE</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.908163</td>\n",
       "      <td>0.091837</td>\n",
       "      <td>919.518514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOGIT</td>\n",
       "      <td>0.429825</td>\n",
       "      <td>0.570175</td>\n",
       "      <td>0.903061</td>\n",
       "      <td>0.096939</td>\n",
       "      <td>442.532136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LASSO LOGIT</td>\n",
       "      <td>0.412281</td>\n",
       "      <td>0.587719</td>\n",
       "      <td>0.915816</td>\n",
       "      <td>0.084184</td>\n",
       "      <td>441.603212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RANDOM FOREST</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.913265</td>\n",
       "      <td>0.086735</td>\n",
       "      <td>111.310418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Fraud prediction accuracy  Type 2 error  \\\n",
       "0            OLS                   0.491228      0.508772   \n",
       "1          RIDGE                   0.491228      0.508772   \n",
       "2          LOGIT                   0.429825      0.570175   \n",
       "3    LASSO LOGIT                   0.412281      0.587719   \n",
       "4  RANDOM FOREST                   0.368421      0.631579   \n",
       "\n",
       "   Not Fraud prediction accuracy  Type 1 error  Benefit in thousands  \n",
       "0                       0.905612      0.094388            895.224404  \n",
       "1                       0.908163      0.091837            919.518514  \n",
       "2                       0.903061      0.096939            442.532136  \n",
       "3                       0.915816      0.084184            441.603212  \n",
       "4                       0.913265      0.086735            111.310418  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wacc = 0.0764\n",
    "np.random.seed(2335312)\n",
    "desired_probability = 0.2\n",
    "\n",
    "df['Train']=[1 if np.random.uniform()<0.5 else 0 for _ in range(len(df))]\n",
    "df.head()\n",
    "\n",
    "x=df.drop(columns=['fraud_reported', 'Train'])\n",
    "y=df['fraud_reported']\n",
    "\n",
    "x_train = x[df['Train'] == 1]\n",
    "#It selects the rows on x, where the conditiomn is true\n",
    "x_test = x[df['Train'] == 0]\n",
    "#It selects the rows on x, where the conditiomn is true\n",
    "y_train = y[df['Train'] == 1]\n",
    "#It selects the rows on y, where the conditiomn is true\n",
    "y_test = y[df['Train'] == 0]\n",
    "#It selects the rows on y, where the conditiomn is true\n",
    "\n",
    "numeric_df = x_train.select_dtypes(include=['number'])\n",
    "numeric_test_df = x_test.select_dtypes(include=['number'])\n",
    "\n",
    "categorical_df = x_train.select_dtypes(include=['object'])\n",
    "categorical_test_df = x_test.select_dtypes(include=['object'])\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(numeric_df)\n",
    "\n",
    "# Transform numeric features\n",
    "X_train_numeric_processed = scaler.transform(numeric_df)\n",
    "X_test_numeric_processed = scaler.transform(numeric_test_df)\n",
    "\n",
    "encoder= OneHotEncoder()\n",
    "encoder.fit(categorical_df)\n",
    "\n",
    "X_train_categorical_processed = encoder.transform(categorical_df).toarray()\n",
    "X_test_categorical_processed = encoder.transform(categorical_test_df).toarray()\n",
    "\n",
    "X_train_processed = np.concatenate((X_train_numeric_processed, X_train_categorical_processed), axis=1)\n",
    "X_test_processed = np.concatenate((X_test_numeric_processed, X_test_categorical_processed), axis=1)\n",
    "\n",
    "total_samples = len(y_train)\n",
    "fraud_sample = sum(y_train)\n",
    "non_fraud_sample = total_samples - fraud_sample\n",
    "sample_fraud = fraud_sample/total_samples\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "ols=linear_model.LinearRegression()\n",
    "ols.fit(X_train_processed, y_train)\n",
    "\n",
    "ols_predictions = ols.predict(X_test_processed).round(0)\n",
    "ols_predictions\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_ols=mean_squared_error(y_test, ols_predictions)\n",
    "mse_ols\n",
    "\n",
    "ols_ct=pd.crosstab(y_test, ols_predictions)\n",
    "ols_ct\n",
    "\n",
    "type1_ols=ols_ct.iloc[0,1]/(ols_ct.iloc[0,0]+ols_ct.iloc[0,1])\n",
    "type1_ols\n",
    "type2_ols=ols_ct.iloc[1,0]/(ols_ct.iloc[1,1]+ols_ct.iloc[1,0])\n",
    "type2_ols\n",
    "fraud_acc_ols = ols_ct.iloc[1,1] / (ols_ct.iloc[1,1]+ols_ct.iloc[1,0])\n",
    "fraud_acc_ols\n",
    "nfraud_acc_ols = ols_ct.iloc[0,0] / (ols_ct.iloc[0,1]+ols_ct.iloc[0,0])\n",
    "nfraud_acc_ols\n",
    "\n",
    "r_ols=(ols_ct.iloc[0,0]+ols_ct.iloc[1,1])/(ols_ct.iloc[0,0]+ols_ct.iloc[0,1]+ols_ct.iloc[1,0]+ols_ct.iloc[1,1])\n",
    "r_ols\n",
    "\n",
    "from sklearn import linear_model\n",
    "ridge=linear_model.Ridge()\n",
    "ridge.fit(X_train_processed, y_train)\n",
    "\n",
    "ridge.fit(X_train_processed, y_train).coef_\n",
    "\n",
    "ridge_predictions = ridge.predict(X_test_processed).round(0)\n",
    "ridge_predictions\n",
    "mse_ridge=mean_squared_error(y_test, ridge_predictions)\n",
    "mse_ridge\n",
    "ridge_ct=pd.crosstab(y_test, ridge_predictions)\n",
    "ridge_ct\n",
    "\n",
    "type1_ridge=ridge_ct.iloc[0,1]/(ridge_ct.iloc[0,0]+ridge_ct.iloc[0,1])\n",
    "type1_ridge\n",
    "\n",
    "type2_ridge=ridge_ct.iloc[1,0]/(ridge_ct.iloc[1,1]+ridge_ct.iloc[1,0])\n",
    "type2_ridge\n",
    "fraud_acc_ridge = ridge_ct.iloc[1,1] / (ridge_ct.iloc[1,1]+ridge_ct.iloc[1,0])\n",
    "fraud_acc_ridge\n",
    "nfraud_acc_ridge = ridge_ct.iloc[0,0] / (ridge_ct.iloc[0,1]+ridge_ct.iloc[0,0])\n",
    "nfraud_acc_ridge\n",
    "r_ridge=(ridge_ct.iloc[0,0]+ridge_ct.iloc[1,1])/(ridge_ct.iloc[0,0]+ridge_ct.iloc[0,1]+ridge_ct.iloc[1,0]+ridge_ct.iloc[1,1])\n",
    "r_ridge\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "logit=linear_model.LogisticRegression()\n",
    "logit.fit(X_train_processed, y_train)\n",
    "logit_predictions = logit.predict(X_test_processed)\n",
    "logit_predictions\n",
    "\n",
    "mse_logit=mean_squared_error(y_test, logit_predictions)\n",
    "mse_logit\n",
    "\n",
    "logit_ct=pd.crosstab(y_test, logit_predictions)\n",
    "logit_ct\n",
    "\n",
    "type1_logit=logit_ct.iloc[0,1]/(logit_ct.iloc[0,0]+logit_ct.iloc[0,1])\n",
    "type1_logit\n",
    "\n",
    "type2_logit=logit_ct.iloc[1,0]/(logit_ct.iloc[1,1]+logit_ct.iloc[1,0])\n",
    "type2_logit\n",
    "\n",
    "fraud_acc_logit = logit_ct.iloc[1,1] / (logit_ct.iloc[1,1]+logit_ct.iloc[1,0])\n",
    "fraud_acc_logit\n",
    "\n",
    "nfraud_acc_logit = logit_ct.iloc[0,0] / (logit_ct.iloc[0,1]+logit_ct.iloc[0,0])\n",
    "nfraud_acc_logit\n",
    "\n",
    "r_logit=(logit_ct.iloc[0,0]+logit_ct.iloc[1,1])/(logit_ct.iloc[0,0]+logit_ct.iloc[0,1]+logit_ct.iloc[1,0]+logit_ct.iloc[1,1])\n",
    "r_logit\n",
    "\n",
    "from sklearn import linear_model\n",
    "lasso_logit=linear_model.LogisticRegression(penalty='l1', solver='liblinear')\n",
    "lasso_logit.fit(X_train_processed, y_train)\n",
    "\n",
    "lasso_logit_predictions = lasso_logit.predict(X_test_processed)\n",
    "lasso_logit_predictions\n",
    "\n",
    "mse_lasso_logit=mean_squared_error(y_test, lasso_logit_predictions)\n",
    "mse_lasso_logit\n",
    "\n",
    "lasso_logit_ct=pd.crosstab(y_test, lasso_logit_predictions)\n",
    "lasso_logit_ct\n",
    "\n",
    "type1_lasso_logit=lasso_logit_ct.iloc[0,1]/(lasso_logit_ct.iloc[0,0]+lasso_logit_ct.iloc[0,1])\n",
    "type1_lasso_logit\n",
    "\n",
    "type2_lasso_logit=lasso_logit_ct.iloc[1,0]/(lasso_logit_ct.iloc[1,1]+lasso_logit_ct.iloc[1,0])\n",
    "type2_lasso_logit\n",
    "fraud_acc_lasso_logit = lasso_logit_ct.iloc[1,1] / (lasso_logit_ct.iloc[1,1]+lasso_logit_ct.iloc[1,0])\n",
    "fraud_acc_lasso_logit\n",
    "nfraud_acc_lasso_logit = lasso_logit_ct.iloc[0,0] / (lasso_logit_ct.iloc[0,1]+lasso_logit_ct.iloc[0,0])\n",
    "nfraud_acc_lasso_logit \n",
    "\n",
    "r_lasso_logit=(lasso_logit_ct.iloc[0,0]+lasso_logit_ct.iloc[1,1])/(lasso_logit_ct.iloc[0,0]+lasso_logit_ct.iloc[0,1]+lasso_logit_ct.iloc[1,0]+lasso_logit_ct.iloc[1,1])\n",
    "r_lasso_logit\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_estimators = int(np.sqrt(X_train_processed.shape[1]))\n",
    "\n",
    "# Initialize Random Forest classifier with the calculated number of estimators\n",
    "rf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "\n",
    "# Train the classifier\n",
    "rf.fit(X_train_processed, y_train)\n",
    "\n",
    "rf_predictions=rf.predict(X_test_processed)\n",
    "rf_predictions\n",
    "\n",
    "mse_rf=mean_squared_error(y_test, rf_predictions)\n",
    "mse_rf\n",
    "\n",
    "rf_ct=pd.crosstab(y_test, rf_predictions)\n",
    "rf_ct\n",
    "\n",
    "type1_rf=rf_ct.iloc[0,1]/(rf_ct.iloc[0,0]+rf_ct.iloc[0,1])\n",
    "type1_rf\n",
    "\n",
    "type2_rf=rf_ct.iloc[1,0]/(rf_ct.iloc[1,1]+rf_ct.iloc[1,0])\n",
    "type2_rf\n",
    "\n",
    "fraud_acc_rf = rf_ct.iloc[1,1] / (rf_ct.iloc[1,1]+rf_ct.iloc[1,0])\n",
    "fraud_acc_rf\n",
    "\n",
    "nfraud_acc_rf = rf_ct.iloc[0,0] / (rf_ct.iloc[0,1]+rf_ct.iloc[0,0])\n",
    "nfraud_acc_rf\n",
    "\n",
    "r_rf=(rf_ct.iloc[0,0]+rf_ct.iloc[1,1])/(rf_ct.iloc[0,0]+rf_ct.iloc[0,1]+rf_ct.iloc[1,0]+rf_ct.iloc[1,1])\n",
    "r_rf\n",
    "\n",
    "mse_values=[mse_ols, mse_ridge, mse_logit, mse_lasso_logit, mse_rf]\n",
    "pseudo_r2=[r_ols, r_ridge, r_logit,r_lasso_logit, r_rf]\n",
    "type1=[type1_ols, type1_ridge, type1_logit, type1_lasso_logit, type1_rf]\n",
    "type2=[type2_ols, type2_ridge, type2_logit, type2_lasso_logit, type2_rf]\n",
    "fraud_acc=[fraud_acc_ols, fraud_acc_ridge, fraud_acc_logit, fraud_acc_lasso_logit, fraud_acc_rf]\n",
    "nfraud_acc=[nfraud_acc_ols, nfraud_acc_ridge, nfraud_acc_logit, nfraud_acc_lasso_logit, nfraud_acc_rf]\n",
    "\n",
    "total_claim = x_test.loc[y_test == 1, 'total_claim_amount'].sum()\n",
    "\n",
    "total_policy =((x_test.loc[y_test ==1, 'policy_annual_premium'])/wacc).sum()\n",
    "\n",
    "total_investigation_costs = y_test.count() * 550\n",
    "\n",
    "legal_fees = 0.365\n",
    "\n",
    "benefit = [(total_claim*fraud_acc_ols + total_investigation_costs - (1+legal_fees)*total_claim*type1_ols - total_policy)/10**3, \n",
    "          (total_claim*fraud_acc_ridge + total_investigation_costs - (1+legal_fees)*total_claim*type1_ridge - total_policy)/10**3,\n",
    "          (total_claim*fraud_acc_logit + total_investigation_costs - (1+legal_fees)*total_claim*type1_logit - total_policy)/10**3,\n",
    "          (total_claim*fraud_acc_lasso_logit + total_investigation_costs - (1+legal_fees)*total_claim*type1_lasso_logit - total_policy)/10**3, \n",
    "          (total_claim*fraud_acc_rf + total_investigation_costs - (1+legal_fees)*total_claim*type1_rf - total_policy)/10**3]\n",
    "\n",
    "model_names=['OLS', 'RIDGE', 'LOGIT', 'LASSO LOGIT', 'RANDOM FOREST']\n",
    "summary_df3 = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Fraud prediction accuracy': fraud_acc, \n",
    "    'Type 2 error': type2, \n",
    "    'Not Fraud prediction accuracy': nfraud_acc,\n",
    "    'Type 1 error': type1,\n",
    "    'Benefit in thousands': benefit})\n",
    "\n",
    "summary_df3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n"
     ]
    }
   ],
   "source": [
    "f3 = y_test.sum()\n",
    "\n",
    "print(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61199.73684210526\n",
      "1280.9591228070178\n"
     ]
    }
   ],
   "source": [
    "c3 = x_test.loc[y_test == 1, 'total_claim_amount'].mean()\n",
    "p3 = x_test.loc[y_test == 1, 'policy_annual_premium'].mean()\n",
    "print(c3)\n",
    "print(p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fraud prediction accuracy</th>\n",
       "      <th>Type 2 error</th>\n",
       "      <th>Not Fraud prediction accuracy</th>\n",
       "      <th>Type 1 error</th>\n",
       "      <th>Benefit in thousands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.134831</td>\n",
       "      <td>603.219463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RIDGE</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.867978</td>\n",
       "      <td>0.132022</td>\n",
       "      <td>632.145271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOGIT</td>\n",
       "      <td>0.415385</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.884831</td>\n",
       "      <td>0.115169</td>\n",
       "      <td>109.329036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LASSO LOGIT</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.867978</td>\n",
       "      <td>0.132022</td>\n",
       "      <td>283.959732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RANDOM FOREST</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.918539</td>\n",
       "      <td>0.081461</td>\n",
       "      <td>-820.241588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Fraud prediction accuracy  Type 2 error  \\\n",
       "0            OLS                   0.507692      0.492308   \n",
       "1          RIDGE                   0.507692      0.492308   \n",
       "2          LOGIT                   0.415385      0.584615   \n",
       "3    LASSO LOGIT                   0.461538      0.538462   \n",
       "4  RANDOM FOREST                   0.246154      0.753846   \n",
       "\n",
       "   Not Fraud prediction accuracy  Type 1 error  Benefit in thousands  \n",
       "0                       0.865169      0.134831            603.219463  \n",
       "1                       0.867978      0.132022            632.145271  \n",
       "2                       0.884831      0.115169            109.329036  \n",
       "3                       0.867978      0.132022            283.959732  \n",
       "4                       0.918539      0.081461           -820.241588  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wacc = 0.0764\n",
    "np.random.seed(6545678)\n",
    "desired_probability = 0.2\n",
    "\n",
    "df['Train']=[1 if np.random.uniform()<0.5 else 0 for _ in range(len(df))]\n",
    "df.head()\n",
    "\n",
    "x=df.drop(columns=['fraud_reported', 'Train'])\n",
    "y=df['fraud_reported']\n",
    "\n",
    "x_train = x[df['Train'] == 1]\n",
    "#It selects the rows on x, where the conditiomn is true\n",
    "x_test = x[df['Train'] == 0]\n",
    "#It selects the rows on x, where the conditiomn is true\n",
    "y_train = y[df['Train'] == 1]\n",
    "#It selects the rows on y, where the conditiomn is true\n",
    "y_test = y[df['Train'] == 0]\n",
    "#It selects the rows on y, where the conditiomn is true\n",
    "\n",
    "numeric_df = x_train.select_dtypes(include=['number'])\n",
    "numeric_test_df = x_test.select_dtypes(include=['number'])\n",
    "\n",
    "categorical_df = x_train.select_dtypes(include=['object'])\n",
    "categorical_test_df = x_test.select_dtypes(include=['object'])\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(numeric_df)\n",
    "\n",
    "# Transform numeric features\n",
    "X_train_numeric_processed = scaler.transform(numeric_df)\n",
    "X_test_numeric_processed = scaler.transform(numeric_test_df)\n",
    "\n",
    "encoder= OneHotEncoder()\n",
    "encoder.fit(categorical_df)\n",
    "\n",
    "X_train_categorical_processed = encoder.transform(categorical_df).toarray()\n",
    "X_test_categorical_processed = encoder.transform(categorical_test_df).toarray()\n",
    "\n",
    "X_train_processed = np.concatenate((X_train_numeric_processed, X_train_categorical_processed), axis=1)\n",
    "X_test_processed = np.concatenate((X_test_numeric_processed, X_test_categorical_processed), axis=1)\n",
    "\n",
    "total_samples = len(y_train)\n",
    "fraud_sample = sum(y_train)\n",
    "non_fraud_sample = total_samples - fraud_sample\n",
    "sample_fraud = fraud_sample/total_samples\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "ols=linear_model.LinearRegression()\n",
    "ols.fit(X_train_processed, y_train)\n",
    "\n",
    "ols_predictions = ols.predict(X_test_processed).round(0)\n",
    "ols_predictions\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_ols=mean_squared_error(y_test, ols_predictions)\n",
    "mse_ols\n",
    "\n",
    "ols_ct=pd.crosstab(y_test, ols_predictions)\n",
    "ols_ct\n",
    "\n",
    "type1_ols=ols_ct.iloc[0,1]/(ols_ct.iloc[0,0]+ols_ct.iloc[0,1])\n",
    "type1_ols\n",
    "type2_ols=ols_ct.iloc[1,0]/(ols_ct.iloc[1,1]+ols_ct.iloc[1,0])\n",
    "type2_ols\n",
    "fraud_acc_ols = ols_ct.iloc[1,1] / (ols_ct.iloc[1,1]+ols_ct.iloc[1,0])\n",
    "fraud_acc_ols\n",
    "nfraud_acc_ols = ols_ct.iloc[0,0] / (ols_ct.iloc[0,1]+ols_ct.iloc[0,0])\n",
    "nfraud_acc_ols\n",
    "\n",
    "r_ols=(ols_ct.iloc[0,0]+ols_ct.iloc[1,1])/(ols_ct.iloc[0,0]+ols_ct.iloc[0,1]+ols_ct.iloc[1,0]+ols_ct.iloc[1,1])\n",
    "r_ols\n",
    "\n",
    "from sklearn import linear_model\n",
    "ridge=linear_model.Ridge()\n",
    "ridge.fit(X_train_processed, y_train)\n",
    "\n",
    "ridge.fit(X_train_processed, y_train).coef_\n",
    "\n",
    "ridge_predictions = ridge.predict(X_test_processed).round(0)\n",
    "ridge_predictions\n",
    "mse_ridge=mean_squared_error(y_test, ridge_predictions)\n",
    "mse_ridge\n",
    "ridge_ct=pd.crosstab(y_test, ridge_predictions)\n",
    "ridge_ct\n",
    "\n",
    "type1_ridge=ridge_ct.iloc[0,1]/(ridge_ct.iloc[0,0]+ridge_ct.iloc[0,1])\n",
    "type1_ridge\n",
    "\n",
    "type2_ridge=ridge_ct.iloc[1,0]/(ridge_ct.iloc[1,1]+ridge_ct.iloc[1,0])\n",
    "type2_ridge\n",
    "fraud_acc_ridge = ridge_ct.iloc[1,1] / (ridge_ct.iloc[1,1]+ridge_ct.iloc[1,0])\n",
    "fraud_acc_ridge\n",
    "nfraud_acc_ridge = ridge_ct.iloc[0,0] / (ridge_ct.iloc[0,1]+ridge_ct.iloc[0,0])\n",
    "nfraud_acc_ridge\n",
    "r_ridge=(ridge_ct.iloc[0,0]+ridge_ct.iloc[1,1])/(ridge_ct.iloc[0,0]+ridge_ct.iloc[0,1]+ridge_ct.iloc[1,0]+ridge_ct.iloc[1,1])\n",
    "r_ridge\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "logit=linear_model.LogisticRegression()\n",
    "logit.fit(X_train_processed, y_train)\n",
    "logit_predictions = logit.predict(X_test_processed)\n",
    "logit_predictions\n",
    "\n",
    "mse_logit=mean_squared_error(y_test, logit_predictions)\n",
    "mse_logit\n",
    "\n",
    "logit_ct=pd.crosstab(y_test, logit_predictions)\n",
    "logit_ct\n",
    "\n",
    "type1_logit=logit_ct.iloc[0,1]/(logit_ct.iloc[0,0]+logit_ct.iloc[0,1])\n",
    "type1_logit\n",
    "\n",
    "type2_logit=logit_ct.iloc[1,0]/(logit_ct.iloc[1,1]+logit_ct.iloc[1,0])\n",
    "type2_logit\n",
    "\n",
    "fraud_acc_logit = logit_ct.iloc[1,1] / (logit_ct.iloc[1,1]+logit_ct.iloc[1,0])\n",
    "fraud_acc_logit\n",
    "\n",
    "nfraud_acc_logit = logit_ct.iloc[0,0] / (logit_ct.iloc[0,1]+logit_ct.iloc[0,0])\n",
    "nfraud_acc_logit\n",
    "\n",
    "r_logit=(logit_ct.iloc[0,0]+logit_ct.iloc[1,1])/(logit_ct.iloc[0,0]+logit_ct.iloc[0,1]+logit_ct.iloc[1,0]+logit_ct.iloc[1,1])\n",
    "r_logit\n",
    "\n",
    "from sklearn import linear_model\n",
    "lasso_logit=linear_model.LogisticRegression(penalty='l1', solver='liblinear')\n",
    "lasso_logit.fit(X_train_processed, y_train)\n",
    "\n",
    "lasso_logit_predictions = lasso_logit.predict(X_test_processed)\n",
    "lasso_logit_predictions\n",
    "\n",
    "mse_lasso_logit=mean_squared_error(y_test, lasso_logit_predictions)\n",
    "mse_lasso_logit\n",
    "\n",
    "lasso_logit_ct=pd.crosstab(y_test, lasso_logit_predictions)\n",
    "lasso_logit_ct\n",
    "\n",
    "type1_lasso_logit=lasso_logit_ct.iloc[0,1]/(lasso_logit_ct.iloc[0,0]+lasso_logit_ct.iloc[0,1])\n",
    "type1_lasso_logit\n",
    "\n",
    "type2_lasso_logit=lasso_logit_ct.iloc[1,0]/(lasso_logit_ct.iloc[1,1]+lasso_logit_ct.iloc[1,0])\n",
    "type2_lasso_logit\n",
    "fraud_acc_lasso_logit = lasso_logit_ct.iloc[1,1] / (lasso_logit_ct.iloc[1,1]+lasso_logit_ct.iloc[1,0])\n",
    "fraud_acc_lasso_logit\n",
    "nfraud_acc_lasso_logit = lasso_logit_ct.iloc[0,0] / (lasso_logit_ct.iloc[0,1]+lasso_logit_ct.iloc[0,0])\n",
    "nfraud_acc_lasso_logit \n",
    "\n",
    "r_lasso_logit=(lasso_logit_ct.iloc[0,0]+lasso_logit_ct.iloc[1,1])/(lasso_logit_ct.iloc[0,0]+lasso_logit_ct.iloc[0,1]+lasso_logit_ct.iloc[1,0]+lasso_logit_ct.iloc[1,1])\n",
    "r_lasso_logit\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_estimators = int(np.sqrt(X_train_processed.shape[1]))\n",
    "\n",
    "# Initialize Random Forest classifier with the calculated number of estimators\n",
    "rf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "\n",
    "# Train the classifier\n",
    "rf.fit(X_train_processed, y_train)\n",
    "\n",
    "rf_predictions=rf.predict(X_test_processed)\n",
    "rf_predictions\n",
    "\n",
    "mse_rf=mean_squared_error(y_test, rf_predictions)\n",
    "mse_rf\n",
    "\n",
    "rf_ct=pd.crosstab(y_test, rf_predictions)\n",
    "rf_ct\n",
    "\n",
    "type1_rf=rf_ct.iloc[0,1]/(rf_ct.iloc[0,0]+rf_ct.iloc[0,1])\n",
    "type1_rf\n",
    "\n",
    "type2_rf=rf_ct.iloc[1,0]/(rf_ct.iloc[1,1]+rf_ct.iloc[1,0])\n",
    "type2_rf\n",
    "\n",
    "fraud_acc_rf = rf_ct.iloc[1,1] / (rf_ct.iloc[1,1]+rf_ct.iloc[1,0])\n",
    "fraud_acc_rf\n",
    "\n",
    "nfraud_acc_rf = rf_ct.iloc[0,0] / (rf_ct.iloc[0,1]+rf_ct.iloc[0,0])\n",
    "nfraud_acc_rf\n",
    "\n",
    "r_rf=(rf_ct.iloc[0,0]+rf_ct.iloc[1,1])/(rf_ct.iloc[0,0]+rf_ct.iloc[0,1]+rf_ct.iloc[1,0]+rf_ct.iloc[1,1])\n",
    "r_rf\n",
    "\n",
    "mse_values=[mse_ols, mse_ridge, mse_logit, mse_lasso_logit, mse_rf]\n",
    "pseudo_r2=[r_ols, r_ridge, r_logit,r_lasso_logit, r_rf]\n",
    "type1=[type1_ols, type1_ridge, type1_logit, type1_lasso_logit, type1_rf]\n",
    "type2=[type2_ols, type2_ridge, type2_logit, type2_lasso_logit, type2_rf]\n",
    "fraud_acc=[fraud_acc_ols, fraud_acc_ridge, fraud_acc_logit, fraud_acc_lasso_logit, fraud_acc_rf]\n",
    "nfraud_acc=[nfraud_acc_ols, nfraud_acc_ridge, nfraud_acc_logit, nfraud_acc_lasso_logit, nfraud_acc_rf]\n",
    "\n",
    "total_claim = x_test.loc[y_test == 1, 'total_claim_amount'].sum()\n",
    "\n",
    "total_policy =((x_test.loc[y_test ==1, 'policy_annual_premium'])/wacc).sum()\n",
    "\n",
    "total_investigation_costs = y_test.count() * 550\n",
    "\n",
    "legal_fees = 0.365\n",
    "\n",
    "benefit = [(total_claim*fraud_acc_ols + total_investigation_costs - (1+legal_fees)*total_claim*type1_ols - total_policy)/10**3, \n",
    "          (total_claim*fraud_acc_ridge + total_investigation_costs - (1+legal_fees)*total_claim*type1_ridge - total_policy)/10**3,\n",
    "          (total_claim*fraud_acc_logit + total_investigation_costs - (1+legal_fees)*total_claim*type1_logit - total_policy)/10**3,\n",
    "          (total_claim*fraud_acc_lasso_logit + total_investigation_costs - (1+legal_fees)*total_claim*type1_lasso_logit - total_policy)/10**3, \n",
    "          (total_claim*fraud_acc_rf + total_investigation_costs - (1+legal_fees)*total_claim*type1_rf - total_policy)/10**3]\n",
    "\n",
    "model_names=['OLS', 'RIDGE', 'LOGIT', 'LASSO LOGIT', 'RANDOM FOREST']\n",
    "summary_df4 = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Fraud prediction accuracy': fraud_acc, \n",
    "    'Type 2 error': type2, \n",
    "    'Not Fraud prediction accuracy': nfraud_acc,\n",
    "    'Type 1 error': type1,\n",
    "    'Benefit in thousands': benefit})\n",
    "\n",
    "summary_df4\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n"
     ]
    }
   ],
   "source": [
    "f4 = y_test.sum()\n",
    "\n",
    "print(f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58030.92307692308\n",
      "1237.4935384615385\n"
     ]
    }
   ],
   "source": [
    "c4 = x_test.loc[y_test == 1, 'total_claim_amount'].mean()\n",
    "p4 = x_test.loc[y_test == 1, 'policy_annual_premium'].mean()\n",
    "print(c4)\n",
    "print(p4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fraud prediction accuracy</th>\n",
       "      <th>Type 2 error</th>\n",
       "      <th>Not Fraud prediction accuracy</th>\n",
       "      <th>Type 1 error</th>\n",
       "      <th>Benefit in thousands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.879357</td>\n",
       "      <td>0.120643</td>\n",
       "      <td>1212.071575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RIDGE</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.879357</td>\n",
       "      <td>0.120643</td>\n",
       "      <td>1212.071575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOGIT</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.892761</td>\n",
       "      <td>0.107239</td>\n",
       "      <td>249.411226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LASSO LOGIT</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.882038</td>\n",
       "      <td>0.117962</td>\n",
       "      <td>446.972972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RANDOM FOREST</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.906166</td>\n",
       "      <td>0.093834</td>\n",
       "      <td>-408.692456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Fraud prediction accuracy  Type 2 error  \\\n",
       "0            OLS                   0.558333      0.441667   \n",
       "1          RIDGE                   0.558333      0.441667   \n",
       "2          LOGIT                   0.408333      0.591667   \n",
       "3    LASSO LOGIT                   0.450000      0.550000   \n",
       "4  RANDOM FOREST                   0.300000      0.700000   \n",
       "\n",
       "   Not Fraud prediction accuracy  Type 1 error  Benefit in thousands  \n",
       "0                       0.879357      0.120643           1212.071575  \n",
       "1                       0.879357      0.120643           1212.071575  \n",
       "2                       0.892761      0.107239            249.411226  \n",
       "3                       0.882038      0.117962            446.972972  \n",
       "4                       0.906166      0.093834           -408.692456  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wacc = 0.0764\n",
    "np.random.seed(987611234)\n",
    "desired_probability = 0.2\n",
    "\n",
    "df['Train']=[1 if np.random.uniform()<0.5 else 0 for _ in range(len(df))]\n",
    "df.head()\n",
    "\n",
    "x=df.drop(columns=['fraud_reported', 'Train'])\n",
    "y=df['fraud_reported']\n",
    "\n",
    "x_train = x[df['Train'] == 1]\n",
    "#It selects the rows on x, where the conditiomn is true\n",
    "x_test = x[df['Train'] == 0]\n",
    "#It selects the rows on x, where the conditiomn is true\n",
    "y_train = y[df['Train'] == 1]\n",
    "#It selects the rows on y, where the conditiomn is true\n",
    "y_test = y[df['Train'] == 0]\n",
    "#It selects the rows on y, where the conditiomn is true\n",
    "\n",
    "numeric_df = x_train.select_dtypes(include=['number'])\n",
    "numeric_test_df = x_test.select_dtypes(include=['number'])\n",
    "\n",
    "categorical_df = x_train.select_dtypes(include=['object'])\n",
    "categorical_test_df = x_test.select_dtypes(include=['object'])\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(numeric_df)\n",
    "\n",
    "# Transform numeric features\n",
    "X_train_numeric_processed = scaler.transform(numeric_df)\n",
    "X_test_numeric_processed = scaler.transform(numeric_test_df)\n",
    "\n",
    "encoder= OneHotEncoder()\n",
    "encoder.fit(categorical_df)\n",
    "\n",
    "X_train_categorical_processed = encoder.transform(categorical_df).toarray()\n",
    "X_test_categorical_processed = encoder.transform(categorical_test_df).toarray()\n",
    "\n",
    "X_train_processed = np.concatenate((X_train_numeric_processed, X_train_categorical_processed), axis=1)\n",
    "X_test_processed = np.concatenate((X_test_numeric_processed, X_test_categorical_processed), axis=1)\n",
    "\n",
    "total_samples = len(y_train)\n",
    "fraud_sample = sum(y_train)\n",
    "non_fraud_sample = total_samples - fraud_sample\n",
    "sample_fraud = fraud_sample/total_samples\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "ols=linear_model.LinearRegression()\n",
    "ols.fit(X_train_processed, y_train)\n",
    "\n",
    "ols_predictions = ols.predict(X_test_processed).round(0)\n",
    "ols_predictions\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_ols=mean_squared_error(y_test, ols_predictions)\n",
    "mse_ols\n",
    "\n",
    "ols_ct=pd.crosstab(y_test, ols_predictions)\n",
    "ols_ct\n",
    "\n",
    "type1_ols=ols_ct.iloc[0,1]/(ols_ct.iloc[0,0]+ols_ct.iloc[0,1])\n",
    "type1_ols\n",
    "type2_ols=ols_ct.iloc[1,0]/(ols_ct.iloc[1,1]+ols_ct.iloc[1,0])\n",
    "type2_ols\n",
    "fraud_acc_ols = ols_ct.iloc[1,1] / (ols_ct.iloc[1,1]+ols_ct.iloc[1,0])\n",
    "fraud_acc_ols\n",
    "nfraud_acc_ols = ols_ct.iloc[0,0] / (ols_ct.iloc[0,1]+ols_ct.iloc[0,0])\n",
    "nfraud_acc_ols\n",
    "\n",
    "r_ols=(ols_ct.iloc[0,0]+ols_ct.iloc[1,1])/(ols_ct.iloc[0,0]+ols_ct.iloc[0,1]+ols_ct.iloc[1,0]+ols_ct.iloc[1,1])\n",
    "r_ols\n",
    "\n",
    "from sklearn import linear_model\n",
    "ridge=linear_model.Ridge()\n",
    "ridge.fit(X_train_processed, y_train)\n",
    "\n",
    "ridge.fit(X_train_processed, y_train).coef_\n",
    "\n",
    "ridge_predictions = ridge.predict(X_test_processed).round(0)\n",
    "ridge_predictions\n",
    "mse_ridge=mean_squared_error(y_test, ridge_predictions)\n",
    "mse_ridge\n",
    "ridge_ct=pd.crosstab(y_test, ridge_predictions)\n",
    "ridge_ct\n",
    "\n",
    "type1_ridge=ridge_ct.iloc[0,1]/(ridge_ct.iloc[0,0]+ridge_ct.iloc[0,1])\n",
    "type1_ridge\n",
    "\n",
    "type2_ridge=ridge_ct.iloc[1,0]/(ridge_ct.iloc[1,1]+ridge_ct.iloc[1,0])\n",
    "type2_ridge\n",
    "fraud_acc_ridge = ridge_ct.iloc[1,1] / (ridge_ct.iloc[1,1]+ridge_ct.iloc[1,0])\n",
    "fraud_acc_ridge\n",
    "nfraud_acc_ridge = ridge_ct.iloc[0,0] / (ridge_ct.iloc[0,1]+ridge_ct.iloc[0,0])\n",
    "nfraud_acc_ridge\n",
    "r_ridge=(ridge_ct.iloc[0,0]+ridge_ct.iloc[1,1])/(ridge_ct.iloc[0,0]+ridge_ct.iloc[0,1]+ridge_ct.iloc[1,0]+ridge_ct.iloc[1,1])\n",
    "r_ridge\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "logit=linear_model.LogisticRegression()\n",
    "logit.fit(X_train_processed, y_train)\n",
    "logit_predictions = logit.predict(X_test_processed)\n",
    "logit_predictions\n",
    "\n",
    "mse_logit=mean_squared_error(y_test, logit_predictions)\n",
    "mse_logit\n",
    "\n",
    "logit_ct=pd.crosstab(y_test, logit_predictions)\n",
    "logit_ct\n",
    "\n",
    "type1_logit=logit_ct.iloc[0,1]/(logit_ct.iloc[0,0]+logit_ct.iloc[0,1])\n",
    "type1_logit\n",
    "\n",
    "type2_logit=logit_ct.iloc[1,0]/(logit_ct.iloc[1,1]+logit_ct.iloc[1,0])\n",
    "type2_logit\n",
    "\n",
    "fraud_acc_logit = logit_ct.iloc[1,1] / (logit_ct.iloc[1,1]+logit_ct.iloc[1,0])\n",
    "fraud_acc_logit\n",
    "\n",
    "nfraud_acc_logit = logit_ct.iloc[0,0] / (logit_ct.iloc[0,1]+logit_ct.iloc[0,0])\n",
    "nfraud_acc_logit\n",
    "\n",
    "r_logit=(logit_ct.iloc[0,0]+logit_ct.iloc[1,1])/(logit_ct.iloc[0,0]+logit_ct.iloc[0,1]+logit_ct.iloc[1,0]+logit_ct.iloc[1,1])\n",
    "r_logit\n",
    "\n",
    "from sklearn import linear_model\n",
    "lasso_logit=linear_model.LogisticRegression(penalty='l1', solver='liblinear')\n",
    "lasso_logit.fit(X_train_processed, y_train)\n",
    "\n",
    "lasso_logit_predictions = lasso_logit.predict(X_test_processed)\n",
    "lasso_logit_predictions\n",
    "\n",
    "mse_lasso_logit=mean_squared_error(y_test, lasso_logit_predictions)\n",
    "mse_lasso_logit\n",
    "\n",
    "lasso_logit_ct=pd.crosstab(y_test, lasso_logit_predictions)\n",
    "lasso_logit_ct\n",
    "\n",
    "type1_lasso_logit=lasso_logit_ct.iloc[0,1]/(lasso_logit_ct.iloc[0,0]+lasso_logit_ct.iloc[0,1])\n",
    "type1_lasso_logit\n",
    "\n",
    "type2_lasso_logit=lasso_logit_ct.iloc[1,0]/(lasso_logit_ct.iloc[1,1]+lasso_logit_ct.iloc[1,0])\n",
    "type2_lasso_logit\n",
    "fraud_acc_lasso_logit = lasso_logit_ct.iloc[1,1] / (lasso_logit_ct.iloc[1,1]+lasso_logit_ct.iloc[1,0])\n",
    "fraud_acc_lasso_logit\n",
    "nfraud_acc_lasso_logit = lasso_logit_ct.iloc[0,0] / (lasso_logit_ct.iloc[0,1]+lasso_logit_ct.iloc[0,0])\n",
    "nfraud_acc_lasso_logit \n",
    "\n",
    "r_lasso_logit=(lasso_logit_ct.iloc[0,0]+lasso_logit_ct.iloc[1,1])/(lasso_logit_ct.iloc[0,0]+lasso_logit_ct.iloc[0,1]+lasso_logit_ct.iloc[1,0]+lasso_logit_ct.iloc[1,1])\n",
    "r_lasso_logit\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_estimators = int(np.sqrt(X_train_processed.shape[1]))\n",
    "\n",
    "# Initialize Random Forest classifier with the calculated number of estimators\n",
    "rf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "\n",
    "# Train the classifier\n",
    "rf.fit(X_train_processed, y_train)\n",
    "\n",
    "rf_predictions=rf.predict(X_test_processed)\n",
    "rf_predictions\n",
    "\n",
    "mse_rf=mean_squared_error(y_test, rf_predictions)\n",
    "mse_rf\n",
    "\n",
    "rf_ct=pd.crosstab(y_test, rf_predictions)\n",
    "rf_ct\n",
    "\n",
    "type1_rf=rf_ct.iloc[0,1]/(rf_ct.iloc[0,0]+rf_ct.iloc[0,1])\n",
    "type1_rf\n",
    "\n",
    "type2_rf=rf_ct.iloc[1,0]/(rf_ct.iloc[1,1]+rf_ct.iloc[1,0])\n",
    "type2_rf\n",
    "\n",
    "fraud_acc_rf = rf_ct.iloc[1,1] / (rf_ct.iloc[1,1]+rf_ct.iloc[1,0])\n",
    "fraud_acc_rf\n",
    "\n",
    "nfraud_acc_rf = rf_ct.iloc[0,0] / (rf_ct.iloc[0,1]+rf_ct.iloc[0,0])\n",
    "nfraud_acc_rf\n",
    "\n",
    "r_rf=(rf_ct.iloc[0,0]+rf_ct.iloc[1,1])/(rf_ct.iloc[0,0]+rf_ct.iloc[0,1]+rf_ct.iloc[1,0]+rf_ct.iloc[1,1])\n",
    "r_rf\n",
    "\n",
    "mse_values=[mse_ols, mse_ridge, mse_logit, mse_lasso_logit, mse_rf]\n",
    "pseudo_r2=[r_ols, r_ridge, r_logit,r_lasso_logit, r_rf]\n",
    "type1=[type1_ols, type1_ridge, type1_logit, type1_lasso_logit, type1_rf]\n",
    "type2=[type2_ols, type2_ridge, type2_logit, type2_lasso_logit, type2_rf]\n",
    "fraud_acc=[fraud_acc_ols, fraud_acc_ridge, fraud_acc_logit, fraud_acc_lasso_logit, fraud_acc_rf]\n",
    "nfraud_acc=[nfraud_acc_ols, nfraud_acc_ridge, nfraud_acc_logit, nfraud_acc_lasso_logit, nfraud_acc_rf]\n",
    "\n",
    "total_claim = x_test.loc[y_test == 1, 'total_claim_amount'].sum()\n",
    "\n",
    "total_policy =((x_test.loc[y_test ==1, 'policy_annual_premium'])/wacc).sum()\n",
    "\n",
    "total_investigation_costs = y_test.count() * 550\n",
    "\n",
    "legal_fees = 0.365\n",
    "\n",
    "benefit = [(total_claim*fraud_acc_ols + total_investigation_costs - (1+legal_fees)*total_claim*type1_ols - total_policy)/10**3, \n",
    "          (total_claim*fraud_acc_ridge + total_investigation_costs - (1+legal_fees)*total_claim*type1_ridge - total_policy)/10**3,\n",
    "          (total_claim*fraud_acc_logit + total_investigation_costs - (1+legal_fees)*total_claim*type1_logit - total_policy)/10**3,\n",
    "          (total_claim*fraud_acc_lasso_logit + total_investigation_costs - (1+legal_fees)*total_claim*type1_lasso_logit - total_policy)/10**3, \n",
    "          (total_claim*fraud_acc_rf + total_investigation_costs - (1+legal_fees)*total_claim*type1_rf - total_policy)/10**3]\n",
    "\n",
    "model_names=['OLS', 'RIDGE', 'LOGIT', 'LASSO LOGIT', 'RANDOM FOREST']\n",
    "summary_df5 = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Fraud prediction accuracy': fraud_acc, \n",
    "    'Type 2 error': type2, \n",
    "    'Not Fraud prediction accuracy': nfraud_acc,\n",
    "    'Type 1 error': type1,\n",
    "    'Benefit in thousands': benefit})\n",
    "\n",
    "summary_df5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "f5 = y_test.sum()\n",
    "\n",
    "print(f5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60911.333333333336\n",
      "1232.8699166666668\n"
     ]
    }
   ],
   "source": [
    "c5 = x_test.loc[y_test == 1, 'total_claim_amount'].mean()\n",
    "p5 = x_test.loc[y_test == 1, 'policy_annual_premium'].mean()\n",
    "print(c5)\n",
    "print(p5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fraud prediction accuracy</th>\n",
       "      <th>Type 2 error</th>\n",
       "      <th>Not Fraud prediction accuracy</th>\n",
       "      <th>Type 1 error</th>\n",
       "      <th>Benefit in thousands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>0.385246</td>\n",
       "      <td>0.614754</td>\n",
       "      <td>0.920981</td>\n",
       "      <td>0.079019</td>\n",
       "      <td>371.259872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RIDGE</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.918256</td>\n",
       "      <td>0.081744</td>\n",
       "      <td>404.703582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOGIT</td>\n",
       "      <td>0.352459</td>\n",
       "      <td>0.647541</td>\n",
       "      <td>0.923706</td>\n",
       "      <td>0.076294</td>\n",
       "      <td>154.140178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LASSO LOGIT</td>\n",
       "      <td>0.360656</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.923706</td>\n",
       "      <td>0.076294</td>\n",
       "      <td>215.365506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RANDOM FOREST</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.942779</td>\n",
       "      <td>0.057221</td>\n",
       "      <td>-937.120380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Fraud prediction accuracy  Type 2 error  \\\n",
       "0            OLS                   0.385246      0.614754   \n",
       "1          RIDGE                   0.393443      0.606557   \n",
       "2          LOGIT                   0.352459      0.647541   \n",
       "3    LASSO LOGIT                   0.360656      0.639344   \n",
       "4  RANDOM FOREST                   0.180328      0.819672   \n",
       "\n",
       "   Not Fraud prediction accuracy  Type 1 error  Benefit in thousands  \n",
       "0                       0.920981      0.079019            371.259872  \n",
       "1                       0.918256      0.081744            404.703582  \n",
       "2                       0.923706      0.076294            154.140178  \n",
       "3                       0.923706      0.076294            215.365506  \n",
       "4                       0.942779      0.057221           -937.120380  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wacc = 0.0764\n",
    "np.random.seed(85137122)\n",
    "desired_probability = 0.2\n",
    "\n",
    "df['Train']=[1 if np.random.uniform()<0.5 else 0 for _ in range(len(df))]\n",
    "df.head()\n",
    "\n",
    "x=df.drop(columns=['fraud_reported', 'Train'])\n",
    "y=df['fraud_reported']\n",
    "\n",
    "x_train = x[df['Train'] == 1]\n",
    "#It selects the rows on x, where the conditiomn is true\n",
    "x_test = x[df['Train'] == 0]\n",
    "#It selects the rows on x, where the conditiomn is true\n",
    "y_train = y[df['Train'] == 1]\n",
    "#It selects the rows on y, where the conditiomn is true\n",
    "y_test = y[df['Train'] == 0]\n",
    "#It selects the rows on y, where the conditiomn is true\n",
    "\n",
    "numeric_df = x_train.select_dtypes(include=['number'])\n",
    "numeric_test_df = x_test.select_dtypes(include=['number'])\n",
    "\n",
    "categorical_df = x_train.select_dtypes(include=['object'])\n",
    "categorical_test_df = x_test.select_dtypes(include=['object'])\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(numeric_df)\n",
    "\n",
    "# Transform numeric features\n",
    "X_train_numeric_processed = scaler.transform(numeric_df)\n",
    "X_test_numeric_processed = scaler.transform(numeric_test_df)\n",
    "\n",
    "encoder= OneHotEncoder()\n",
    "encoder.fit(categorical_df)\n",
    "\n",
    "X_train_categorical_processed = encoder.transform(categorical_df).toarray()\n",
    "X_test_categorical_processed = encoder.transform(categorical_test_df).toarray()\n",
    "\n",
    "X_train_processed = np.concatenate((X_train_numeric_processed, X_train_categorical_processed), axis=1)\n",
    "X_test_processed = np.concatenate((X_test_numeric_processed, X_test_categorical_processed), axis=1)\n",
    "\n",
    "total_samples = len(y_train)\n",
    "fraud_sample = sum(y_train)\n",
    "non_fraud_sample = total_samples - fraud_sample\n",
    "sample_fraud = fraud_sample/total_samples\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "ols=linear_model.LinearRegression()\n",
    "ols.fit(X_train_processed, y_train)\n",
    "\n",
    "ols_predictions = ols.predict(X_test_processed).round(0)\n",
    "ols_predictions\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_ols=mean_squared_error(y_test, ols_predictions)\n",
    "mse_ols\n",
    "\n",
    "ols_ct=pd.crosstab(y_test, ols_predictions)\n",
    "ols_ct\n",
    "\n",
    "type1_ols=ols_ct.iloc[0,1]/(ols_ct.iloc[0,0]+ols_ct.iloc[0,1])\n",
    "type1_ols\n",
    "type2_ols=ols_ct.iloc[1,0]/(ols_ct.iloc[1,1]+ols_ct.iloc[1,0])\n",
    "type2_ols\n",
    "fraud_acc_ols = ols_ct.iloc[1,1] / (ols_ct.iloc[1,1]+ols_ct.iloc[1,0])\n",
    "fraud_acc_ols\n",
    "nfraud_acc_ols = ols_ct.iloc[0,0] / (ols_ct.iloc[0,1]+ols_ct.iloc[0,0])\n",
    "nfraud_acc_ols\n",
    "\n",
    "r_ols=(ols_ct.iloc[0,0]+ols_ct.iloc[1,1])/(ols_ct.iloc[0,0]+ols_ct.iloc[0,1]+ols_ct.iloc[1,0]+ols_ct.iloc[1,1])\n",
    "r_ols\n",
    "\n",
    "from sklearn import linear_model\n",
    "ridge=linear_model.Ridge()\n",
    "ridge.fit(X_train_processed, y_train)\n",
    "\n",
    "ridge.fit(X_train_processed, y_train).coef_\n",
    "\n",
    "ridge_predictions = ridge.predict(X_test_processed).round(0)\n",
    "ridge_predictions\n",
    "mse_ridge=mean_squared_error(y_test, ridge_predictions)\n",
    "mse_ridge\n",
    "ridge_ct=pd.crosstab(y_test, ridge_predictions)\n",
    "ridge_ct\n",
    "\n",
    "type1_ridge=ridge_ct.iloc[0,1]/(ridge_ct.iloc[0,0]+ridge_ct.iloc[0,1])\n",
    "type1_ridge\n",
    "\n",
    "type2_ridge=ridge_ct.iloc[1,0]/(ridge_ct.iloc[1,1]+ridge_ct.iloc[1,0])\n",
    "type2_ridge\n",
    "fraud_acc_ridge = ridge_ct.iloc[1,1] / (ridge_ct.iloc[1,1]+ridge_ct.iloc[1,0])\n",
    "fraud_acc_ridge\n",
    "nfraud_acc_ridge = ridge_ct.iloc[0,0] / (ridge_ct.iloc[0,1]+ridge_ct.iloc[0,0])\n",
    "nfraud_acc_ridge\n",
    "r_ridge=(ridge_ct.iloc[0,0]+ridge_ct.iloc[1,1])/(ridge_ct.iloc[0,0]+ridge_ct.iloc[0,1]+ridge_ct.iloc[1,0]+ridge_ct.iloc[1,1])\n",
    "r_ridge\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "logit=linear_model.LogisticRegression()\n",
    "logit.fit(X_train_processed, y_train)\n",
    "logit_predictions = logit.predict(X_test_processed)\n",
    "logit_predictions\n",
    "\n",
    "mse_logit=mean_squared_error(y_test, logit_predictions)\n",
    "mse_logit\n",
    "\n",
    "logit_ct=pd.crosstab(y_test, logit_predictions)\n",
    "logit_ct\n",
    "\n",
    "type1_logit=logit_ct.iloc[0,1]/(logit_ct.iloc[0,0]+logit_ct.iloc[0,1])\n",
    "type1_logit\n",
    "\n",
    "type2_logit=logit_ct.iloc[1,0]/(logit_ct.iloc[1,1]+logit_ct.iloc[1,0])\n",
    "type2_logit\n",
    "\n",
    "fraud_acc_logit = logit_ct.iloc[1,1] / (logit_ct.iloc[1,1]+logit_ct.iloc[1,0])\n",
    "fraud_acc_logit\n",
    "\n",
    "nfraud_acc_logit = logit_ct.iloc[0,0] / (logit_ct.iloc[0,1]+logit_ct.iloc[0,0])\n",
    "nfraud_acc_logit\n",
    "\n",
    "r_logit=(logit_ct.iloc[0,0]+logit_ct.iloc[1,1])/(logit_ct.iloc[0,0]+logit_ct.iloc[0,1]+logit_ct.iloc[1,0]+logit_ct.iloc[1,1])\n",
    "r_logit\n",
    "\n",
    "from sklearn import linear_model\n",
    "lasso_logit=linear_model.LogisticRegression(penalty='l1', solver='liblinear')\n",
    "lasso_logit.fit(X_train_processed, y_train)\n",
    "\n",
    "lasso_logit_predictions = lasso_logit.predict(X_test_processed)\n",
    "lasso_logit_predictions\n",
    "\n",
    "mse_lasso_logit=mean_squared_error(y_test, lasso_logit_predictions)\n",
    "mse_lasso_logit\n",
    "\n",
    "lasso_logit_ct=pd.crosstab(y_test, lasso_logit_predictions)\n",
    "lasso_logit_ct\n",
    "\n",
    "type1_lasso_logit=lasso_logit_ct.iloc[0,1]/(lasso_logit_ct.iloc[0,0]+lasso_logit_ct.iloc[0,1])\n",
    "type1_lasso_logit\n",
    "\n",
    "type2_lasso_logit=lasso_logit_ct.iloc[1,0]/(lasso_logit_ct.iloc[1,1]+lasso_logit_ct.iloc[1,0])\n",
    "type2_lasso_logit\n",
    "fraud_acc_lasso_logit = lasso_logit_ct.iloc[1,1] / (lasso_logit_ct.iloc[1,1]+lasso_logit_ct.iloc[1,0])\n",
    "fraud_acc_lasso_logit\n",
    "nfraud_acc_lasso_logit = lasso_logit_ct.iloc[0,0] / (lasso_logit_ct.iloc[0,1]+lasso_logit_ct.iloc[0,0])\n",
    "nfraud_acc_lasso_logit \n",
    "\n",
    "r_lasso_logit=(lasso_logit_ct.iloc[0,0]+lasso_logit_ct.iloc[1,1])/(lasso_logit_ct.iloc[0,0]+lasso_logit_ct.iloc[0,1]+lasso_logit_ct.iloc[1,0]+lasso_logit_ct.iloc[1,1])\n",
    "r_lasso_logit\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_estimators = int(np.sqrt(X_train_processed.shape[1]))\n",
    "\n",
    "# Initialize Random Forest classifier with the calculated number of estimators\n",
    "rf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "\n",
    "# Train the classifier\n",
    "rf.fit(X_train_processed, y_train)\n",
    "\n",
    "rf_predictions=rf.predict(X_test_processed)\n",
    "rf_predictions\n",
    "\n",
    "mse_rf=mean_squared_error(y_test, rf_predictions)\n",
    "mse_rf\n",
    "\n",
    "rf_ct=pd.crosstab(y_test, rf_predictions)\n",
    "rf_ct\n",
    "\n",
    "type1_rf=rf_ct.iloc[0,1]/(rf_ct.iloc[0,0]+rf_ct.iloc[0,1])\n",
    "type1_rf\n",
    "\n",
    "type2_rf=rf_ct.iloc[1,0]/(rf_ct.iloc[1,1]+rf_ct.iloc[1,0])\n",
    "type2_rf\n",
    "\n",
    "fraud_acc_rf = rf_ct.iloc[1,1] / (rf_ct.iloc[1,1]+rf_ct.iloc[1,0])\n",
    "fraud_acc_rf\n",
    "\n",
    "nfraud_acc_rf = rf_ct.iloc[0,0] / (rf_ct.iloc[0,1]+rf_ct.iloc[0,0])\n",
    "nfraud_acc_rf\n",
    "\n",
    "r_rf=(rf_ct.iloc[0,0]+rf_ct.iloc[1,1])/(rf_ct.iloc[0,0]+rf_ct.iloc[0,1]+rf_ct.iloc[1,0]+rf_ct.iloc[1,1])\n",
    "r_rf\n",
    "\n",
    "mse_values=[mse_ols, mse_ridge, mse_logit, mse_lasso_logit, mse_rf]\n",
    "pseudo_r2=[r_ols, r_ridge, r_logit,r_lasso_logit, r_rf]\n",
    "type1=[type1_ols, type1_ridge, type1_logit, type1_lasso_logit, type1_rf]\n",
    "type2=[type2_ols, type2_ridge, type2_logit, type2_lasso_logit, type2_rf]\n",
    "fraud_acc=[fraud_acc_ols, fraud_acc_ridge, fraud_acc_logit, fraud_acc_lasso_logit, fraud_acc_rf]\n",
    "nfraud_acc=[nfraud_acc_ols, nfraud_acc_ridge, nfraud_acc_logit, nfraud_acc_lasso_logit, nfraud_acc_rf]\n",
    "\n",
    "total_claim = x_test.loc[y_test == 1, 'total_claim_amount'].sum()\n",
    "\n",
    "total_policy =((x_test.loc[y_test ==1, 'policy_annual_premium'])/wacc).sum()\n",
    "\n",
    "total_investigation_costs = y_test.count() * 550\n",
    "\n",
    "legal_fees = 0.365\n",
    "\n",
    "benefit = [(total_claim*fraud_acc_ols + total_investigation_costs - (1+legal_fees)*total_claim*type1_ols - total_policy)/10**3, \n",
    "          (total_claim*fraud_acc_ridge + total_investigation_costs - (1+legal_fees)*total_claim*type1_ridge - total_policy)/10**3,\n",
    "          (total_claim*fraud_acc_logit + total_investigation_costs - (1+legal_fees)*total_claim*type1_logit - total_policy)/10**3,\n",
    "          (total_claim*fraud_acc_lasso_logit + total_investigation_costs - (1+legal_fees)*total_claim*type1_lasso_logit - total_policy)/10**3, \n",
    "          (total_claim*fraud_acc_rf + total_investigation_costs - (1+legal_fees)*total_claim*type1_rf - total_policy)/10**3]\n",
    "\n",
    "model_names=['OLS', 'RIDGE', 'LOGIT', 'LASSO LOGIT', 'RANDOM FOREST']\n",
    "summary_df6 = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Fraud prediction accuracy': fraud_acc, \n",
    "    'Type 2 error': type2, \n",
    "    'Not Fraud prediction accuracy': nfraud_acc,\n",
    "    'Type 1 error': type1,\n",
    "    'Benefit in thousands': benefit})\n",
    "\n",
    "summary_df6\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n"
     ]
    }
   ],
   "source": [
    "f6 = y_test.sum()\n",
    "\n",
    "print(f6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61225.32786885246\n",
      "1233.430163934426\n"
     ]
    }
   ],
   "source": [
    "c6 = x_test.loc[y_test == 1, 'total_claim_amount'].mean()\n",
    "p6 = x_test.loc[y_test == 1, 'policy_annual_premium'].mean()\n",
    "print(c6)\n",
    "print(p6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "61124.06504065041\n",
      "1257.2066666666665\n"
     ]
    }
   ],
   "source": [
    "wacc = 0.0764\n",
    "np.random.seed(98765)\n",
    "desired_probability = 0.2\n",
    "\n",
    "df['Train']=[1 if np.random.uniform()<0.5 else 0 for _ in range(len(df))]\n",
    "df.head()\n",
    "\n",
    "x=df.drop(columns=['fraud_reported', 'Train'])\n",
    "y=df['fraud_reported']\n",
    "\n",
    "x_train = x[df['Train'] == 1]\n",
    "#It selects the rows on x, where the conditiomn is true\n",
    "x_test = x[df['Train'] == 0]\n",
    "#It selects the rows on x, where the conditiomn is true\n",
    "y_train = y[df['Train'] == 1]\n",
    "#It selects the rows on y, where the conditiomn is true\n",
    "y_test = y[df['Train'] == 0]\n",
    "#It selects the rows on y, where the conditiomn is true\n",
    "\n",
    "numeric_df = x_train.select_dtypes(include=['number'])\n",
    "numeric_test_df = x_test.select_dtypes(include=['number'])\n",
    "\n",
    "categorical_df = x_train.select_dtypes(include=['object'])\n",
    "categorical_test_df = x_test.select_dtypes(include=['object'])\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(numeric_df)\n",
    "\n",
    "# Transform numeric features\n",
    "X_train_numeric_processed = scaler.transform(numeric_df)\n",
    "X_test_numeric_processed = scaler.transform(numeric_test_df)\n",
    "\n",
    "encoder= OneHotEncoder()\n",
    "encoder.fit(categorical_df)\n",
    "\n",
    "X_train_categorical_processed = encoder.transform(categorical_df).toarray()\n",
    "X_test_categorical_processed = encoder.transform(categorical_test_df).toarray()\n",
    "\n",
    "X_train_processed = np.concatenate((X_train_numeric_processed, X_train_categorical_processed), axis=1)\n",
    "X_test_processed = np.concatenate((X_test_numeric_processed, X_test_categorical_processed), axis=1)\n",
    "\n",
    "total_samples = len(y_train)\n",
    "fraud_sample = sum(y_train)\n",
    "non_fraud_sample = total_samples - fraud_sample\n",
    "sample_fraud = fraud_sample/total_samples\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "ols=linear_model.LinearRegression()\n",
    "ols.fit(X_train_processed, y_train)\n",
    "\n",
    "ols_predictions = ols.predict(X_test_processed).round(0)\n",
    "ols_predictions\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_ols=mean_squared_error(y_test, ols_predictions)\n",
    "mse_ols\n",
    "\n",
    "ols_ct=pd.crosstab(y_test, ols_predictions)\n",
    "ols_ct\n",
    "\n",
    "type1_ols=ols_ct.iloc[0,1]/(ols_ct.iloc[0,0]+ols_ct.iloc[0,1])\n",
    "type1_ols\n",
    "type2_ols=ols_ct.iloc[1,0]/(ols_ct.iloc[1,1]+ols_ct.iloc[1,0])\n",
    "type2_ols\n",
    "fraud_acc_ols = ols_ct.iloc[1,1] / (ols_ct.iloc[1,1]+ols_ct.iloc[1,0])\n",
    "fraud_acc_ols\n",
    "nfraud_acc_ols = ols_ct.iloc[0,0] / (ols_ct.iloc[0,1]+ols_ct.iloc[0,0])\n",
    "nfraud_acc_ols\n",
    "\n",
    "r_ols=(ols_ct.iloc[0,0]+ols_ct.iloc[1,1])/(ols_ct.iloc[0,0]+ols_ct.iloc[0,1]+ols_ct.iloc[1,0]+ols_ct.iloc[1,1])\n",
    "r_ols\n",
    "\n",
    "from sklearn import linear_model\n",
    "ridge=linear_model.Ridge()\n",
    "ridge.fit(X_train_processed, y_train)\n",
    "\n",
    "ridge.fit(X_train_processed, y_train).coef_\n",
    "\n",
    "ridge_predictions = ridge.predict(X_test_processed).round(0)\n",
    "ridge_predictions\n",
    "mse_ridge=mean_squared_error(y_test, ridge_predictions)\n",
    "mse_ridge\n",
    "ridge_ct=pd.crosstab(y_test, ridge_predictions)\n",
    "ridge_ct\n",
    "\n",
    "type1_ridge=ridge_ct.iloc[0,1]/(ridge_ct.iloc[0,0]+ridge_ct.iloc[0,1])\n",
    "type1_ridge\n",
    "\n",
    "type2_ridge=ridge_ct.iloc[1,0]/(ridge_ct.iloc[1,1]+ridge_ct.iloc[1,0])\n",
    "type2_ridge\n",
    "fraud_acc_ridge = ridge_ct.iloc[1,1] / (ridge_ct.iloc[1,1]+ridge_ct.iloc[1,0])\n",
    "fraud_acc_ridge\n",
    "nfraud_acc_ridge = ridge_ct.iloc[0,0] / (ridge_ct.iloc[0,1]+ridge_ct.iloc[0,0])\n",
    "nfraud_acc_ridge\n",
    "r_ridge=(ridge_ct.iloc[0,0]+ridge_ct.iloc[1,1])/(ridge_ct.iloc[0,0]+ridge_ct.iloc[0,1]+ridge_ct.iloc[1,0]+ridge_ct.iloc[1,1])\n",
    "r_ridge\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "logit=linear_model.LogisticRegression()\n",
    "logit.fit(X_train_processed, y_train)\n",
    "logit_predictions = logit.predict(X_test_processed)\n",
    "logit_predictions\n",
    "\n",
    "mse_logit=mean_squared_error(y_test, logit_predictions)\n",
    "mse_logit\n",
    "\n",
    "logit_ct=pd.crosstab(y_test, logit_predictions)\n",
    "logit_ct\n",
    "\n",
    "type1_logit=logit_ct.iloc[0,1]/(logit_ct.iloc[0,0]+logit_ct.iloc[0,1])\n",
    "type1_logit\n",
    "\n",
    "type2_logit=logit_ct.iloc[1,0]/(logit_ct.iloc[1,1]+logit_ct.iloc[1,0])\n",
    "type2_logit\n",
    "\n",
    "fraud_acc_logit = logit_ct.iloc[1,1] / (logit_ct.iloc[1,1]+logit_ct.iloc[1,0])\n",
    "fraud_acc_logit\n",
    "\n",
    "nfraud_acc_logit = logit_ct.iloc[0,0] / (logit_ct.iloc[0,1]+logit_ct.iloc[0,0])\n",
    "nfraud_acc_logit\n",
    "\n",
    "r_logit=(logit_ct.iloc[0,0]+logit_ct.iloc[1,1])/(logit_ct.iloc[0,0]+logit_ct.iloc[0,1]+logit_ct.iloc[1,0]+logit_ct.iloc[1,1])\n",
    "r_logit\n",
    "\n",
    "from sklearn import linear_model\n",
    "lasso_logit=linear_model.LogisticRegression(penalty='l1', solver='liblinear')\n",
    "lasso_logit.fit(X_train_processed, y_train)\n",
    "\n",
    "lasso_logit_predictions = lasso_logit.predict(X_test_processed)\n",
    "lasso_logit_predictions\n",
    "\n",
    "mse_lasso_logit=mean_squared_error(y_test, lasso_logit_predictions)\n",
    "mse_lasso_logit\n",
    "\n",
    "lasso_logit_ct=pd.crosstab(y_test, lasso_logit_predictions)\n",
    "lasso_logit_ct\n",
    "\n",
    "type1_lasso_logit=lasso_logit_ct.iloc[0,1]/(lasso_logit_ct.iloc[0,0]+lasso_logit_ct.iloc[0,1])\n",
    "type1_lasso_logit\n",
    "\n",
    "type2_lasso_logit=lasso_logit_ct.iloc[1,0]/(lasso_logit_ct.iloc[1,1]+lasso_logit_ct.iloc[1,0])\n",
    "type2_lasso_logit\n",
    "fraud_acc_lasso_logit = lasso_logit_ct.iloc[1,1] / (lasso_logit_ct.iloc[1,1]+lasso_logit_ct.iloc[1,0])\n",
    "fraud_acc_lasso_logit\n",
    "nfraud_acc_lasso_logit = lasso_logit_ct.iloc[0,0] / (lasso_logit_ct.iloc[0,1]+lasso_logit_ct.iloc[0,0])\n",
    "nfraud_acc_lasso_logit \n",
    "\n",
    "r_lasso_logit=(lasso_logit_ct.iloc[0,0]+lasso_logit_ct.iloc[1,1])/(lasso_logit_ct.iloc[0,0]+lasso_logit_ct.iloc[0,1]+lasso_logit_ct.iloc[1,0]+lasso_logit_ct.iloc[1,1])\n",
    "r_lasso_logit\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_estimators = int(np.sqrt(X_train_processed.shape[1]))\n",
    "\n",
    "# Initialize Random Forest classifier with the calculated number of estimators\n",
    "rf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "\n",
    "# Train the classifier\n",
    "rf.fit(X_train_processed, y_train)\n",
    "\n",
    "rf_predictions=rf.predict(X_test_processed)\n",
    "rf_predictions\n",
    "\n",
    "mse_rf=mean_squared_error(y_test, rf_predictions)\n",
    "mse_rf\n",
    "\n",
    "rf_ct=pd.crosstab(y_test, rf_predictions)\n",
    "rf_ct\n",
    "\n",
    "type1_rf=rf_ct.iloc[0,1]/(rf_ct.iloc[0,0]+rf_ct.iloc[0,1])\n",
    "type1_rf\n",
    "\n",
    "type2_rf=rf_ct.iloc[1,0]/(rf_ct.iloc[1,1]+rf_ct.iloc[1,0])\n",
    "type2_rf\n",
    "\n",
    "fraud_acc_rf = rf_ct.iloc[1,1] / (rf_ct.iloc[1,1]+rf_ct.iloc[1,0])\n",
    "fraud_acc_rf\n",
    "\n",
    "nfraud_acc_rf = rf_ct.iloc[0,0] / (rf_ct.iloc[0,1]+rf_ct.iloc[0,0])\n",
    "nfraud_acc_rf\n",
    "\n",
    "r_rf=(rf_ct.iloc[0,0]+rf_ct.iloc[1,1])/(rf_ct.iloc[0,0]+rf_ct.iloc[0,1]+rf_ct.iloc[1,0]+rf_ct.iloc[1,1])\n",
    "r_rf\n",
    "\n",
    "mse_values=[mse_ols, mse_ridge, mse_logit, mse_lasso_logit, mse_rf]\n",
    "pseudo_r2=[r_ols, r_ridge, r_logit,r_lasso_logit, r_rf]\n",
    "type1=[type1_ols, type1_ridge, type1_logit, type1_lasso_logit, type1_rf]\n",
    "type2=[type2_ols, type2_ridge, type2_logit, type2_lasso_logit, type2_rf]\n",
    "fraud_acc=[fraud_acc_ols, fraud_acc_ridge, fraud_acc_logit, fraud_acc_lasso_logit, fraud_acc_rf]\n",
    "nfraud_acc=[nfraud_acc_ols, nfraud_acc_ridge, nfraud_acc_logit, nfraud_acc_lasso_logit, nfraud_acc_rf]\n",
    "\n",
    "total_claim = x_test.loc[y_test == 1, 'total_claim_amount'].sum()\n",
    "\n",
    "total_policy =((x_test.loc[y_test ==1, 'policy_annual_premium'])/wacc).sum()\n",
    "\n",
    "total_investigation_costs = y_test.count() * 550\n",
    "\n",
    "legal_fees = 0.365\n",
    "\n",
    "benefit = [(total_claim*fraud_acc_ols + total_investigation_costs - (1+legal_fees)*total_claim*type1_ols - total_policy)/10**3, \n",
    "          (total_claim*fraud_acc_ridge + total_investigation_costs - (1+legal_fees)*total_claim*type1_ridge - total_policy)/10**3,\n",
    "          (total_claim*fraud_acc_logit + total_investigation_costs - (1+legal_fees)*total_claim*type1_logit - total_policy)/10**3,\n",
    "          (total_claim*fraud_acc_lasso_logit + total_investigation_costs - (1+legal_fees)*total_claim*type1_lasso_logit - total_policy)/10**3, \n",
    "          (total_claim*fraud_acc_rf + total_investigation_costs - (1+legal_fees)*total_claim*type1_rf - total_policy)/10**3]\n",
    "\n",
    "model_names=['OLS', 'RIDGE', 'LOGIT', 'LASSO LOGIT', 'RANDOM FOREST']\n",
    "summary_df7 = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Fraud prediction accuracy': fraud_acc, \n",
    "    'Type 2 error': type2, \n",
    "    'Not Fraud prediction accuracy': nfraud_acc,\n",
    "    'Type 1 error': type1,\n",
    "    'Benefit in thousands': benefit})\n",
    "\n",
    "summary_df7\n",
    "\n",
    "f7 = y_test.sum()\n",
    "\n",
    "print(f7)\n",
    "\n",
    "c7 = x_test.loc[y_test == 1, 'total_claim_amount'].mean()\n",
    "p7 = x_test.loc[y_test == 1, 'policy_annual_premium'].mean()\n",
    "print(c7)\n",
    "print(p7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "f7 = y_test.sum()\n",
    "\n",
    "print(f7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61124.06504065041\n",
      "1257.2066666666665\n"
     ]
    }
   ],
   "source": [
    "c7 = x_test.loc[y_test == 1, 'total_claim_amount'].mean()\n",
    "p7 = x_test.loc[y_test == 1, 'policy_annual_premium'].mean()\n",
    "print(c7)\n",
    "print(p7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fraud prediction accuracy</th>\n",
       "      <th>Type 2 error</th>\n",
       "      <th>Not Fraud prediction accuracy</th>\n",
       "      <th>Type 1 error</th>\n",
       "      <th>Benefit in thousands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>1020.534982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RIDGE</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>1020.534982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOGIT</td>\n",
       "      <td>0.445312</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.902116</td>\n",
       "      <td>0.097884</td>\n",
       "      <td>623.976677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LASSO LOGIT</td>\n",
       "      <td>0.460938</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.902116</td>\n",
       "      <td>0.097884</td>\n",
       "      <td>746.707927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RANDOM FOREST</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>-333.599809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Fraud prediction accuracy  Type 2 error  \\\n",
       "0            OLS                   0.492188      0.507812   \n",
       "1          RIDGE                   0.492188      0.507812   \n",
       "2          LOGIT                   0.445312      0.554688   \n",
       "3    LASSO LOGIT                   0.460938      0.539062   \n",
       "4  RANDOM FOREST                   0.265625      0.734375   \n",
       "\n",
       "   Not Fraud prediction accuracy  Type 1 error  Benefit in thousands  \n",
       "0                       0.904762      0.095238           1020.534982  \n",
       "1                       0.904762      0.095238           1020.534982  \n",
       "2                       0.902116      0.097884            623.976677  \n",
       "3                       0.902116      0.097884            746.707927  \n",
       "4                       0.944444      0.055556           -333.599809  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fraud prediction accuracy</th>\n",
       "      <th>Type 2 error</th>\n",
       "      <th>Not Fraud prediction accuracy</th>\n",
       "      <th>Type 1 error</th>\n",
       "      <th>Benefit in thousands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>0.425197</td>\n",
       "      <td>0.574803</td>\n",
       "      <td>0.892761</td>\n",
       "      <td>0.107239</td>\n",
       "      <td>427.686446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RIDGE</td>\n",
       "      <td>0.425197</td>\n",
       "      <td>0.574803</td>\n",
       "      <td>0.898123</td>\n",
       "      <td>0.101877</td>\n",
       "      <td>485.026180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOGIT</td>\n",
       "      <td>0.370079</td>\n",
       "      <td>0.629921</td>\n",
       "      <td>0.906166</td>\n",
       "      <td>0.093834</td>\n",
       "      <td>139.222317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LASSO LOGIT</td>\n",
       "      <td>0.385827</td>\n",
       "      <td>0.614173</td>\n",
       "      <td>0.900804</td>\n",
       "      <td>0.099196</td>\n",
       "      <td>205.257858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RANDOM FOREST</td>\n",
       "      <td>0.259843</td>\n",
       "      <td>0.740157</td>\n",
       "      <td>0.932976</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>-437.705941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Fraud prediction accuracy  Type 2 error  \\\n",
       "0            OLS                   0.425197      0.574803   \n",
       "1          RIDGE                   0.425197      0.574803   \n",
       "2          LOGIT                   0.370079      0.629921   \n",
       "3    LASSO LOGIT                   0.385827      0.614173   \n",
       "4  RANDOM FOREST                   0.259843      0.740157   \n",
       "\n",
       "   Not Fraud prediction accuracy  Type 1 error  Benefit in thousands  \n",
       "0                       0.892761      0.107239            427.686446  \n",
       "1                       0.898123      0.101877            485.026180  \n",
       "2                       0.906166      0.093834            139.222317  \n",
       "3                       0.900804      0.099196            205.257858  \n",
       "4                       0.932976      0.067024           -437.705941  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fraud prediction accuracy</th>\n",
       "      <th>Type 2 error</th>\n",
       "      <th>Not Fraud prediction accuracy</th>\n",
       "      <th>Type 1 error</th>\n",
       "      <th>Benefit in thousands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.905612</td>\n",
       "      <td>0.094388</td>\n",
       "      <td>895.224404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RIDGE</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.908163</td>\n",
       "      <td>0.091837</td>\n",
       "      <td>919.518514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOGIT</td>\n",
       "      <td>0.429825</td>\n",
       "      <td>0.570175</td>\n",
       "      <td>0.903061</td>\n",
       "      <td>0.096939</td>\n",
       "      <td>442.532136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LASSO LOGIT</td>\n",
       "      <td>0.412281</td>\n",
       "      <td>0.587719</td>\n",
       "      <td>0.915816</td>\n",
       "      <td>0.084184</td>\n",
       "      <td>441.603212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RANDOM FOREST</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.913265</td>\n",
       "      <td>0.086735</td>\n",
       "      <td>111.310418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Fraud prediction accuracy  Type 2 error  \\\n",
       "0            OLS                   0.491228      0.508772   \n",
       "1          RIDGE                   0.491228      0.508772   \n",
       "2          LOGIT                   0.429825      0.570175   \n",
       "3    LASSO LOGIT                   0.412281      0.587719   \n",
       "4  RANDOM FOREST                   0.368421      0.631579   \n",
       "\n",
       "   Not Fraud prediction accuracy  Type 1 error  Benefit in thousands  \n",
       "0                       0.905612      0.094388            895.224404  \n",
       "1                       0.908163      0.091837            919.518514  \n",
       "2                       0.903061      0.096939            442.532136  \n",
       "3                       0.915816      0.084184            441.603212  \n",
       "4                       0.913265      0.086735            111.310418  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fraud prediction accuracy</th>\n",
       "      <th>Type 2 error</th>\n",
       "      <th>Not Fraud prediction accuracy</th>\n",
       "      <th>Type 1 error</th>\n",
       "      <th>Benefit in thousands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.134831</td>\n",
       "      <td>603.219463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RIDGE</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.867978</td>\n",
       "      <td>0.132022</td>\n",
       "      <td>632.145271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOGIT</td>\n",
       "      <td>0.415385</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.884831</td>\n",
       "      <td>0.115169</td>\n",
       "      <td>109.329036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LASSO LOGIT</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.867978</td>\n",
       "      <td>0.132022</td>\n",
       "      <td>283.959732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RANDOM FOREST</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.918539</td>\n",
       "      <td>0.081461</td>\n",
       "      <td>-820.241588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Fraud prediction accuracy  Type 2 error  \\\n",
       "0            OLS                   0.507692      0.492308   \n",
       "1          RIDGE                   0.507692      0.492308   \n",
       "2          LOGIT                   0.415385      0.584615   \n",
       "3    LASSO LOGIT                   0.461538      0.538462   \n",
       "4  RANDOM FOREST                   0.246154      0.753846   \n",
       "\n",
       "   Not Fraud prediction accuracy  Type 1 error  Benefit in thousands  \n",
       "0                       0.865169      0.134831            603.219463  \n",
       "1                       0.867978      0.132022            632.145271  \n",
       "2                       0.884831      0.115169            109.329036  \n",
       "3                       0.867978      0.132022            283.959732  \n",
       "4                       0.918539      0.081461           -820.241588  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fraud prediction accuracy</th>\n",
       "      <th>Type 2 error</th>\n",
       "      <th>Not Fraud prediction accuracy</th>\n",
       "      <th>Type 1 error</th>\n",
       "      <th>Benefit in thousands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.879357</td>\n",
       "      <td>0.120643</td>\n",
       "      <td>1212.071575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RIDGE</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>0.879357</td>\n",
       "      <td>0.120643</td>\n",
       "      <td>1212.071575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOGIT</td>\n",
       "      <td>0.408333</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.892761</td>\n",
       "      <td>0.107239</td>\n",
       "      <td>249.411226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LASSO LOGIT</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.882038</td>\n",
       "      <td>0.117962</td>\n",
       "      <td>446.972972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RANDOM FOREST</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.906166</td>\n",
       "      <td>0.093834</td>\n",
       "      <td>-408.692456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Fraud prediction accuracy  Type 2 error  \\\n",
       "0            OLS                   0.558333      0.441667   \n",
       "1          RIDGE                   0.558333      0.441667   \n",
       "2          LOGIT                   0.408333      0.591667   \n",
       "3    LASSO LOGIT                   0.450000      0.550000   \n",
       "4  RANDOM FOREST                   0.300000      0.700000   \n",
       "\n",
       "   Not Fraud prediction accuracy  Type 1 error  Benefit in thousands  \n",
       "0                       0.879357      0.120643           1212.071575  \n",
       "1                       0.879357      0.120643           1212.071575  \n",
       "2                       0.892761      0.107239            249.411226  \n",
       "3                       0.882038      0.117962            446.972972  \n",
       "4                       0.906166      0.093834           -408.692456  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fraud prediction accuracy</th>\n",
       "      <th>Type 2 error</th>\n",
       "      <th>Not Fraud prediction accuracy</th>\n",
       "      <th>Type 1 error</th>\n",
       "      <th>Benefit in thousands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>0.385246</td>\n",
       "      <td>0.614754</td>\n",
       "      <td>0.920981</td>\n",
       "      <td>0.079019</td>\n",
       "      <td>371.259872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RIDGE</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.918256</td>\n",
       "      <td>0.081744</td>\n",
       "      <td>404.703582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOGIT</td>\n",
       "      <td>0.352459</td>\n",
       "      <td>0.647541</td>\n",
       "      <td>0.923706</td>\n",
       "      <td>0.076294</td>\n",
       "      <td>154.140178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LASSO LOGIT</td>\n",
       "      <td>0.360656</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.923706</td>\n",
       "      <td>0.076294</td>\n",
       "      <td>215.365506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RANDOM FOREST</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.942779</td>\n",
       "      <td>0.057221</td>\n",
       "      <td>-937.120380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Fraud prediction accuracy  Type 2 error  \\\n",
       "0            OLS                   0.385246      0.614754   \n",
       "1          RIDGE                   0.393443      0.606557   \n",
       "2          LOGIT                   0.352459      0.647541   \n",
       "3    LASSO LOGIT                   0.360656      0.639344   \n",
       "4  RANDOM FOREST                   0.180328      0.819672   \n",
       "\n",
       "   Not Fraud prediction accuracy  Type 1 error  Benefit in thousands  \n",
       "0                       0.920981      0.079019            371.259872  \n",
       "1                       0.918256      0.081744            404.703582  \n",
       "2                       0.923706      0.076294            154.140178  \n",
       "3                       0.923706      0.076294            215.365506  \n",
       "4                       0.942779      0.057221           -937.120380  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fraud prediction accuracy</th>\n",
       "      <th>Type 2 error</th>\n",
       "      <th>Not Fraud prediction accuracy</th>\n",
       "      <th>Type 1 error</th>\n",
       "      <th>Benefit in thousands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.593496</td>\n",
       "      <td>0.879896</td>\n",
       "      <td>0.120104</td>\n",
       "      <td>77.903559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RIDGE</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>0.593496</td>\n",
       "      <td>0.879896</td>\n",
       "      <td>0.120104</td>\n",
       "      <td>77.903559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOGIT</td>\n",
       "      <td>0.365854</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.885117</td>\n",
       "      <td>0.114883</td>\n",
       "      <td>-174.127080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LASSO LOGIT</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.887728</td>\n",
       "      <td>0.112272</td>\n",
       "      <td>402.784349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RANDOM FOREST</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.950392</td>\n",
       "      <td>0.049608</td>\n",
       "      <td>-971.233564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Fraud prediction accuracy  Type 2 error  \\\n",
       "0            OLS                   0.406504      0.593496   \n",
       "1          RIDGE                   0.406504      0.593496   \n",
       "2          LOGIT                   0.365854      0.634146   \n",
       "3    LASSO LOGIT                   0.439024      0.560976   \n",
       "4  RANDOM FOREST                   0.170732      0.829268   \n",
       "\n",
       "   Not Fraud prediction accuracy  Type 1 error  Benefit in thousands  \n",
       "0                       0.879896      0.120104             77.903559  \n",
       "1                       0.879896      0.120104             77.903559  \n",
       "2                       0.885117      0.114883           -174.127080  \n",
       "3                       0.887728      0.112272            402.784349  \n",
       "4                       0.950392      0.049608           -971.233564  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [summary_df1, summary_df2, summary_df3, summary_df4, summary_df5, summary_df6, summary_df7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.466627\n",
       "1    0.467798\n",
       "2    0.398178\n",
       "3    0.424323\n",
       "4    0.255872\n",
       "Name: Fraud prediction accuracy, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Average_Fraud_prediction_accuracy = (summary_df1['Fraud prediction accuracy']+ summary_df2['Fraud prediction accuracy'] + summary_df3['Fraud prediction accuracy'] + summary_df4['Fraud prediction accuracy'] + summary_df5['Fraud prediction accuracy'] + summary_df6['Fraud prediction accuracy']+ summary_df7['Fraud prediction accuracy'])/len(dfs)\n",
    "Average_Fraud_prediction_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.533373\n",
       "1    0.532202\n",
       "2    0.601822\n",
       "3    0.575677\n",
       "4    0.744128\n",
       "Name: Type 2 error, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Average_type2 = (summary_df1['Type 2 error']+ summary_df2['Type 2 error'] + summary_df3['Type 2 error'] + summary_df4['Type 2 error'] + summary_df5['Type 2 error'] + summary_df6['Type 2 error']+ summary_df7['Type 2 error'])/len(dfs)\n",
    "Average_type2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.892648\n",
       "1    0.893791\n",
       "2    0.899680\n",
       "3    0.897169\n",
       "4    0.929795\n",
       "Name: Not Fraud prediction accuracy, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Average_NFraud_prediction_accuracy = (summary_df1['Not Fraud prediction accuracy']+ summary_df2['Not Fraud prediction accuracy'] + summary_df3['Not Fraud prediction accuracy'] + summary_df4['Not Fraud prediction accuracy'] + summary_df5['Not Fraud prediction accuracy'] + summary_df6['Not Fraud prediction accuracy'] + summary_df7['Not Fraud prediction accuracy'])/len(dfs)\n",
    "Average_NFraud_prediction_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.215893\n",
       "1    0.214751\n",
       "2    0.210354\n",
       "3    0.213610\n",
       "4    0.198889\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Average_type1 = (summary_df1['Type 1 error']+ summary_df2['Type 1 error'] + summary_df3['Type 1 error'] + summary_df4['Type 1 error'] + summary_df5['Type 1 error'] + summary_df6['Type 1 error']+ summary_df7['Not Fraud prediction accuracy'])/len(dfs)\n",
    "Average_type1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    658.271472\n",
       "1    678.843380\n",
       "2    220.640642\n",
       "3    391.807365\n",
       "4   -542.469046\n",
       "Name: Benefit in thousands, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Average_benefit = (summary_df1['Benefit in thousands'] + summary_df2['Benefit in thousands']+ summary_df3['Benefit in thousands']+ summary_df4['Benefit in thousands']+ summary_df5['Benefit in thousands']+ summary_df6['Benefit in thousands']+ summary_df7['Benefit in thousands'])/len(dfs)\n",
    "Average_benefit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El MSE es una medida del promedio de los cuadrados de los errores, es decir, la diferencia promedio al cuadrado entre los valores observados y los valores predichos por el modelo. Cuanto menor sea el MSE, mejor serÃ¡ el modelo en tÃ©rminos de precisiÃ³n.\n",
    "\n",
    "El Pseudo R-cuadrado es una medida que intenta proporcionar una interpretaciÃ³n similar al R-cuadrado para modelos que no son de mÃ­nimos cuadrados ordinarios, como la regresiÃ³n logÃ­stica. No se interpreta exactamente de la misma manera que el R-cuadrado en la regresiÃ³n lineal, pero un valor mÃ¡s alto generalmente indica un mejor ajuste del modelo.\n",
    "\n",
    "Error de Tipo 1 (Falsos Positivos): Un alto error de Tipo 1 significa que el modelo estÃ¡ identificando incorrectamente transacciones legÃ­timas como fraudulentas. Esto puede ser costoso y molesto para los clientes legÃ­timos y puede daÃ±ar la relaciÃ³n con los clientes y la reputaciÃ³n de la compaÃ±Ã­a de seguros. Predice que hay fraude, cuando no hay fraude.\n",
    "\n",
    "El error de Tipo 2 se refiere a la tasa de falsos negativos, es decir, cuÃ¡ntas veces un modelo no logra detectar un evento (como el fraude) cuando en realidad sÃ­ ocurriÃ³. Esto puede resultar en pÃ©rdidas financieras significativas para la compaÃ±Ã­a de seguros si los reclamos fraudulentos no se detectan. Predice que no hay fraude, cuando hay fraude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of False negatives: The number of instances where the model incorrectly predicts not fraud (negative class)\n",
    "\n",
    "Number of actual Positives: Total number of instances where true outcome is fraud\n",
    "\n",
    "Type II Error Rate= Number of False Negatives/Number of Actual Positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of False Positives: The number of instances where the model incorrectly predicts default (positive class) when the true outcome is not default (negative class).\n",
    "\n",
    "Number of Actual Negatives: The total number of instances where the true outcome is not default (negative class).\n",
    "\n",
    "Type I Error Rate= Number of False Positives/Number of Actual Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el contexto de la prevenciÃ³n de fraudes en seguros, minimizar los errores de Tipo 2 generalmente serÃ­a la prioridad porque los reclamos fraudulentos pueden tener un impacto financiero significativo. Sin embargo, un modelo con un error de Tipo 1 extremadamente alto tambiÃ©n podrÃ­a ser imprÃ¡ctico porque sobrecargarÃ­a al equipo de revisiÃ³n de reclamos con falsas alarmas.En el contexto de la prevenciÃ³n de fraudes en seguros, minimizar los errores de Tipo 2 generalmente serÃ­a la prioridad porque los reclamos fraudulentos pueden tener un impacto financiero significativo. Sin embargo, un modelo con un error de Tipo 1 extremadamente alto tambiÃ©n podrÃ­a ser imprÃ¡ctico porque sobrecargarÃ­a al equipo de revisiÃ³n de reclamos con falsas alarmas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In $ terms\n",
    "\n",
    "**If I predict fraud, I wonÂ´t pay anything.**\n",
    "\n",
    "If correctly predict fraud, I will gain the \"Total claim amount\"\n",
    "(I didnÂ´t pay when I shouldnÂ´t have)\n",
    "\n",
    "If incorrectly predict fraud (type 1), I will lose a customer => lose policy annual premium\n",
    "(I didnÂ´t pay when I should have)\n",
    "\n",
    "**If I predict not fraud, I will pay.**\n",
    "\n",
    "If I correctly predict not fraud, I will \"not lose\" (gain) the policy annual premium\n",
    "(I paid when I should have)\n",
    "\n",
    "If I incorrectly predict not fraud (type 2), I will lose the \"Total claim amount\" (because I shouldnÂ´t be paying it)\n",
    "(I paid when I shouldnÂ´t have)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefit\n",
    "\n",
    "If the prediction is \"not fraud\" the outcome would be the same as if the model had never been implemented. If the prediction is \"Not fraud\", no additional measure or actions would be implemented and the results woulnÂ´t change. No incremental actions, measures, benefits or cashflows.\n",
    "\n",
    "If the prediction is \"fraud\", there will be new actions: we wouldnÂ´t pay. However, there will also be consequences. When we correctly predict fraud we wonÂ´t pay when we shouldnÂ´t, so the money we wonÂ´t spend would be a gain (equal to the claim amount).  When we incorrectly predict fraud, we wonÂ´t pay when we should have. This will probably mean that we lose a customer and, therefore, lose the annual premium. \n",
    "\n",
    "The benefit of using this model is defined as Gain - Loss, where:\n",
    "\n",
    "Gain:   Total claim when fraud occurs * probability of accurately predicting fraud \n",
    "\n",
    "Loss:   Total annual premium when fraud occurs * probability of incorrectly predicting fraud (type 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fraud prediction accuracy</th>\n",
       "      <th>Type 2 error</th>\n",
       "      <th>Not Fraud prediction accuracy</th>\n",
       "      <th>Type 1 error</th>\n",
       "      <th>Benefit in thousands</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>0.466627</td>\n",
       "      <td>0.533373</td>\n",
       "      <td>0.892648</td>\n",
       "      <td>0.215893</td>\n",
       "      <td>658.271472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RIDGE</td>\n",
       "      <td>0.467798</td>\n",
       "      <td>0.532202</td>\n",
       "      <td>0.893791</td>\n",
       "      <td>0.214751</td>\n",
       "      <td>678.843380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOGIT</td>\n",
       "      <td>0.398178</td>\n",
       "      <td>0.601822</td>\n",
       "      <td>0.899680</td>\n",
       "      <td>0.210354</td>\n",
       "      <td>220.640642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LASSO LOGIT</td>\n",
       "      <td>0.424323</td>\n",
       "      <td>0.575677</td>\n",
       "      <td>0.897169</td>\n",
       "      <td>0.213610</td>\n",
       "      <td>391.807365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RANDOM FOREST</td>\n",
       "      <td>0.255872</td>\n",
       "      <td>0.744128</td>\n",
       "      <td>0.929795</td>\n",
       "      <td>0.198889</td>\n",
       "      <td>-542.469046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Fraud prediction accuracy  Type 2 error  \\\n",
       "0            OLS                   0.466627      0.533373   \n",
       "1          RIDGE                   0.467798      0.532202   \n",
       "2          LOGIT                   0.398178      0.601822   \n",
       "3    LASSO LOGIT                   0.424323      0.575677   \n",
       "4  RANDOM FOREST                   0.255872      0.744128   \n",
       "\n",
       "   Not Fraud prediction accuracy  Type 1 error  Benefit in thousands  \n",
       "0                       0.892648      0.215893            658.271472  \n",
       "1                       0.893791      0.214751            678.843380  \n",
       "2                       0.899680      0.210354            220.640642  \n",
       "3                       0.897169      0.213610            391.807365  \n",
       "4                       0.929795      0.198889           -542.469046  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names=['OLS','RIDGE', 'LOGIT', 'LASSO LOGIT', 'RANDOM FOREST']\n",
    "cv = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Fraud prediction accuracy': Average_Fraud_prediction_accuracy, \n",
    "    'Type 2 error': Average_type2, \n",
    "    'Not Fraud prediction accuracy': Average_NFraud_prediction_accuracy,\n",
    "    'Type 1 error': Average_type1,\n",
    "    'Benefit in thousands': Average_benefit})\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123.42857142857143"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average fraud cases\n",
    "n_fraud_average = (f1+f2+f3+f4+f5+f6+f7)/7\n",
    "n_fraud_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60792.09270816288"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Claim average\n",
    "claim_average = (c1+c2+c3+c4+c5+c6+c7)/7\n",
    "claim_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1245.5977171081124"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Premium average\n",
    "premium_average = (p1+p2+p3+p4+p5+p6+p7)/7\n",
    "premium_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pesar de que LASSO LOGIT es el modelo con mayor error tipo 1, es el modelo que minimiza el error tipo 2, es decir, el modelo que mejor predice los casos de fraude.\n",
    "\n",
    "Debido a que el error tipo 2 es \"mÃ¡s caro\" que el error tipo 2  (prima anual que la aseguradora recibe es significativamente menor a la cantidad de dinero que debe pagar en caso de siniestro), LASSO LOGIT es el modelo que maximiza los beneficios monetarios. \n",
    "\n",
    "En ese sentido, que la aseguradore use ese modelo le ayudarÃ¡ a ahorrar 218 mil de dÃ³lares por cada 122 casos de fraude, pues mÃ¡s del 40% de los fraudes son identificados.\n",
    "\n",
    "Si extrapolamos estos resultados y aplicamos el modelo a mÃ¡s de 122 casos, las ganancias aumentarÃ¡n significativamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
